---
layout: sphinx
title: Sphinx 2.0.1-beta reference manual
description:  Sphinx 2.0.1-beta reference manual
keywords :  Sphinx 2.0.1-beta reference manual
---

<div lang="en" class="book" title="Sphinx 2.0.1-beta reference manual">
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="chapter"><a href="#intro">1. Introduction</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#about">1.1. About</a></span></dt>
<dt><span class="sect1"><a href="#features">1.2. Sphinx features</a></span></dt>
<dt><span class="sect1"><a href="#getting">1.3. Where to get Sphinx</a></span></dt>
<dt><span class="sect1"><a href="#license">1.4. License</a></span></dt>
<dt><span class="sect1"><a href="#credits">1.5. Credits</a></span></dt>
<dt><span class="sect1"><a href="#history">1.6. History</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#installation">2. Installation</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#supported-system">2.1. Supported systems</a></span></dt>
<dt><span class="sect1"><a href="#required-tools">2.2. Required tools</a></span></dt>
<dt><span class="sect1"><a href="#installing">2.3. Installing Sphinx on Linux</a></span></dt>
<dt><span class="sect1"><a href="#installing-windows">2.4. Installing Sphinx on Windows</a></span></dt>
<dt><span class="sect1"><a href="#install-problems">2.5. Known installation issues</a></span></dt>
<dt><span class="sect1"><a href="#quick-tour">2.6. Quick Sphinx usage tour</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#indexing">3. Indexing</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#sources">3.1. Data sources</a></span></dt>
<dt><span class="sect1"><a href="#attributes">3.2. Attributes</a></span></dt>
<dt><span class="sect1"><a href="#mva">3.3. MVA (multi-valued attributes)</a></span></dt>
<dt><span class="sect1"><a href="#indexes">3.4. Indexes</a></span></dt>
<dt><span class="sect1"><a href="#data-restrictions">3.5. Restrictions on the source data</a></span></dt>
<dt><span class="sect1"><a href="#charsets">3.6. Charsets, case folding, and translation tables</a></span></dt>
<dt><span class="sect1"><a href="#sql">3.7. SQL data sources (MySQL, PostgreSQL)</a></span></dt>
<dt><span class="sect1"><a href="#xmlpipe">3.8. xmlpipe data source</a></span></dt>
<dt><span class="sect1"><a href="#xmlpipe2">3.9. xmlpipe2 data source</a></span></dt>
<dt><span class="sect1"><a href="#live-updates">3.10. Live index updates</a></span></dt>
<dt><span class="sect1"><a href="#delta-updates">3.11. Delta index updates</a></span></dt>
<dt><span class="sect1"><a href="#index-merging">3.12. Index merging</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#rt-indexes">4. Real-time indexes</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#rt-overview">4.1. RT indexes overview</a></span></dt>
<dt><span class="sect1"><a href="#rt-caveats">4.2. Known caveats with RT indexes</a></span></dt>
<dt><span class="sect1"><a href="#rt-internals">4.3. RT index internals</a></span></dt>
<dt><span class="sect1"><a href="#rt-binlog">4.4. Binary logging</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#searching">5. Searching</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#matching-modes">5.1. Matching modes</a></span></dt>
<dt><span class="sect1"><a href="#boolean-syntax">5.2. Boolean query syntax</a></span></dt>
<dt><span class="sect1"><a href="#extended-syntax">5.3. Extended query syntax</a></span></dt>
<dt><span class="sect1"><a href="#weighting">5.4. Weighting</a></span></dt>
<dt><span class="sect1"><a href="#expressions">5.5. Expressions, functions, and operators</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#operators">5.5.1. Operators</a></span></dt>
<dt><span class="sect2"><a href="#numeric-functions">5.5.2. Numeric functions</a></span></dt>
<dt><span class="sect2"><a href="#date-time-functions">5.5.3. Date and time functions</a></span></dt>
<dt><span class="sect2"><a href="#type-conversion-functions">5.5.4. Type conversion functions</a></span></dt>
<dt><span class="sect2"><a href="#comparison-functions">5.5.5. Comparison functions</a></span></dt>
<dt><span class="sect2"><a href="#misc-functions">5.5.6. Miscellaneous functions</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sorting-modes">5.6. Sorting modes</a></span></dt>
<dt><span class="sect1"><a href="#clustering">5.7. Grouping (clustering) search results</a></span></dt>
<dt><span class="sect1"><a href="#distributed">5.8. Distributed searching</a></span></dt>
<dt><span class="sect1"><a href="#query-log-format">5.9. <code class="filename">searchd</code> query log formats</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#plain-log-format">5.9.1. Plain log format</a></span></dt>
<dt><span class="sect2"><a href="#sphinxql-log-format">5.9.2. SphinxQL log format</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sphinxql">5.10. MySQL protocol support and SphinxQL</a></span></dt>
<dt><span class="sect1"><a href="#multi-queries">5.11. Multi-queries</a></span></dt>
<dt><span class="sect1"><a href="#collations">5.12. Collations</a></span></dt>
<dt><span class="sect1"><a href="#udf">5.13. User-defined functions (UDF)</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#command-line-tools">6. Command line tools reference</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#ref-indexer">6.1. <code class="filename">indexer</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-searchd">6.2. <code class="filename">searchd</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-search">6.3. <code class="filename">search</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-spelldump">6.4. <code class="filename">spelldump</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-indextool">6.5. <code class="filename">indextool</code> command reference</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#sphinxql-reference">7. SphinxQL reference</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#sphinxql-select">7.1. SELECT syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-meta">7.2. SHOW META syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-warnings">7.3. SHOW WARNINGS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-status">7.4. SHOW STATUS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-insert">7.5. INSERT and REPLACE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-delete">7.6. DELETE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-set">7.7. SET syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-commit">7.8. BEGIN, COMMIT, and ROLLBACK syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-call-snippets">7.9. CALL SNIPPETS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-call-keywords">7.10. CALL KEYWORDS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-tables">7.11. SHOW TABLES syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-describe">7.12. DESCRIBE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-create-function">7.13. CREATE FUNCTION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-drop-function">7.14. DROP FUNCTION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-variables">7.15. SHOW VARIABLES syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-collation">7.16. SHOW COLLATION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-update">7.17. UPDATE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-multi-queries">7.18. Multi-statement queries</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-comment-syntax">7.19. Comment syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-reserved-keywords">7.20. List of SphinxQL reserved keywords</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-upgrading-magics">7.21. SphinxQL upgrade notes, version 2.0.1-beta</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#api-reference">8. API reference</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#api-funcgroup-general">8.1. General API functions</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-getlasterror">8.1.1. GetLastError</a></span></dt>
<dt><span class="sect2"><a href="#api-func-getlastwarning">8.1.2. GetLastWarning</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setserver">8.1.3. SetServer</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setretries">8.1.4. SetRetries</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setconnecttimeout">8.1.5. SetConnectTimeout</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setarrayresult">8.1.6. SetArrayResult</a></span></dt>
<dt><span class="sect2"><a href="#api-func-isconnecterror">8.1.7. IsConnectError</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-general-query-settings">8.2. General query settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setlimits">8.2.1. SetLimits</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setmaxquerytime">8.2.2. SetMaxQueryTime</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setoverride">8.2.3. SetOverride</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setselect">8.2.4. SetSelect</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-fulltext-query-settings">8.3. Full-text search query settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setmatchmode">8.3.1. SetMatchMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setrankingmode">8.3.2. SetRankingMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setsortmode">8.3.3. SetSortMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setweights">8.3.4. SetWeights</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfieldweights">8.3.5. SetFieldWeights</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setindexweights">8.3.6. SetIndexWeights</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-filtering">8.4. Result set filtering settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setidrange">8.4.1. SetIDRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilter">8.4.2. SetFilter</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilterrange">8.4.3. SetFilterRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilterfloatrange">8.4.4. SetFilterFloatRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setgeoanchor">8.4.5. SetGeoAnchor</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-groupby">8.5. GROUP BY settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setgroupby">8.5.1. SetGroupBy</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setgroupdistinct">8.5.2. SetGroupDistinct</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-querying">8.6. Querying</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-query">8.6.1. Query</a></span></dt>
<dt><span class="sect2"><a href="#api-func-addquery">8.6.2. AddQuery</a></span></dt>
<dt><span class="sect2"><a href="#api-func-runqueries">8.6.3. RunQueries</a></span></dt>
<dt><span class="sect2"><a href="#api-func-resetfilters">8.6.4. ResetFilters</a></span></dt>
<dt><span class="sect2"><a href="#api-func-resetgroupby">8.6.5. ResetGroupBy</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-additional-functionality">8.7. Additional functionality</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-buildexcerpts">8.7.1. BuildExcerpts</a></span></dt>
<dt><span class="sect2"><a href="#api-func-updateatttributes">8.7.2. UpdateAttributes</a></span></dt>
<dt><span class="sect2"><a href="#api-func-buildkeywords">8.7.3. BuildKeywords</a></span></dt>
<dt><span class="sect2"><a href="#api-func-escapestring">8.7.4. EscapeString</a></span></dt>
<dt><span class="sect2"><a href="#api-func-status">8.7.5. Status</a></span></dt>
<dt><span class="sect2"><a href="#api-func-flushattributes">8.7.6. FlushAttributes</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-pconn">8.8. Persistent connections</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-open">8.8.1. Open</a></span></dt>
<dt><span class="sect2"><a href="#api-func-close">8.8.2. Close</a></span></dt>
</dl></dd></dl></dd><dt><span class="chapter"><a href="#sphinxse">9. MySQL storage engine (SphinxSE)</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#sphinxse-overview">9.1. SphinxSE overview</a></span></dt>
<dt><span class="sect1"><a href="#sphinxse-installing">9.2. Installing SphinxSE</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#sphinxse-mysql50">9.2.1. Compiling MySQL 5.0.x with SphinxSE</a></span></dt>
<dt><span class="sect2"><a href="#sphinxse-mysql51">9.2.2. Compiling MySQL 5.1.x with SphinxSE</a></span></dt>
<dt><span class="sect2"><a href="#sphinxse-checking">9.2.3. Checking SphinxSE installation</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sphinxse-using">9.3. Using SphinxSE</a></span></dt>
<dt><span class="sect1"><a href="#sphinxse-snippets">9.4. Building snippets (excerpts) via MySQL</a></span></dt>
</dl></dd><dt><span class="chapter"><a href="#reporting-bugs">10. Reporting bugs</a></span></dt>
<dt><span class="chapter"><a href="#conf-reference">11. <code class="filename">sphinx.conf</code> options reference</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#confgroup-source">11.1. Data source configuration options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-source-type">11.1.1. type</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-host">11.1.2. sql_host</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-port">11.1.3. sql_port</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-user">11.1.4. sql_user</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-pass">11.1.5. sql_pass</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-db">11.1.6. sql_db</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-sock">11.1.7. sql_sock</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-connect-flags">11.1.8. mysql_connect_flags</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-ssl">11.1.9. mysql_ssl_cert, mysql_ssl_key, mysql_ssl_ca</a></span></dt>
<dt><span class="sect2"><a href="#conf-odbc-dsn">11.1.10. odbc_dsn</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-pre">11.1.11. sql_query_pre</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query">11.1.12. sql_query</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-joined-field">11.1.13. sql_joined_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-range">11.1.14. sql_query_range</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-range-step">11.1.15. sql_range_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-killlist">11.1.16. sql_query_killlist</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-uint">11.1.17. sql_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-bool">11.1.18. sql_attr_bool</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-bigint">11.1.19. sql_attr_bigint</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-timestamp">11.1.20. sql_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-str2ordinal">11.1.21. sql_attr_str2ordinal</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-float">11.1.22. sql_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-multi">11.1.23. sql_attr_multi</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-string">11.1.24. sql_attr_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-str2wordcount">11.1.25. sql_attr_str2wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-column-buffers">11.1.26. sql_column_buffers</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-field-string">11.1.27. sql_field_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-field-str2wordcount">11.1.28. sql_field_str2wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-file-field">11.1.29. sql_file_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-post">11.1.30. sql_query_post</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-post-index">11.1.31. sql_query_post_index</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-ranged-throttle">11.1.32. sql_ranged_throttle</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-info">11.1.33. sql_query_info</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-command">11.1.34. xmlpipe_command</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field">11.1.35. xmlpipe_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field-string">11.1.36. xmlpipe_field_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field-wordcount">11.1.37. xmlpipe_field_wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-uint">11.1.38. xmlpipe_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-bool">11.1.39. xmlpipe_attr_bool</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-timestamp">11.1.40. xmlpipe_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-str2ordinal">11.1.41. xmlpipe_attr_str2ordinal</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-float">11.1.42. xmlpipe_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-multi">11.1.43. xmlpipe_attr_multi</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-string">11.1.44. xmlpipe_attr_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-fixup-utf8">11.1.45. xmlpipe_fixup_utf8</a></span></dt>
<dt><span class="sect2"><a href="#conf-mssql-winauth">11.1.46. mssql_winauth</a></span></dt>
<dt><span class="sect2"><a href="#conf-mssql-unicode">11.1.47. mssql_unicode</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-zlib">11.1.48. unpack_zlib</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-mysqlcompress">11.1.49. unpack_mysqlcompress</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-mysqlcompress-maxsize">11.1.50. unpack_mysqlcompress_maxsize</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-index">11.2. Index configuration options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-index-type">11.2.1. type</a></span></dt>
<dt><span class="sect2"><a href="#conf-source">11.2.2. source</a></span></dt>
<dt><span class="sect2"><a href="#conf-path">11.2.3. path</a></span></dt>
<dt><span class="sect2"><a href="#conf-docinfo">11.2.4. docinfo</a></span></dt>
<dt><span class="sect2"><a href="#conf-mlock">11.2.5. mlock</a></span></dt>
<dt><span class="sect2"><a href="#conf-morphology">11.2.6. morphology</a></span></dt>
<dt><span class="sect2"><a href="#conf-dict">11.2.7. dict</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-sp">11.2.8. index_sp</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-zones">11.2.9. index_zones</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-stemming-len">11.2.10. min_stemming_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-stopwords">11.2.11. stopwords</a></span></dt>
<dt><span class="sect2"><a href="#conf-wordforms">11.2.12. wordforms</a></span></dt>
<dt><span class="sect2"><a href="#conf-exceptions">11.2.13. exceptions</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-word-len">11.2.14. min_word_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-charset-type">11.2.15. charset_type</a></span></dt>
<dt><span class="sect2"><a href="#conf-charset-table">11.2.16. charset_table</a></span></dt>
<dt><span class="sect2"><a href="#conf-ignore-chars">11.2.17. ignore_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-prefix-len">11.2.18. min_prefix_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-infix-len">11.2.19. min_infix_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-prefix-fields">11.2.20. prefix_fields</a></span></dt>
<dt><span class="sect2"><a href="#conf-infix-fields">11.2.21. infix_fields</a></span></dt>
<dt><span class="sect2"><a href="#conf-enable-star">11.2.22. enable_star</a></span></dt>
<dt><span class="sect2"><a href="#conf-ngram-len">11.2.23. ngram_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-ngram-chars">11.2.24. ngram_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-phrase-boundary">11.2.25. phrase_boundary</a></span></dt>
<dt><span class="sect2"><a href="#conf-phrase-boundary-step">11.2.26. phrase_boundary_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-strip">11.2.27. html_strip</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-index-attrs">11.2.28. html_index_attrs</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-remove-elements">11.2.29. html_remove_elements</a></span></dt>
<dt><span class="sect2"><a href="#conf-local">11.2.30. local</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent">11.2.31. agent</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-blackhole">11.2.32. agent_blackhole</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-connect-timeout">11.2.33. agent_connect_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-query-timeout">11.2.34. agent_query_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-preopen">11.2.35. preopen</a></span></dt>
<dt><span class="sect2"><a href="#conf-ondisk-dict">11.2.36. ondisk_dict</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-enable">11.2.37. inplace_enable</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-hit-gap">11.2.38. inplace_hit_gap</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-docinfo-gap">11.2.39. inplace_docinfo_gap</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-reloc-factor">11.2.40. inplace_reloc_factor</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-write-factor">11.2.41. inplace_write_factor</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-exact-words">11.2.42. index_exact_words</a></span></dt>
<dt><span class="sect2"><a href="#conf-overshort-step">11.2.43. overshort_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-stopword-step">11.2.44. stopword_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-hitless-words">11.2.45. hitless_words</a></span></dt>
<dt><span class="sect2"><a href="#conf-expand-keywords">11.2.46. expand_keywords</a></span></dt>
<dt><span class="sect2"><a href="#conf-blend-chars">11.2.47. blend_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-blend-mode">11.2.48. blend_mode</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-mem-limit">11.2.49. rt_mem_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-field">11.2.50. rt_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-uint">11.2.51. rt_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-bigint">11.2.52. rt_attr_bigint</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-float">11.2.53. rt_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-timestamp">11.2.54. rt_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-string">11.2.55. rt_attr_string</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-indexer">11.3. <code class="filename">indexer</code> program configuration
      options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-mem-limit">11.3.1. mem_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-iops">11.3.2. max_iops</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-iosize">11.3.3. max_iosize</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-xmlpipe2-field">11.3.4. max_xmlpipe2_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-write-buffer">11.3.5. write_buffer</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-file-field-buffer">11.3.6. max_file_field_buffer</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-searchd">11.4. <code class="filename">searchd</code> program configuration
      options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-listen">11.4.1. listen</a></span></dt>
<dt><span class="sect2"><a href="#conf-address">11.4.2. address</a></span></dt>
<dt><span class="sect2"><a href="#conf-port">11.4.3. port</a></span></dt>
<dt><span class="sect2"><a href="#conf-log">11.4.4. log</a></span></dt>
<dt><span class="sect2"><a href="#conf-query-log">11.4.5. query_log</a></span></dt>
<dt><span class="sect2"><a href="#conf-query-log-format">11.4.6. query_log_format</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-timeout">11.4.7. read_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-client-timeout">11.4.8. client_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-children">11.4.9. max_children</a></span></dt>
<dt><span class="sect2"><a href="#conf-pid-file">11.4.10. pid_file</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-matches">11.4.11. max_matches</a></span></dt>
<dt><span class="sect2"><a href="#conf-seamless-rotate">11.4.12. seamless_rotate</a></span></dt>
<dt><span class="sect2"><a href="#conf-preopen-indexes">11.4.13. preopen_indexes</a></span></dt>
<dt><span class="sect2"><a href="#conf-unlink-old">11.4.14. unlink_old</a></span></dt>
<dt><span class="sect2"><a href="#conf-attr-flush-period">11.4.15. attr_flush_period</a></span></dt>
<dt><span class="sect2"><a href="#conf-ondisk-dict-default">11.4.16. ondisk_dict_default</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-packet-size">11.4.17. max_packet_size</a></span></dt>
<dt><span class="sect2"><a href="#conf-mva-updates-pool">11.4.18. mva_updates_pool</a></span></dt>
<dt><span class="sect2"><a href="#conf-crash-log-path">11.4.19. crash_log_path</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-filters">11.4.20. max_filters</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-filter-values">11.4.21. max_filter_values</a></span></dt>
<dt><span class="sect2"><a href="#conf-listen-backlog">11.4.22. listen_backlog</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-buffer">11.4.23. read_buffer</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-unhinted">11.4.24. read_unhinted</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-batch-queries">11.4.25. max_batch_queries</a></span></dt>
<dt><span class="sect2"><a href="#conf-subtree-docs-cache">11.4.26. subtree_docs_cache</a></span></dt>
<dt><span class="sect2"><a href="#conf-subtree-hits-cache">11.4.27. subtree_hits_cache</a></span></dt>
<dt><span class="sect2"><a href="#conf-workers">11.4.28. workers</a></span></dt>
<dt><span class="sect2"><a href="#conf-dist-threads">11.4.29. dist_threads</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-path">11.4.30. binlog_path</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-flush">11.4.31. binlog_flush</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-max-log-size">11.4.32. binlog_max_log_size</a></span></dt>
<dt><span class="sect2"><a href="#conf-collation-server">11.4.33. collation_server</a></span></dt>
<dt><span class="sect2"><a href="#conf-collation-libc-locale">11.4.34. collation_libc_locale</a></span></dt>
<dt><span class="sect2"><a href="#conf-plugin-dir">11.4.35. plugin_dir</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-version-string">11.4.36. mysql_version_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-flush-period">11.4.37. rt_flush_period</a></span></dt>
<dt><span class="sect2"><a href="#conf-thread-stack">11.4.38. thread_stack</a></span></dt>
<dt><span class="sect2"><a href="#conf-expansion-limit">11.4.39. expansion_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-compat-sphinxql-magics">11.4.40. compat_sphinxql_magics</a></span></dt>
<dt><span class="sect2"><a href="#conf-watchdog">11.4.41. watchdog</a></span></dt>
</dl></dd></dl></dd><dt><span class="appendix"><a href="#changelog">A. Sphinx revision history</a></span></dt>
<dd><dl><dt><span class="sect1"><a href="#rel111">A.1. Version 2.0.1-beta, 22 apr 2011</a></span></dt>
<dt><span class="sect1"><a href="#rel110">A.2. Version 1.10-beta, 19 jul 2010</a></span></dt>
<dt><span class="sect1"><a href="#rel099">A.3. Version 0.9.9-release, 02 dec 2009</a></span></dt>
<dt><span class="sect1"><a href="#rel099rc2">A.4. Version 0.9.9-rc2, 08 apr 2009</a></span></dt>
<dt><span class="sect1"><a href="#rel099rc1">A.5. Version 0.9.9-rc1, 17 nov 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel0981">A.6. Version 0.9.8.1, 30 oct 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel098">A.7. Version 0.9.8, 14 jul 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel097">A.8. Version 0.9.7, 02 apr 2007</a></span></dt>
<dt><span class="sect1"><a href="#rel097rc2">A.9. Version 0.9.7-rc2, 15 dec 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel097rc">A.10. Version 0.9.7-rc1, 26 oct 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel096">A.11. Version 0.9.6, 24 jul 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel096rc1">A.12. Version 0.9.6-rc1, 26 jun 2006</a></span></dt>
</dl></dd></dl></div>
<div class="list-of-examples"><p><b>List of Examples</b></p><dl><dt>3.1. <a href="#ex-ranged-queries">Ranged query usage example</a></dt>
<dt>3.2. <a href="#ex-xmlpipe-document">XMLpipe document stream</a></dt>
<dt>3.3. <a href="#ex-xmlpipe2-document">xmlpipe2 document stream</a></dt>
<dt>3.4. <a href="#ex-live-updates">Fully automated live updates</a></dt>
<dt>4.1. <a href="#ex-rt-updates">RT index declaration</a></dt>
<dt>5.1. <a href="#ex-boolean-query">Boolean query example</a></dt>
<dt>5.2. <a href="#ex-extended-query">Extended matching mode: query example</a></dt>
</dl></div>
<div class="chapter" title="Chapter&nbsp;1.&nbsp;Introduction"><div class="titlepage"><div><div><h2 class="title"><a name="intro"></a>Chapter&nbsp;1.&nbsp;Introduction</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#about">1.1. About</a></span></dt>
<dt><span class="sect1"><a href="#features">1.2. Sphinx features</a></span></dt>
<dt><span class="sect1"><a href="#getting">1.3. Where to get Sphinx</a></span></dt>
<dt><span class="sect1"><a href="#license">1.4. License</a></span></dt>
<dt><span class="sect1"><a href="#credits">1.5. Credits</a></span></dt>
<dt><span class="sect1"><a href="#history">1.6. History</a></span></dt>
</dl></div>
<div class="sect1" title="1.1.&nbsp;About"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="about"></a>1.1.&nbsp;About</h2></div></div></div>
<p>Sphinx is a full-text search engine, publicly distributed under
      GPL version 2. Commercial licensing (eg. for embedded use) is available
      upon request.</p><p>Technically, Sphinx is a standalone software package provides fast
      and relevant full-text search functionality to client applications. It
      was specially designed to integrate well with SQL databases storing the
      data, and to be easily accessed scripting languages. However, Sphinx
      does not depend on nor require any specific database to function.</p><p>Applications can access Sphinx search daemon (searchd) using any
      of the three different access methods: a) via native search API
      (SphinxAPI), b) via Sphinx own implementation of MySQL network protocol
      (using a small SQL subset called SphinxQL), or c) via MySQL server with
      a pluggable storage engine (SphinxSE).</p><p>Official native SphinxAPI implementations for PHP, Perl, Ruby, and
      Java are included within the distribution package. API is very
      lightweight so porting it to a new language is known to take a few hours
      or days. Third party API ports and plugins exist for Perl, C#, Haskell,
      Ruby-on-Rails, and possibly other languages and frameworks.</p><p>Starting version 1.10-beta, Sphinx supports two different indexing
      backends: "disk" index backend, and "realtime" (RT) index backend. Disk
      indexes support online full-text index rebuilds, but online updates can
      only be done on non-text (attribute) data. RT indexes additionally allow
      for online full-text index updates. Previous versions only supported
      disk indexes.</p><p>Data can be loaded into disk indexes using a so-called data
      source. Built-in sources can fetch data directly from MySQL, PostgreSQL,
      ODBC compliant database (MS SQL, Oracle, etc), or a pipe in a custom XML
      format. Adding new data sources drivers (eg. to natively support other
      DBMSes) is designed to be as easy as possible. RT indexes, as of
      1.10-beta, can only be populated using SphinxQL.</p><p>As for the name, Sphinx is an acronym which is officially decoded
      as SQL Phrase Index. Yes, I know about CMU's Sphinx project.</p></div>
<div class="sect1" title="1.2.&nbsp;Sphinx features"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="features"></a>1.2.&nbsp;Sphinx features</h2></div></div></div>
<p>Key Sphinx features are:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>high indexing and searching performance;</p></li>
<li class="listitem"><p>advanced indexing and querying tools (flexible and
          feature-rich text tokenizer, querying language, several different
          ranking modes, etc);</p></li>
<li class="listitem"><p>advanced result set post-processing (SELECT with expressions,
          WHERE, ORDER BY, GROUP BY etc over text search results);</p></li>
<li class="listitem"><p>proven scalability up to billions of documents, terabytes of
          data, and thousands of queries per second;</p></li>
<li class="listitem"><p>easy integration with SQL and XML data sources, and SphinxAPI,
          SphinxQL, or SphinxSE search interfaces;</p></li>
<li class="listitem"><p>easy scaling with distributed searches.</p></li>
</ul></div>
<p>To expand a bit, Sphinx:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>has high indexing speed (upto 10-15 MB/sec per core on an
          internal benchmark);</p></li>
<li class="listitem"><p>has high search speed (upto 150-250 queries/sec per core
          against 1,000,000 documents, 1.2 GB of data on an internal
          benchmark);</p></li>
<li class="listitem"><p>has high scalability (biggest known cluster indexes over
          3,000,000,000 documents, and busiest one peaks over 50,000,000
          queries/day);</p></li>
<li class="listitem"><p>provides good relevance ranking through combination of phrase
          proximity ranking and statistical (BM25) ranking;</p></li>
<li class="listitem"><p>provides distributed searching capabilities;</p></li>
<li class="listitem"><p>provides document excerpts (snippets) generation;</p></li>
<li class="listitem"><p>provides searching from within application with SphinxAPI or
          SphinxQL interfaces, and from within MySQL with pluggable SphinxSE
          storage engine;</p></li>
<li class="listitem"><p>supports boolean, phrase, word proximity and other types of
          queries;</p></li>
<li class="listitem"><p>supports multiple full-text fields per document (upto 32 by
          default);</p></li>
<li class="listitem"><p>supports multiple additional attributes per document (ie.
          groups, timestamps, etc);</p></li>
<li class="listitem"><p>supports stopwords;</p></li>
<li class="listitem"><p>supports morphological word forms dictionaries;</p></li>
<li class="listitem"><p>supports tokenizing exceptions;</p></li>
<li class="listitem"><p>supports both single-byte encodings and UTF-8;</p></li>
<li class="listitem"><p>supports stemming (stemmers for English, Russian and Czech are
          built-in; and stemmers for French, Spanish, Portuguese, Italian,
          Romanian, German, Dutch, Swedish, Norwegian, Danish, Finnish,
          Hungarian, are available by building third party <a class="ulink" href="http://snowball.tartarus.org/" target="_top">libstemmer
          library</a>);</p></li>
<li class="listitem"><p>supports MySQL natively (all types of tables, including
          MyISAM, InnoDB, NDB, Archive, etc are supported);</p></li>
<li class="listitem"><p>supports PostgreSQL natively;</p></li>
<li class="listitem"><p>supports ODBC compliant databases (MS SQL, Oracle, etc)
          natively;</p></li>
<li class="listitem"><p>...has 50+ other features not listed here, refer to API and
          configuration manual!</p></li>
</ul></div></div>
<div class="sect1" title="1.3.&nbsp;Where to get Sphinx"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="getting"></a>1.3.&nbsp;Where to get Sphinx</h2></div></div></div>
<p>Sphinx is available through its official Web site at <a class="ulink" href="http://sphinxsearch.com/" target="_top">http://sphinxsearch.com/</a>.</p><p>Currently, Sphinx distribution tarball includes the following
      software: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="filename">indexer</code>: an utility which creates
            fulltext indexes;</p></li>
<li class="listitem"><p><code class="filename">search</code>: a simple command-line (CLI)
            test utility which searches through fulltext indexes;</p></li>
<li class="listitem"><p><code class="filename">searchd</code>: a daemon which enables
            external software (eg. Web applications) to search through
            fulltext indexes;</p></li>
<li class="listitem"><p><code class="filename">sphinxapi</code>: a set of searchd client API
            libraries for popular Web scripting languages (PHP, Python, Perl,
            Ruby).</p></li>
<li class="listitem"><p><code class="filename">spelldump</code>: a simple command-line tool
            to extract the items from an <code class="filename">ispell</code> or
            <code class="filename">MySpell</code> (as bundled with OpenOffice) format
            dictionary to help customize your index, for use with <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a>.</p></li>
<li class="listitem"><p><code class="filename">indextool</code>: an utility to dump
            miscellaneous debug information about the index, added in version
            0.9.9-rc2.</p></li>
</ul></div></div>
<div class="sect1" title="1.4.&nbsp;License"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="license"></a>1.4.&nbsp;License</h2></div></div></div>
<p>This program is free software; you can redistribute it and/or
      modify it under the terms of the GNU General Public License as published
      by the Free Software Foundation; either version 2 of the License, or (at
      your option) any later version. See COPYING file for details.</p><p>This program is distributed in the hope that it will be useful,
      but WITHOUT ANY WARRANTY; without even the implied warranty of
      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General
      Public License for more details.</p><p>You should have received a copy of the GNU General Public License
      along with this program; if not, write to the Free Software Foundation,
      Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA</p><p>Non-GPL licensing (for OEM/ISV embedded use) can also be arranged,
      please <a class="ulink" href="http://sphinxsearch.com/contacts.html" target="_top">contact
      us</a> to discuss commercial licensing possibilities.</p></div>
<div class="sect1" title="1.5.&nbsp;Credits"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="credits"></a>1.5.&nbsp;Credits</h2></div></div></div>
<h3>Author</h3><p>Sphinx initial author (and a benevolent dictator ever since):
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Andrew Aksyonoff, <a class="ulink" href="http://shodan.ru" target="_top">http://shodan.ru</a></p></li>
</ul></div>
<h3>Team</h3><p>Past and present employees of Sphinx Technologies Inc who should
      be noted on their work on Sphinx (in alphabetical order): </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Alexander Klimenko</p></li>
<li class="listitem"><p>Alexey Dvoichenkov</p></li>
<li class="listitem"><p>Alexey Vinogradov</p></li>
<li class="listitem"><p>Ilya Kuznetsov</p></li>
<li class="listitem"><p>Stanislav Klinov</p></li>
</ul></div>
<h3>Contributors</h3><p>People who contributed to Sphinx and their contributions (in no
      particular order): </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Robert "coredev" Bengtsson (Sweden), initial version of
            PostgreSQL data source</p></li>
<li class="listitem"><p>Len Kranendonk, Perl API</p></li>
<li class="listitem"><p>Dmytro Shteflyuk, Ruby API</p></li>
</ul></div>
<p>Many other people have contributed ideas, bug reports, fixes, etc.
      Thank you!</p></div>
<div class="sect1" title="1.6.&nbsp;History"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="history"></a>1.6.&nbsp;History</h2></div></div></div>
<p>Sphinx development was started back in 2001, because I didn't
      manage to find an acceptable search solution (for a database driven Web
      site) which would meet my requirements. Actually, each and every
      important aspect was a problem: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>search quality (ie. good relevance) </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>statistical ranking methods performed rather bad,
                  especially on large collections of small documents (forums,
                  blogs, etc)</p></li>
</ul></div></li>
<li class="listitem"><p>search speed </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>especially if searching for phrases which contain
                  stopwords, as in "to be or not to be"</p></li>
</ul></div></li>
<li class="listitem"><p>moderate disk and CPU requirements when indexing
            </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>important in shared hosting enivronment, not to
                  mention the indexing speed.</p></li>
</ul></div></li>
</ul></div>
<p>Despite the amount of time passed and numerous improvements made
      in the other solutions, there's still no solution which I personally
      would be eager to migrate to.</p><p>Considering that and a lot of positive feedback received from
      Sphinx users during last years, the obvious decision is to continue
      developing Sphinx (and, eventually, to take over the world).</p></div></div>
<div class="chapter" title="Chapter&nbsp;2.&nbsp;Installation"><div class="titlepage"><div><div><h2 class="title"><a name="installation"></a>Chapter&nbsp;2.&nbsp;Installation</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#supported-system">2.1. Supported systems</a></span></dt>
<dt><span class="sect1"><a href="#required-tools">2.2. Required tools</a></span></dt>
<dt><span class="sect1"><a href="#installing">2.3. Installing Sphinx on Linux</a></span></dt>
<dt><span class="sect1"><a href="#installing-windows">2.4. Installing Sphinx on Windows</a></span></dt>
<dt><span class="sect1"><a href="#install-problems">2.5. Known installation issues</a></span></dt>
<dt><span class="sect1"><a href="#quick-tour">2.6. Quick Sphinx usage tour</a></span></dt>
</dl></div>
<div class="sect1" title="2.1.&nbsp;Supported systems"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="supported-system"></a>2.1.&nbsp;Supported systems</h2></div></div></div>
<p>Most modern UNIX systems with a C++ compiler should be able to
      compile and run Sphinx without any modifications.</p><p>Currently known systems Sphinx has been successfully running on
      are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Linux 2.4.x, 2.6.x (many various distributions)</p></li>
<li class="listitem"><p>Windows 2000, XP</p></li>
<li class="listitem"><p>FreeBSD 4.x, 5.x, 6.x, 7.x</p></li>
<li class="listitem"><p>NetBSD 1.6, 3.0</p></li>
<li class="listitem"><p>Solaris 9, 11</p></li>
<li class="listitem"><p>Mac OS X</p></li>
</ul></div>
<p>CPU architectures known to work include X86, X86-64, SPARC64,
      ARM.</p><p>Chance are good that Sphinx should work on other Unix platforms as
      well; please report any platforms missing from this list that worked for
      you!</p></div>
<div class="sect1" title="2.2.&nbsp;Required tools"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="required-tools"></a>2.2.&nbsp;Required tools</h2></div></div></div>
<p>On UNIX, you will need the following tools to build and install
      Sphinx: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>a working C++ compiler. GNU gcc is known to work.</p></li>
<li class="listitem"><p>a good make program. GNU make is known to work.</p></li>
</ul></div>
<p>On Windows, you will need Microsoft Visual C/C++ Studio .NET 2003
      or 2005. Other compilers/environments will probably work as well, but
      for the time being, you will have to build makefile (or other
      environment specific project files) manually.</p></div>
<div class="sect1" title="2.3.&nbsp;Installing Sphinx on Linux"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="installing"></a>2.3.&nbsp;Installing Sphinx on Linux</h2></div></div></div>
<div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Extract everything from the distribution tarball (haven't
            you already?) and go to the <code class="filename">sphinx</code>
            subdirectory. (We are using version 2.0.1-beta here for the sake
            of example only; be sure to change this to a specific version
            you're using.)</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;tar&nbsp;xzvf&nbsp;sphinx-2.0.1-beta.tar.gz<br>
$&nbsp;cd&nbsp;sphinx<br>
</code></strong></p></div></li>
<li class="listitem"><p>Run the configuration program:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;./configure</code></strong></p></div>
<p>There's a number of options to configure. The complete
            listing may be obtained by using <code class="option">--help</code> switch.
            The most important ones are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--prefix</code>, which specifies where to
                  install Sphinx; such as
                  <code class="option">--prefix=/usr/local/sphinx</code> (all of the
                  examples use this prefix)</p></li>
<li class="listitem"><p><code class="option">--with-mysql</code>, which specifies where
                  to look for MySQL include and library files, if
                  auto-detection fails;</p></li>
<li class="listitem"><p><code class="option">--with-pgsql</code>, which specifies where
                  to look for PostgreSQL include and library files.</p></li>
</ul></div></li>
<li class="listitem"><p>Build the binaries:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;make</code></strong></p></div></li>
<li class="listitem"><p>Install the binaries in the directory of your choice:
            (defaults to <code class="filename">/usr/local/bin/</code> on *nix systems,
            but is overridden with <code class="option">configure --prefix</code>)</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;make&nbsp;install</code></strong></p></div></li>
</ol></div></div>
<div class="sect1" title="2.4.&nbsp;Installing Sphinx on Windows"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="installing-windows"></a>2.4.&nbsp;Installing Sphinx on Windows</h2></div></div></div>
<p>Installing Sphinx on a Windows server is often easier than
      installing on a Linux environment; unless you are preparing code
      patches, you can use the pre-compiled binary files from the Downloads
      area on the website.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Extract everything from the .zip file you have downloaded -
          <code class="filename">sphinx-2.0.1-beta-win32.zip</code>, or
          <code class="filename">sphinx-2.0.1-beta-win32-pgsql.zip</code> if you need
          PostgresSQL support as well. (We are using version 2.0.1-beta here
          for the sake of example only; be sure to change this to a specific
          version you're using.) You can use Windows Explorer in Windows XP
          and up to extract the files, or a freeware package like 7Zip to open
          the archive.</p><p>For the remainder of this guide, we will assume that the
          folders are unzipped into <code class="filename">C:\Sphinx</code>, such that
          <code class="filename">searchd.exe</code> can be found in
          <code class="filename">C:\Sphinx\bin\searchd.exe</code>. If you decide to use
          any different location for the folders or configuration file, please
          change it accordingly.</p></li>
<li class="listitem"><p>Edit the contents of sphinx.conf.in - specifically entries
          relating to @CONFDIR@ - to paths suitable for your system.</p></li>
<li class="listitem"><p>Install the <code class="filename">searchd</code> system as a Windows
          service:</p><div class="literallayout"><p><strong class="userinput"><code>C:\Sphinx\bin&gt;&nbsp;C:\Sphinx\bin\searchd&nbsp;--install&nbsp;--config<br>
C:\Sphinx\sphinx.conf.in&nbsp;--servicename&nbsp;SphinxSearch</code></strong></p></div></li>
<li class="listitem"><p>The <code class="filename">searchd</code> service will now be listed in
          the Services panel within the Management Console, available from
          Administrative Tools. It will not have been started, as you will
          need to configure it and build your indexes with
          <code class="filename">indexer</code> before starting the service. A guide to
          do this can be found under <a class="link" href="#quick-tour" title="2.6.&nbsp;Quick Sphinx usage tour">Quick
          tour</a>.</p><p>During the next steps of the install (which involve running
          indexer pretty much as you would on Linux) you may find that you get
          an error relating to libmysql.dll not being found. If you have MySQL
          installed, you should find a copy of this library in your Windows
          directory, or sometimes in Windows\System32, or failing that in the
          MySQL core directories. If you do receive an error please copy
          libmysql.dll into the bin directory.</p></li>
</ol></div></div>
<div class="sect1" title="2.5.&nbsp;Known installation issues"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="install-problems"></a>2.5.&nbsp;Known installation issues</h2></div></div></div>
<p>If <code class="filename">configure</code> fails to locate MySQL headers
      and/or libraries, try checking for and installing
      <code class="filename">mysql-devel</code> package. On some systems, it is not
      installed by default.</p><p>If <code class="filename">make</code> fails with a message which look like
      </p><pre class="programlisting">/bin/sh: g++: command not found
make[1]: *** [libsphinx_a-sphinx.o] Error 127
</pre><p> try checking for and installing <code class="filename">gcc-c++</code>
      package.</p><p>If you are getting compile-time errors which look like
      </p><pre class="programlisting">sphinx.cpp:67: error: invalid application of `sizeof' to
    incomplete type `Private::SizeError&lt;false&gt;'
</pre><p> this means that some compile-time type size check failed.
      The most probable reason is that off_t type is less than 64-bit on your
      system. As a quick hack, you can edit sphinx.h and replace off_t with
      DWORD in a typedef for SphOffset_t, but note that this will prohibit you
      from using full-text indexes larger than 2 GB. Even if the hack helps,
      please report such issues, providing the exact error message and
      compiler/OS details, so I could properly fix them in next
      releases.</p><p>If you keep getting any other error, or the suggestions above do
      not seem to help you, please don't hesitate to contact me.</p></div>
<div class="sect1" title="2.6.&nbsp;Quick Sphinx usage tour"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="quick-tour"></a>2.6.&nbsp;Quick Sphinx usage tour</h2></div></div></div>
<p>All the example commands below assume that you installed Sphinx in
      <code class="filename">/usr/local/sphinx</code>, so <code class="filename">searchd</code>
      can be found in
      <code class="filename">/usr/local/sphinx/bin/searchd</code>.</p><p>To use Sphinx, you will need to:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Create a configuration file.</p><p>Default configuration file name is
          <code class="filename">sphinx.conf</code>. All Sphinx programs look for this
          file in current working directory by default.</p><p>Sample configuration file,
          <code class="filename">sphinx.conf.dist</code>, which has all the options
          documented, is created by <code class="filename">configure</code>. Copy and
          edit that sample file to make your own configuration: (assuming
          Sphinx is installed into
          <code class="filename">/usr/local/sphinx/</code>)</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;cp&nbsp;sphinx.conf.dist&nbsp;sphinx.conf<br>
$&nbsp;vi&nbsp;sphinx.conf</code></strong></p></div>
<p>Sample configuration file is setup to index
          <code class="filename">documents</code> table from MySQL database
          <code class="filename">test</code>; so there's
          <code class="filename">example.sql</code> sample data file to populate that
          table with a few documents for testing purposes:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;mysql&nbsp;-u&nbsp;test&nbsp;&lt;&nbsp;/usr/local/sphinx/etc/example.sql</code></strong></p></div></li>
<li class="listitem"><p>Run the indexer to create full-text index from your
          data:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/indexer&nbsp;--all</code></strong></p></div></li>
<li class="listitem"><p>Query your newly created index!</p></li>
</ol></div>
<p>To query the index from command line, use
      <code class="filename">search</code> utility:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/search&nbsp;test</code></strong></p></div>
<p>To query the index from your PHP scripts, you need to:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Run the search daemon which your script will talk to:</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;cd&nbsp;/usr/local/sphinx/etc<br>
$&nbsp;/usr/local/sphinx/bin/searchd</code></strong></p></div></li>
<li class="listitem"><p>Run the attached PHP API test script (to ensure that the
          daemon was succesfully started and is ready to serve the
          queries):</p><div class="literallayout"><p><strong class="userinput"><code>$&nbsp;cd&nbsp;sphinx/api<br>
$&nbsp;php&nbsp;test.php&nbsp;test</code></strong></p></div></li>
<li class="listitem"><p>Include the API (it's located in
          <code class="filename">api/sphinxapi.php</code>) into your own scripts and
          use it.</p></li>
</ol></div>
<p>Happy searching!</p></div></div>
<div class="chapter" title="Chapter&nbsp;3.&nbsp;Indexing"><div class="titlepage"><div><div><h2 class="title"><a name="indexing"></a>Chapter&nbsp;3.&nbsp;Indexing</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#sources">3.1. Data sources</a></span></dt>
<dt><span class="sect1"><a href="#attributes">3.2. Attributes</a></span></dt>
<dt><span class="sect1"><a href="#mva">3.3. MVA (multi-valued attributes)</a></span></dt>
<dt><span class="sect1"><a href="#indexes">3.4. Indexes</a></span></dt>
<dt><span class="sect1"><a href="#data-restrictions">3.5. Restrictions on the source data</a></span></dt>
<dt><span class="sect1"><a href="#charsets">3.6. Charsets, case folding, and translation tables</a></span></dt>
<dt><span class="sect1"><a href="#sql">3.7. SQL data sources (MySQL, PostgreSQL)</a></span></dt>
<dt><span class="sect1"><a href="#xmlpipe">3.8. xmlpipe data source</a></span></dt>
<dt><span class="sect1"><a href="#xmlpipe2">3.9. xmlpipe2 data source</a></span></dt>
<dt><span class="sect1"><a href="#live-updates">3.10. Live index updates</a></span></dt>
<dt><span class="sect1"><a href="#delta-updates">3.11. Delta index updates</a></span></dt>
<dt><span class="sect1"><a href="#index-merging">3.12. Index merging</a></span></dt>
</dl></div>
<div class="sect1" title="3.1.&nbsp;Data sources"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sources"></a>3.1.&nbsp;Data sources</h2></div></div></div>
<p>The data to be indexed can generally come from very different
      sources: SQL databases, plain text files, HTML files, mailboxes, and so
      on. From Sphinx point of view, the data it indexes is a set of
      structured <em class="glossterm">documents</em>, each of which has the same
      set of <em class="glossterm">fields</em>. This is biased towards SQL, where
      each row correspond to a document, and each column to a field.</p><p>Depending on what source Sphinx should get the data from,
      different code is required to fetch the data and prepare it for
      indexing. This code is called <em class="glossterm">data source driver</em>
      (or simply <em class="glossterm">driver</em> or <em class="glossterm">data
      source</em> for brevity).</p><p>At the time of this writing, there are drivers for MySQL and
      PostgreSQL databases, which can connect to the database using its native
      C/C++ API, run queries and fetch the data. There's also a driver called
      xmlpipe, which runs a specified command and reads the data from its
      <code class="filename">stdout</code>. See <a class="xref" href="#xmlpipe" title="3.8.&nbsp;xmlpipe data source">Section&nbsp;3.8, “xmlpipe data source”</a> section for
      the format description.</p><p>There can be as many sources per index as necessary. They will be
      sequentially processed in the very same order which was specifed in
      index definition. All the documents coming from those sources will be
      merged as if they were coming from a single source.</p></div>
<div class="sect1" title="3.2.&nbsp;Attributes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="attributes"></a>3.2.&nbsp;Attributes</h2></div></div></div>
<p>Attributes are additional values associated with each document
      that can be used to perform additional filtering and sorting during
      search.</p><p>It is often desired to additionally process full-text search
      results based not only on matching document ID and its rank, but on a
      number of other per-document values as well. For instance, one might
      need to sort news search results by date and then relevance, or search
      through products within specified price range, or limit blog search to
      posts made by selected users, or group results by month. To do that
      efficiently, Sphinx allows to attach a number of additional
      <em class="glossterm">attributes</em> to each document, and store their
      values in the full-text index. It's then possible to use stored values
      to filter, sort, or group full-text matches.</p><p>Attributes, unlike the fields, are not full-text indexed. They are
      stored in the index, but it is not possible to search them as full-text,
      and attempting to do so results in an error.</p><p>For example, it is impossible to use the extended matching mode
      expression <code class="option">@column 1</code> to match documents where column is
      1, if column is an attribute, and this is still true even if the numeric
      digits are normally indexed.</p><p>Attributes can be used for filtering, though, to restrict returned
      rows, as well as sorting or <a class="link" href="#clustering" title="5.7.&nbsp;Grouping (clustering) search results">result
      grouping</a>; it is entirely possible to sort results purely based on
      attributes, and ignore the search relevance tools. Additionally,
      attributes are returned from the search daemon, while the indexed text
      is not.</p><p>A good example for attributes would be a forum posts table. Assume
      that only title and content fields need to be full-text searchable - but
      that sometimes it is also required to limit search to a certain author
      or a sub-forum (ie. search only those rows that have some specific
      values of author_id or forum_id columns in the SQL table); or to sort
      matches by post_date column; or to group matching posts by month of the
      post_date and calculate per-group match counts.</p><p>This can be achieved by specifying all the mentioned columns
      (excluding title and content, that are full-text fields) as attributes,
      indexing them, and then using API calls to setup filtering, sorting, and
      grouping. Here as an example.</p><h3>Example sphinx.conf part:</h3><pre class="programlisting">...
sql_query = SELECT id, title, content, \
	author_id, forum_id, post_date FROM my_forum_posts
sql_attr_uint = author_id
sql_attr_uint = forum_id
sql_attr_timestamp = post_date
...
</pre><h3>Example application code (in PHP):</h3><pre class="programlisting">// only search posts by author whose ID is 123
$cl-&gt;SetFilter ( "author_id", array ( 123 ) );

// only search posts in sub-forums 1, 3 and 7
$cl-&gt;SetFilter ( "forum_id", array ( 1,3,7 ) );

// sort found posts by posting date in descending order
$cl-&gt;SetSortMode ( SPH_SORT_ATTR_DESC, "post_date" );
</pre><p>Attributes are named. Attribute names are case insensitive.
      Attributes are <span class="emphasis"><em>not</em></span> full-text indexed; they are
      stored in the index as is. Currently supported attribute types are:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>unsigned integers (1-bit to 32-bit wide);</p></li>
<li class="listitem"><p>UNIX timestamps;</p></li>
<li class="listitem"><p>floating point values (32-bit, IEEE 754 single
            precision);</p></li>
<li class="listitem"><p>string ordinals (specially computed integers);</p></li>
<li class="listitem"><p><a class="link" href="#conf-sql-attr-string" title="11.1.24.&nbsp;sql_attr_string">strings</a> (since
            1.10-beta);</p></li>
<li class="listitem"><p><a class="link" href="#mva" title="3.3.&nbsp;MVA (multi-valued attributes)">MVA</a>, multi-value attributes
            (variable-length lists of 32-bit unsigned integers).</p></li>
</ul></div>
<p>The complete set of per-document attribute values is sometimes
      referred to as <em class="glossterm">docinfo</em>. Docinfos can either be
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>stored separately from the main full-text index data
            ("extern" storage, in <code class="filename">.spa</code> file), or</p></li>
<li class="listitem"><p>attached to each occurence of document ID in full-text index
            data ("inline" storage, in <code class="filename">.spd</code> file).</p></li>
</ul></div>
<p>When using extern storage, a copy of <code class="filename">.spa</code>
      file (with all the attribute values for all the documents) is kept in
      RAM by <code class="filename">searchd</code> at all times. This is for
      performance reasons; random disk I/O would be too slow. On the contrary,
      inline storage does not require any additional RAM at all, but that
      comes at the cost of greatly inflating the index size: remember that it
      copies <span class="emphasis"><em>all</em></span> attribute value
      <span class="emphasis"><em>every</em></span> time when the document ID is mentioned, and
      that is exactly as many times as there are different keywords in the
      document. Inline may be the only viable option if you have only a few
      attributes and need to work with big datasets in limited RAM. However,
      in most cases extern storage makes both indexing and searching
      <span class="emphasis"><em>much</em></span> more efficient.</p><p>Search-time memory requirements for extern storage are
      (1+number_of_attrs)*number_of_docs*4 bytes, ie. 10 million docs with 2
      groups and 1 timestamp will take (1+2+1)*10M*4 = 160 MB of RAM. This is
      <span class="emphasis"><em>PER DAEMON</em></span>, not per query.
      <code class="filename">searchd</code> will allocate 160 MB on startup, read the
      data and keep it shared between queries. The children will
      <span class="emphasis"><em>NOT</em></span> allocate any additional copies of this
      data.</p></div>
<div class="sect1" title="3.3.&nbsp;MVA (multi-valued attributes)"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mva"></a>3.3.&nbsp;MVA (multi-valued attributes)</h2></div></div></div>
<p>MVAs, or multi-valued attributes, are an important special type of
      per-document attributes in Sphinx. MVAs make it possible to attach lists
      of values to every document. They are useful for article tags, product
      categories, etc. Filtering and group-by (but not sorting) on MVA
      attributes is supported.</p><p>Currently, MVA list entries are limited to unsigned 32-bit
      integers. The list length is not limited, you can have an arbitrary
      number of values attached to each document as long as RAM permits
      (<code class="filename">.spm</code> file that contains the MVA values will be
      precached in RAM by <code class="filename">searchd</code>). The source data can
      be taken either from a separate query, or from a document field; see
      source type in <a class="link" href="#conf-sql-attr-multi" title="11.1.23.&nbsp;sql_attr_multi">sql_attr_multi</a>. In the first case
      the query will have to return pairs of document ID and MVA values, in
      the second one the field will be parsed for integer values. There are
      absolutely no requirements as to incoming data order; the values will be
      automatically grouped by document ID (and internally sorted within the
      same ID) during indexing anyway.</p><p>When filtering, a document will match the filter on MVA attribute
      if <span class="emphasis"><em>any</em></span> of the values satisfy the filtering
      condition. (Therefore, documents that pass through exclude filters will
      not contain any of the forbidden values.) When grouping by MVA
      attribute, a document will contribute to as many groups as there are
      different MVA values associated with that document. For instance, if the
      collection contains exactly 1 document having a 'tag' MVA with values 5,
      7, and 11, grouping on 'tag' will produce 3 groups with '@count' equal
      to 1 and '@groupby' key values of 5, 7, and 11 respectively. Also note
      that grouping by MVA might lead to duplicate documents in the result
      set: because each document can participate in many groups, it can be
      chosen as the best one in in more than one group, leading to duplicate
      IDs. PHP API historically uses ordered hash on the document ID for the
      resulting rows; so you'll also need to use <a class="link" href="#api-func-setarrayresult" title="8.1.6.&nbsp;SetArrayResult">SetArrayResult()</a> in order to
      employ group-by on MVA with PHP API.</p></div>
<div class="sect1" title="3.4.&nbsp;Indexes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="indexes"></a>3.4.&nbsp;Indexes</h2></div></div></div>
<p>To be able to answer full-text search queries fast, Sphinx needs
      to build a special data structure optimized for such queries from your
      text data. This structure is called <em class="glossterm">index</em>; and
      the process of building index from text is called
      <em class="glossterm">indexing</em>.</p><p>Different index types are well suited for different tasks. For
      example, a disk-based tree-based index would be easy to update (ie.
      insert new documents to existing index), but rather slow to search.
      Therefore, Sphinx architecture allows for different <em class="glossterm">index
      types</em> to be implemented easily.</p><p>The only index type which is implemented in Sphinx at the moment
      is designed for maximum indexing and searching speed. This comes at a
      cost of updates being really slow; theoretically, it might be slower to
      update this type of index than than to reindex it from scratch. However,
      this very frequently could be worked around with muiltiple indexes, see
      <a class="xref" href="#live-updates" title="3.10.&nbsp;Live index updates">Section&nbsp;3.10, “Live index updates”</a> for details.</p><p>It is planned to implement more index types, including the type
      which would be updateable in real time.</p><p>There can be as many indexes per configuration file as necessary.
      <code class="filename">indexer</code> utility can reindex either all of them (if
      <code class="option">--all</code> option is specified), or a certain explicitly
      specified subset. <code class="filename">searchd</code> utility will serve all
      the specified indexes, and the clients can specify what indexes to
      search in run time.</p></div>
<div class="sect1" title="3.5.&nbsp;Restrictions on the source data"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="data-restrictions"></a>3.5.&nbsp;Restrictions on the source data</h2></div></div></div>
<p>There are a few different restrictions imposed on the source data
      which is going to be indexed by Sphinx, of which the single most
      important one is:</p><p><span class="bold"><strong> ALL DOCUMENT IDS MUST BE UNIQUE UNSIGNED
      NON-ZERO INTEGER NUMBERS (32-BIT OR 64-BIT, DEPENDING ON BUILD TIME
      SETTINGS). </strong></span></p><p>If this requirement is not met, different bad things can happen.
      For instance, Sphinx can crash with an internal assertion while
      indexing; or produce strange results when searching due to conflicting
      IDs. Also, a 1000-pound gorilla might eventually come out of your
      display and start throwing barrels at you. You've been warned.</p></div>
<div class="sect1" title="3.6.&nbsp;Charsets, case folding, and translation tables"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="charsets"></a>3.6.&nbsp;Charsets, case folding, and translation tables</h2></div></div></div>
<p>When indexing some index, Sphinx fetches documents from the
      specified sources, splits the text into words, and does case folding so
      that "Abc", "ABC" and "abc" would be treated as the same word (or, to be
      pedantic, <em class="glossterm">term</em>).</p><p>To do that properly, Sphinx needs to know </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>what encoding is the source text in;</p></li>
<li class="listitem"><p>what characters are letters and what are not;</p></li>
<li class="listitem"><p>what letters should be folded to what letters.</p></li>
</ul></div>
<p> This should be configured on a per-index basis using
      <code class="option"><a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a></code>
      and <code class="option"><a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a></code> options.
      <code class="option"><a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a></code>
      specifies whether the document encoding is single-byte (SBCS) or UTF-8.
      <code class="option"><a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a></code>
      specifies the table that maps letter characters to their case folded
      versions. The characters that are not in the table are considered to be
      non-letters and will be treated as word separators when indexing or
      searching through this index.</p><p>Note that while default tables do not include space character
      (ASCII code 0x20, Unicode U+0020) as a letter, it's in fact
      <span class="emphasis"><em>perfectly legal</em></span> to do so. This can be useful, for
      instance, for indexing tag clouds, so that space-separated word sets
      would index as a <span class="emphasis"><em>single</em></span> search query term.</p><p>Default tables currently include English and Russian characters.
      Please do submit your tables for other languages!</p></div>
<div class="sect1" title="3.7.&nbsp;SQL data sources (MySQL, PostgreSQL)"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sql"></a>3.7.&nbsp;SQL data sources (MySQL, PostgreSQL)</h2></div></div></div>
<p>With all the SQL drivers, indexing generally works as follows.
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>connection to the database is established;</p></li>
<li class="listitem"><p>pre-query (see <a class="xref" href="#conf-sql-query-pre" title="11.1.11.&nbsp;sql_query_pre">Section&nbsp;11.1.11, “sql_query_pre”</a>) is
            executed to perform any necessary initial setup, such as setting
            per-connection encoding with MySQL;</p></li>
<li class="listitem"><p>main query (see <a class="xref" href="#conf-sql-query" title="11.1.12.&nbsp;sql_query">Section&nbsp;11.1.12, “sql_query”</a>) is
            executed and the rows it returns are indexed;</p></li>
<li class="listitem"><p>post-query (see <a class="xref" href="#conf-sql-query-post" title="11.1.30.&nbsp;sql_query_post">Section&nbsp;11.1.30, “sql_query_post”</a>) is
            executed to perform any necessary cleanup;</p></li>
<li class="listitem"><p>connection to the database is closed;</p></li>
<li class="listitem"><p>indexer does the sorting phase (to be pedantic, index-type
            specific post-processing);</p></li>
<li class="listitem"><p>connection to the database is established again;</p></li>
<li class="listitem"><p>post-index query (see <a class="xref" href="#conf-sql-query-post-index" title="11.1.31.&nbsp;sql_query_post_index">Section&nbsp;11.1.31, “sql_query_post_index”</a>) is executed to perform any
            necessary final cleanup;</p></li>
<li class="listitem"><p>connection to the database is closed again.</p></li>
</ul></div>
<p> Most options, such as database user/host/password, are
      straightforward. However, there are a few subtle things, which are
      discussed in more detail here.</p><h3><a name="ranged-queries"></a>Ranged queries</h3><p>Main query, which needs to fetch all the documents, can impose a
      read lock on the whole table and stall the concurrent queries (eg.
      INSERTs to MyISAM table), waste a lot of memory for result set, etc. To
      avoid this, Sphinx supports so-called <em class="glossterm">ranged
      queries</em>. With ranged queries, Sphinx first fetches min and
      max document IDs from the table, and then substitutes different ID
      intervals into main query text and runs the modified query to fetch
      another chunk of documents. Here's an example.</p><div class="example"><a name="ex-ranged-queries"></a><p class="title"><b>Example&nbsp;3.1.&nbsp;Ranged query usage example</b></p><div class="example-contents"><pre class="programlisting"># in sphinx.conf

sql_query_range	= SELECT MIN(id),MAX(id) FROM documents
sql_range_step = 1000
sql_query = SELECT * FROM documents WHERE id&gt;=$start AND id&lt;=$end
</pre></div></div>
<br class="example-break"><p>If the table contains document IDs from 1 to, say, 2345, then
      sql_query would be run three times: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>with <code class="option">$start</code> replaced with 1 and
            <code class="option">$end</code> replaced with 1000;</p></li>
<li class="listitem"><p>with <code class="option">$start</code> replaced with 1001 and
            <code class="option">$end</code> replaced with 2000;</p></li>
<li class="listitem"><p>with <code class="option">$start</code> replaced with 2000 and
            <code class="option">$end</code> replaced with 2345.</p></li>
</ol></div>
<p> Obviously, that's not much of a difference for 2000-row
      table, but when it comes to indexing 10-million-row MyISAM table, ranged
      queries might be of some help.</p><h3><code class="option">sql_post</code> vs.
      <code class="option">sql_post_index</code></h3><p>The difference between post-query and post-index query is in that
      post-query is run immediately when Sphinx received all the documents,
      but further indexing <span class="bold"><strong>may</strong></span> still fail for
      some other reason. On the contrary, by the time the post-index query
      gets executed, it is <span class="bold"><strong>guaranteed</strong></span> that
      the indexing was succesful. Database connection is dropped and
      re-established because sorting phase can be very lengthy and would just
      timeout otherwise.</p></div>
<div class="sect1" title="3.8.&nbsp;xmlpipe data source"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="xmlpipe"></a>3.8.&nbsp;xmlpipe data source</h2></div></div></div>
<p>xmlpipe data source was designed to enable users to plug data into
      Sphinx without having to implement new data sources drivers themselves.
      It is limited to 2 fixed fields and 2 fixed attributes, and is
      deprecated in favor of <a class="xref" href="#xmlpipe2" title="3.9.&nbsp;xmlpipe2 data source">Section&nbsp;3.9, “xmlpipe2 data source”</a> now. For new streams,
      use xmlpipe2.</p><p>To use xmlpipe, configure the data source in your configuration
      file as follows: </p><pre class="programlisting">source example_xmlpipe_source
{
    type = xmlpipe
    xmlpipe_command = perl /www/mysite.com/bin/sphinxpipe.pl
}
</pre><p> The <code class="filename">indexer</code> will run the command
      specified in <code class="option"><a class="link" href="#conf-xmlpipe-command" title="11.1.34.&nbsp;xmlpipe_command">xmlpipe_command</a></code>, and then
      read, parse and index the data it prints to <code class="filename">stdout</code>.
      More formally, it opens a pipe to given command and then reads from that
      pipe.</p><p>indexer will expect one or more documents in custom XML format.
      Here's the example document stream, consisting of two documents:
      </p><div class="example"><a name="ex-xmlpipe-document"></a><p class="title"><b>Example&nbsp;3.2.&nbsp;XMLpipe document stream</b></p><div class="example-contents"><pre class="programlisting">&lt;document&gt;
&lt;id&gt;123&lt;/id&gt;
&lt;group&gt;45&lt;/group&gt;
&lt;timestamp&gt;1132223498&lt;/timestamp&gt;
&lt;title&gt;test title&lt;/title&gt;
&lt;body&gt;
this is my document body
&lt;/body&gt;
&lt;/document&gt;

&lt;document&gt;
&lt;id&gt;124&lt;/id&gt;
&lt;group&gt;46&lt;/group&gt;
&lt;timestamp&gt;1132223498&lt;/timestamp&gt;
&lt;title&gt;another test&lt;/title&gt;
&lt;body&gt;
this is another document
&lt;/body&gt;
&lt;/document&gt;
</pre></div></div>
<p><br class="example-break"></p><p>Legacy xmlpipe legacy driver uses a builtin parser which is pretty
      fast but really strict and does not actually fully support XML. It
      requires that all the fields <span class="emphasis"><em>must</em></span> be present,
      formatted <span class="emphasis"><em>exactly</em></span> as in this example, and occur
      <span class="emphasis"><em>exactly</em></span> in the same order. The only optional field
      is <code class="option">timestamp</code>; it defaults to 1.</p></div>
<div class="sect1" title="3.9.&nbsp;xmlpipe2 data source"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="xmlpipe2"></a>3.9.&nbsp;xmlpipe2 data source</h2></div></div></div>
<p>xmlpipe2 lets you pass arbitrary full-text and attribute data to
      Sphinx in yet another custom XML format. It also allows to specify the
      schema (ie. the set of fields and attributes) either in the XML stream
      itself, or in the source settings.</p><p>When indexing xmlpipe2 source, indexer runs the given command,
      opens a pipe to its stdout, and expects well-formed XML stream. Here's
      sample stream data: </p><div class="example"><a name="ex-xmlpipe2-document"></a><p class="title"><b>Example&nbsp;3.3.&nbsp;xmlpipe2 document stream</b></p><div class="example-contents"><pre class="programlisting">&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;sphinx:docset&gt;

&lt;sphinx:schema&gt;
&lt;sphinx:field name="subject"/&gt; 
&lt;sphinx:field name="content"/&gt;
&lt;sphinx:attr name="published" type="timestamp"/&gt;
&lt;sphinx:attr name="author_id" type="int" bits="16" default="1"/&gt;
&lt;/sphinx:schema&gt;

&lt;sphinx:document id="1234"&gt;
&lt;content&gt;this is the main content &lt;![CDATA[[and this &lt;cdata&gt; entry
must be handled properly by xml parser lib]]&gt;&lt;/content&gt;
&lt;published&gt;1012325463&lt;/published&gt;
&lt;subject&gt;note how field/attr tags can be
in &lt;b class="red"&gt;randomized&lt;/b&gt; order&lt;/subject&gt;
&lt;misc&gt;some undeclared element&lt;/misc&gt;
&lt;/sphinx:document&gt;

&lt;sphinx:document id="1235"&gt;
&lt;subject&gt;another subject&lt;/subject&gt;
&lt;content&gt;here comes another document, and i am given to understand,
that in-document field order must not matter, sir&lt;/content&gt;
&lt;published&gt;1012325467&lt;/published&gt;
&lt;/sphinx:document&gt;

&lt;!-- ... even more sphinx:document entries here ... --&gt;

&lt;sphinx:killlist&gt;
&lt;id&gt;1234&lt;/id&gt;
&lt;id&gt;4567&lt;/id&gt;
&lt;/sphinx:killlist&gt;

&lt;/sphinx:docset&gt;
</pre></div></div>
<p><br class="example-break"></p><p>Arbitrary fields and attributes are allowed. They also can occur
      in the stream in arbitrary order within each document; the order is
      ignored. There is a restriction on maximum field length; fields longer
      than 2 MB will be truncated to 2 MB (this limit can be changed in the
      source).</p><p>The schema, ie. complete fields and attributes list, must be
      declared before any document could be parsed. This can be done either in
      the configuration file using <code class="option">xmlpipe_field</code> and
      <code class="option">xmlpipe_attr_XXX</code> settings, or right in the stream using
      &lt;sphinx:schema&gt; element. &lt;sphinx:schema&gt; is optional. It is
      only allowed to occur as the very first sub-element in
      &lt;sphinx:docset&gt;. If there is no in-stream schema definition,
      settings from the configuration file will be used. Otherwise, stream
      settings take precedence.</p><p>Unknown tags (which were not declared neither as fields nor as
      attributes) will be ignored with a warning. In the example above,
      &lt;misc&gt; will be ignored. All embedded tags and their attributes
      (such as &lt;b&gt; in &lt;subject&gt; in the example above) will be
      silently ignored.</p><p>Support for incoming stream encodings depends on whether
      <code class="filename">iconv</code> is installed on the system. xmlpipe2 is
      parsed using <code class="filename">libexpat</code> parser that understands
      US-ASCII, ISO-8859-1, UTF-8 and a few UTF-16 variants natively. Sphinx
      <code class="filename">configure</code> script will also check for
      <code class="filename">libiconv</code> presence, and utilize it to handle other
      encodings. <code class="filename">libexpat</code> also enforces the requirement
      to use UTF-8 charset on Sphinx side, because the parsed data it returns
      is always in UTF-8. </p><p>XML elements (tags) recognized by xmlpipe2 (and their attributes
      where applicable) are: </p><div class="variablelist"><dl><dt><span class="term">sphinx:docset</span></dt>
<dd><p>Mandatory top-level element, denotes and contains xmlpipe2
              document set.</p></dd><dt><span class="term">sphinx:schema</span></dt>
<dd><p>Optional element, must either occur as the very first
              child of sphinx:docset, or never occur at all. Declares the
              document schema. Contains field and attribute declarations. If
              present, overrides per-source settings from the configuration
              file.</p></dd><dt><span class="term">sphinx:field</span></dt>
<dd><p>Optional element, child of sphinx:schema. Declares a
              full-text field. Known attributes are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>"name", specifies the XML element name that will be
                    treated as a full-text field in the subsequent
                    documents.</p></li>
<li class="listitem"><p>"attr", specifies whether to also index this field
                    as a string or word count attribute. Possible values are
                    "string" and "wordcount". Introduced in version
                    1.10-beta.</p></li>
</ul></div>
</dd><dt><span class="term">sphinx:attr</span></dt>
<dd><p>Optional element, child of sphinx:schema. Declares an
              attribute. Known attributes are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>"name", specifies the element name that should be
                    treated as an attribute in the subsequent
                    documents.</p></li>
<li class="listitem"><p>"type", specifies the attribute type. Possible
                    values are "int", "timestamp", "str2ordinal", "bool",
                    "float" and "multi".</p></li>
<li class="listitem"><p>"bits", specifies the bit size for "int" attribute
                    type. Valid values are 1 to 32.</p></li>
<li class="listitem"><p>"default", specifies the default value for this
                    attribute that should be used if the attribute's element
                    is not present in the document.</p></li>
</ul></div>
</dd><dt><span class="term">sphinx:document</span></dt>
<dd><p>Mandatory element, must be a child of sphinx:docset.
              Contains arbitrary other elements with field and attribute
              values to be indexed, as declared either using sphinx:field and
              sphinx:attr elements or in the configuration file. The only
              known attribute is "id" that must contain the unique integer
              document ID.</p></dd><dt><span class="term">sphinx:killlist</span></dt>
<dd><p>Optional element, child of sphinx:docset. Contains a
              number of "id" elements whose contents are document IDs to be
              put into a <a class="link" href="#conf-sql-query-killlist" title="11.1.16.&nbsp;sql_query_killlist">kill-list</a> for this
              index.</p></dd></dl></div></div>
<div class="sect1" title="3.10.&nbsp;Live index updates"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="live-updates"></a>3.10.&nbsp;Live index updates</h2></div></div></div>
<p>There are two major approaches to maintaining the full-text index
      contents up to date. Note, however, that both these approaches deal with
      the task of <span class="emphasis"><em>full-text data updates</em></span>, and not
      attribute updates. Instant attribute updates are supported since version
      0.9.8. Refer to <a class="link" href="#api-func-updateatttributes" title="8.7.2.&nbsp;UpdateAttributes">UpdateAttributes()</a> API call
      description for details.</p><p>First, you can use disk-based indexes, partition them manually,
      and only rebuild the smaller partitions (so-called "deltas") frequently.
      By minimizing the rebuild size, you can reduce the average indexing lag
      to something as low as 30-60 seconds. This approach was the the only one
      available in versions 0.9.x. On huge collections it actually might be
      the most efficient one. Refer to <a class="xref" href="#delta-updates" title="3.11.&nbsp;Delta index updates">Section&nbsp;3.11, “Delta index updates”</a> for
      details.</p><p>Second, versions 1.x (starting with 1.10-beta) add support for
      so-called real-time indexes (RT indexes for short) that on-the-fly
      updates of the full-text data. Updates on a RT index can appear in the
      search results in 1-2 milliseconds, ie. 0.001-0.002 seconds. However, RT
      index are less efficient for bulk indexing huge amounts of data. Refer
      to <a class="xref" href="#rt-indexes" title="Chapter&nbsp;4.&nbsp;Real-time indexes">Chapter&nbsp;4, <i>Real-time indexes</i></a> for details.</p></div>
<div class="sect1" title="3.11.&nbsp;Delta index updates"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="delta-updates"></a>3.11.&nbsp;Delta index updates</h2></div></div></div>
<p>There's a frequent situation when the total dataset is too big to
      be reindexed from scratch often, but the amount of new records is rather
      small. Example: a forum with a 1,000,000 archived posts, but only 1,000
      new posts per day.</p><p>In this case, "live" (almost real time) index updates could be
      implemented using so called "main+delta" scheme.</p><p>The idea is to set up two sources and two indexes, with one "main"
      index for the data which only changes rarely (if ever), and one "delta"
      for the new documents. In the example above, 1,000,000 archived posts
      would go to the main index, and newly inserted 1,000 posts/day would go
      to the delta index. Delta index could then be reindexed very frequently,
      and the documents can be made available to search in a matter of
      minutes.</p><p>Specifying which documents should go to what index and reindexing
      main index could also be made fully automatical. One option would be to
      make a counter table which would track the ID which would split the
      documents, and update it whenever the main index is reindexed. </p><div class="example"><a name="ex-live-updates"></a><p class="title"><b>Example&nbsp;3.4.&nbsp;Fully automated live updates</b></p><div class="example-contents"><pre class="programlisting"># in MySQL
CREATE TABLE sph_counter
(
    counter_id INTEGER PRIMARY KEY NOT NULL,
    max_doc_id INTEGER NOT NULL
);

# in sphinx.conf
source main
{
    # ...
    sql_query_pre = SET NAMES utf8
    sql_query_pre = REPLACE INTO sph_counter SELECT 1, MAX(id) FROM documents
    sql_query = SELECT id, title, body FROM documents \
        WHERE id&lt;=( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
}

source delta : main
{
    sql_query_pre = SET NAMES utf8
    sql_query = SELECT id, title, body FROM documents \
        WHERE id&gt;( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
}

index main
{
    source = main
    path = /path/to/main
    # ... all the other settings
}

# note how all other settings are copied from main,
# but source and path are overridden (they MUST be)
index delta : main
{
    source = delta
    path = /path/to/delta
}
</pre></div></div>
<p><br class="example-break"></p><p>Note how we're overriding <code class="code">sql_query_pre</code> in the delta
      source. We need to explicitly have that override. Otherwise
      <code class="code">REPLACE</code> query would be run when indexing delta source too,
      effectively nullifying it. However, when we issue the directive in the
      inherited source for the first time, it removes <span class="emphasis"><em>all</em></span>
      inherited values, so the encoding setup is also lost. So
      <code class="code">sql_query_pre</code> in the delta can not just be empty; and we
      need to issue the encoding setup query explicitly once again.</p></div>
<div class="sect1" title="3.12.&nbsp;Index merging"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="index-merging"></a>3.12.&nbsp;Index merging</h2></div></div></div>
<p>Merging two existing indexes can be more efficient that indexing
      the data from scratch, and desired in some cases (such as merging 'main'
      and 'delta' indexes instead of simply reindexing 'main' in 'main+delta'
      partitioning scheme). So <code class="filename">indexer</code> has an option to
      do that. Merging the indexes is normally faster than reindexing but
      still <span class="emphasis"><em>not</em></span> instant on huge indexes. Basically, it
      will need to read the contents of both indexes once and write the result
      once. Merging 100 GB and 1 GB index, for example, will result in 202 GB
      of IO (but that's still likely less than the indexing from scratch
      requires).</p><p>The basic command syntax is as follows: </p><div class="literallayout"><p><strong class="userinput"><code><br>
indexer&nbsp;--merge&nbsp;DSTINDEX&nbsp;SRCINDEX&nbsp;[--rotate]<br>
</code></strong></p></div>
<p> Only the DSTINDEX index will be affected: the
      contents of SRCINDEX will be merged into it. <code class="option">--rotate</code>
      switch will be required if DSTINDEX is already being served by
      <code class="filename">searchd</code>. The initially devised usage pattern is to
      merge a smaller update from SRCINDEX into DSTINDEX. Thus, when merging
      the attributes, values from SRCINDEX will win if duplicate document IDs
      are encountered. Note, however, that the "old" keywords will
      <span class="emphasis"><em>not</em></span> be automatically removed in such cases. For
      example, if there's a keyword "old" associated with document 123 in
      DSTINDEX, and a keyword "new" associated with it in SRCINDEX, document
      123 will be found by <span class="emphasis"><em>both</em></span> keywords after the merge.
      You can supply an explicit condition to remove documents from DSTINDEX
      to mitigate that; the relevant switch is
      <code class="option">--merge-dst-range</code>: </p><div class="literallayout"><p><strong class="userinput"><code><br>
indexer&nbsp;--merge&nbsp;main&nbsp;delta&nbsp;--merge-dst-range&nbsp;deleted&nbsp;0&nbsp;0<br>
</code></strong></p></div>
<p> This switch lets you apply filters to the
      destination index along with merging. There can be several filters; all
      of their conditions must be met in order to include the document in the
      resulting mergid index. In the example above, the filter passes only
      those records where 'deleted' is 0, eliminating all records that were
      flagged as deleted (for instance, using <a class="link" href="#api-func-updateatttributes" title="8.7.2.&nbsp;UpdateAttributes">UpdateAttributes()</a>
      call).</p></div></div>
<div class="chapter" title="Chapter&nbsp;4.&nbsp;Real-time indexes"><div class="titlepage"><div><div><h2 class="title"><a name="rt-indexes"></a>Chapter&nbsp;4.&nbsp;Real-time indexes</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#rt-overview">4.1. RT indexes overview</a></span></dt>
<dt><span class="sect1"><a href="#rt-caveats">4.2. Known caveats with RT indexes</a></span></dt>
<dt><span class="sect1"><a href="#rt-internals">4.3. RT index internals</a></span></dt>
<dt><span class="sect1"><a href="#rt-binlog">4.4. Binary logging</a></span></dt>
</dl></div>
<p>Real-time indexes (or RT indexes for brevity) are a new backend that
    lets you insert, update, or delete documents (rows) on the fly. RT indexes
    were added in version 1.10-beta. While querying of RT indexes is possible
    using any of the SphinxAPI, SphinxQL, or SphinxSE, updating them is only
    possible via SphinxQL at the moment. Full SphinxQL reference is available
    in <a class="xref" href="#sphinxql-reference" title="Chapter&nbsp;7.&nbsp;SphinxQL reference">Chapter&nbsp;7, <i>SphinxQL reference</i></a>.</p><div class="sect1" title="4.1.&nbsp;RT indexes overview"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rt-overview"></a>4.1.&nbsp;RT indexes overview</h2></div></div></div>
<p>RT indexes should be declared in <code class="filename">sphinx.conf</code>,
      just as every other index type. Notable differences from the regular,
      disk-based indexes are that a) data sources are not required and
      ignored, and b) you should explicitly enumerate all the text fields, not
      just attributes. Here's an example:</p><div class="example"><a name="ex-rt-updates"></a><p class="title"><b>Example&nbsp;4.1.&nbsp;RT index declaration</b></p><div class="example-contents"><pre class="programlisting">index rt
{
	type = rt
	path = /usr/local/sphinx/data/rt
	rt_field = title
	rt_field = content
	rt_attr_uint = gid
}
</pre></div></div>
<br class="example-break"><p>RT INDEXES ARE CURRENTLY (AS OF VERSION 1.10-beta) A WORK IN
      PROGRESS. Therefore, they might lack certain features: for instance,
      prefix/infix indexing, MVA attributes, etc are not supported yet. There
      also might be performance and stability issues. However, all the regular
      indexing features and most of the searching features are already in
      place, our internal testing passes, and last but not least a number of
      production instances are already using RT indexes with good
      results.</p><p>RT index can be accessed using MySQL protocol. INSERT, REPLACE,
      DELETE, and SELECT statements against RT index are supported. For
      instance, this is an example session with the sample index above:</p><pre class="programlisting">$ mysql -h 127.0.0.1 -P 9306
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
Server version: 1.10-dev (r2153)

Type 'help;' or '\h' for help. Type '\c' to clear the buffer.

mysql&gt; INSERT INTO rt VALUES ( 1, 'first record', 'test one', 123 );
Query OK, 1 row affected (0.05 sec)

mysql&gt; INSERT INTO rt VALUES ( 2, 'second record', 'test two', 234 );
Query OK, 1 row affected (0.00 sec)

mysql&gt; SELECT * FROM rt;
+------+--------+------+
| id   | weight | gid  |
+------+--------+------+
|    1 |      1 |  123 |
|    2 |      1 |  234 |
+------+--------+------+
2 rows in set (0.02 sec)

mysql&gt; SELECT * FROM rt WHERE MATCH('test');
+------+--------+------+
| id   | weight | gid  |
+------+--------+------+
|    1 |   1643 |  123 |
|    2 |   1643 |  234 |
+------+--------+------+
2 rows in set (0.01 sec)

mysql&gt; SELECT * FROM rt WHERE MATCH('@title test');
Empty set (0.00 sec)
</pre><p>Both partial and batch INSERT syntaxes are supported, ie. you can
      specify a subset of columns, and insert several rows at a time.
      Deletions are also possible using DELETE statement; the only currently
      supported syntax is DELETE FROM &lt;index&gt; WHERE id=&lt;id&gt;.
      REPLACE is also supported, enabling you to implement updates.</p><pre class="programlisting">mysql&gt; INSERT INTO rt ( id, title ) VALUES ( 3, 'third row' ), ( 4, 'fourth entry' );
Query OK, 2 rows affected (0.01 sec)

mysql&gt; SELECT * FROM rt;
+------+--------+------+
| id   | weight | gid  |
+------+--------+------+
|    1 |      1 |  123 |
|    2 |      1 |  234 |
|    3 |      1 |    0 |
|    4 |      1 |    0 |
+------+--------+------+
4 rows in set (0.00 sec)

mysql&gt; DELETE FROM rt WHERE id=2;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; SELECT * FROM rt WHERE MATCH('test');
+------+--------+------+
| id   | weight | gid  |
+------+--------+------+
|    1 |   1500 |  123 |
+------+--------+------+
1 row in set (0.00 sec)

mysql&gt; INSERT INTO rt VALUES ( 1, 'first record on steroids', 'test one', 123 );
ERROR 1064 (42000): duplicate id '1'

mysql&gt; REPLACE INTO rt VALUES ( 1, 'first record on steroids', 'test one', 123 );
Query OK, 1 row affected (0.01 sec)

mysql&gt; SELECT * FROM rt WHERE MATCH('steroids');
+------+--------+------+
| id   | weight | gid  |
+------+--------+------+
|    1 |   1500 |  123 |
+------+--------+------+
1 row in set (0.01 sec)
</pre><p>Data stored in RT index should survive clean shutdown. When binary
      logging is enabled, it should also survive crash and/or dirty shutdown,
      and recover on subsequent startup.</p></div>
<div class="sect1" title="4.2.&nbsp;Known caveats with RT indexes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rt-caveats"></a>4.2.&nbsp;Known caveats with RT indexes</h2></div></div></div>
<p>As of 1.10-beta, RT indexes are a beta quality feature: while no
      major, showstopper-class issues are known, there still are a few known
      usage quirks. Those quirks are listed in this section.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Prefix and infix indexing are not supported yet.</p></li>
<li class="listitem"><p>MVAs are not supported yet.</p></li>
<li class="listitem"><p>Disk chunks optimization routine is not implemented
          yet.</p></li>
<li class="listitem"><p>On initial index creation, attributes are reordered by type,
          in the following order: uint, bigint, float, timestamp, string. So
          when using INSERT without an explicit column names list, specify all
          uint column values first, then bigint, etc.</p></li>
<li class="listitem"><p>Default conservative RAM chunk limit
          (<code class="option">rt_mem_limit</code>) of 32M can lead to poor performance
          on bigger indexes, you should raise it to 256..1024M if you're
          planning to index gigabytes.</p></li>
<li class="listitem"><p>High DELETE/REPLACE rate can lead to kill-list fragmentation
          and impact searching performance.</p></li>
<li class="listitem"><p>No transaction size limits are currently imposed; too many
          concurrent INSERT/REPLACE transactions might therefore consume a lot
          of RAM.</p></li>
<li class="listitem"><p>In case of a damaged binlog, recovery will stop on the first
          damaged transaction, even though it's technically possible to keep
          looking further for subsequent undamaged transactions, and recover
          those. This mid-file damage case (due to flaky HDD/CDD/tape?) is
          supposed to be extremely rare, though.</p></li>
<li class="listitem"><p>Multiple INSERTs grouped in a single transaction perform
          better than equivalent single-row transactions and are recommended
          for batch loading of data.</p></li>
</ul></div></div>
<div class="sect1" title="4.3.&nbsp;RT index internals"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rt-internals"></a>4.3.&nbsp;RT index internals</h2></div></div></div>
<p>RT index is internally chunked. It keeps a so-called RAM chunk
      that stores all the most recent changes. RAM chunk memory usage is
      rather strictly limited with per-index <a class="link" href="#conf-rt-mem-limit" title="11.2.49.&nbsp;rt_mem_limit">rt_mem_limit</a> directive. Once RAM
      chunk grows over this limit, a new disk chunk is created from its data,
      and RAM chunk is reset. Thus, while most changes on the RT index will be
      performed in RAM only and complete instantly (in milliseconds), those
      changes that overflow the RAM chunk will stall for the duration of disk
      chunk creation (a few seconds).</p><p>Disk chunks are, in fact, just regular disk-based indexes. But
      they're a part of an RT index and automatically managed by it, so you
      need not configure nor manage them manually. Because a new disk chunk is
      created every time RT chunk overflows the limit, and because in-memory
      chunk format is close to on-disk format, the disk chunks will be
      approximately <code class="option">rt_mem_limit</code> bytes in size each.</p><p>Generally, it is better to set the limit bigger, to minimize both
      the frequency of flushes, and the index fragmentation (number of disk
      chunks). For instance, on a dedicated search server that handles a big
      RT index, it can be advised to set <code class="option">rt_mem_limit</code> to 1-2
      GB. A global limit on all indexes is also planned, but not yet
      implemented yet as of 1.10-beta.</p><p>Disk chunk full-text index data can not be actually modified, so
      the full-text field changes (ie. row deletions and updates) suppress a
      previous row version from a disk chunk using a kill-list, but do not
      actually physically purge the data. Therefore, on workloads with high
      full-text updates ratio index might eventually get polluted by these
      previous row versions, and searching performance would degrade. Physical
      index purging that would improve the performance is planned, but not yet
      implemented as of 1.10-beta.</p><p>Data in RAM chunk gets saved to disk on clean daemon shutdown, and
      then loaded back on startup. However, on daemon or server crash, updates
      from RAM chunk might be lost. To prevent that, binary logging of
      transactions can be used; see <a class="xref" href="#rt-binlog" title="4.4.&nbsp;Binary logging">Section&nbsp;4.4, “Binary logging”</a> for
      details.</p><p>Full-text changes in RT index are transactional. They are stored
      in a per-thread accumulator until COMMIT, then applied at once. Bigger
      batches per single COMMIT should result in faster indexing.</p></div>
<div class="sect1" title="4.4.&nbsp;Binary logging"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rt-binlog"></a>4.4.&nbsp;Binary logging</h2></div></div></div>
<p>Binary logs are essentially a recovery mechanism. With binary logs
      enabled, <code class="filename">searchd</code> writes every given transaction to
      the binlog file, and uses that for recovery after an unclean shutdown.
      On clean shutdown, RAM chunks are saved to disk, and then all the binlog
      files are unlinked.</p><p>During normal operation, a new binlog file will be opened every
      time when <code class="option">binlog_max_log_size</code> limit (which defaults to
      128M) is reached. Older, already closed binlog files are kept until all
      of the transactions stored in them (from all indexes) are flushed as a
      disk chunk. Setting the limit to 0 pretty much prevents binlog from
      being unlinked at all while <code class="filename">searchd</code> is running;
      however, it will still be unlinked on clean shutdown.</p><p>There are 3 different binlog flushing strategies, controlled by
      <a class="link" href="#conf-binlog-flush" title="11.4.31.&nbsp;binlog_flush">binlog_flush</a> directive which
      takes the values of 0, 1, or 2. 0 means to flush the log to OS and sync
      it to disk every second; 1 means flush and sync every transaction; and 2
      (the default mode) means flush every transaction but sync every second.
      Sync is relatively slow because it has to perform physical disk writes,
      so mode 1 is the safest (every committed transaction is guaranteed to be
      written on disk) but the slowest. Flushing log to OS prevents from data
      loss on <code class="filename">searchd</code> crashes but not system crashes.
      Mode 2 is the default.</p><p>On recovery after an unclean shutdown, binlogs are replayed and
      all logged transactions since the last good on-disk state are restored.
      Transactions are checksummed so in case of binlog file corruption
      garbage data will <span class="bold"><strong>not</strong></span> be replayed; such a broken transaction will
      be detected and, currently, will stop replay. Transactions also start
      with a magic marker and timestamped, so in case of binlog damage in the
      middle of the file, it's technically possible to skip broken
      transactions and keep replaying from the next good one, and/or it's
      possible to replay transactions until a given timestamp (point-in-time
      recovery), but none of that is implemented yet as of 1.10-beta.</p><p>One unwanted side effect of binlogs is that activel updating a
      small RT index that fully fits into a RAM chunk part will lead to an
      ever-growing binlog that can never be unlinked until clean shutdown.
      Binlogs are essentially append-only deltas against the last known good
      saved state on disk, and unless RAM chunk gets saved, they can not be
      unlinked. An ever-growing binlog is not very good for disk use and crash
      recovery time. Starting with 2.0.1-beta you can configure
      <code class="filename">searchd</code> to perform a periodic RAM chunk flush to
      fix that problem using a <a class="link" href="#conf-rt-flush-period" title="11.4.37.&nbsp;rt_flush_period">rt_flush_period</a> directive. With
      periodic flushes enabled, <code class="filename">searchd</code> will keep a
      separate thread, checking whether RT indexes RAM chunks need to be
      written back to disk. Once that happens, the respective binlogs can be
      (and are) safely unlinked.</p><p>Note that <code class="code">rt_flush_period</code> only controls the frequency
      at which the <span class="emphasis"><em>checks</em></span> happen. There are no
      <span class="emphasis"><em>guarantees</em></span> that the particular RAM chunk will get
      saved. For instance, it does not make sense to regularly re-save a huge
      RAM chunk that only gets a few rows worh of updates. The search daemon
      determine whether to actually perform the flush with a few
      heuristics.</p></div></div>
<div class="chapter" title="Chapter&nbsp;5.&nbsp;Searching"><div class="titlepage"><div><div><h2 class="title"><a name="searching"></a>Chapter&nbsp;5.&nbsp;Searching</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#matching-modes">5.1. Matching modes</a></span></dt>
<dt><span class="sect1"><a href="#boolean-syntax">5.2. Boolean query syntax</a></span></dt>
<dt><span class="sect1"><a href="#extended-syntax">5.3. Extended query syntax</a></span></dt>
<dt><span class="sect1"><a href="#weighting">5.4. Weighting</a></span></dt>
<dt><span class="sect1"><a href="#expressions">5.5. Expressions, functions, and operators</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#operators">5.5.1. Operators</a></span></dt>
<dt><span class="sect2"><a href="#numeric-functions">5.5.2. Numeric functions</a></span></dt>
<dt><span class="sect2"><a href="#date-time-functions">5.5.3. Date and time functions</a></span></dt>
<dt><span class="sect2"><a href="#type-conversion-functions">5.5.4. Type conversion functions</a></span></dt>
<dt><span class="sect2"><a href="#comparison-functions">5.5.5. Comparison functions</a></span></dt>
<dt><span class="sect2"><a href="#misc-functions">5.5.6. Miscellaneous functions</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sorting-modes">5.6. Sorting modes</a></span></dt>
<dt><span class="sect1"><a href="#clustering">5.7. Grouping (clustering) search results</a></span></dt>
<dt><span class="sect1"><a href="#distributed">5.8. Distributed searching</a></span></dt>
<dt><span class="sect1"><a href="#query-log-format">5.9. <code class="filename">searchd</code> query log formats</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#plain-log-format">5.9.1. Plain log format</a></span></dt>
<dt><span class="sect2"><a href="#sphinxql-log-format">5.9.2. SphinxQL log format</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sphinxql">5.10. MySQL protocol support and SphinxQL</a></span></dt>
<dt><span class="sect1"><a href="#multi-queries">5.11. Multi-queries</a></span></dt>
<dt><span class="sect1"><a href="#collations">5.12. Collations</a></span></dt>
<dt><span class="sect1"><a href="#udf">5.13. User-defined functions (UDF)</a></span></dt>
</dl></div>
<div class="sect1" title="5.1.&nbsp;Matching modes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="matching-modes"></a>5.1.&nbsp;Matching modes</h2></div></div></div>
<p>There are the following matching modes available: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>SPH_MATCH_ALL, matches all query words (default
            mode);</p></li>
<li class="listitem"><p>SPH_MATCH_ANY, matches any of the query words;</p></li>
<li class="listitem"><p>SPH_MATCH_PHRASE, matches query as a phrase, requiring
            perfect match;</p></li>
<li class="listitem"><p>SPH_MATCH_BOOLEAN, matches query as a boolean expression
            (see <a class="xref" href="#boolean-syntax" title="5.2.&nbsp;Boolean query syntax">Section&nbsp;5.2, “Boolean query syntax”</a>);</p></li>
<li class="listitem"><p>SPH_MATCH_EXTENDED, matches query as an expression in Sphinx
            internal query language (see <a class="xref" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">Section&nbsp;5.3, “Extended query syntax”</a>).
            As of 0.9.9, this has been superceded by SPH_MATCH_EXTENDED2,
            providing additional functionality and better performance. The
            ident is retained for legacy application code that will continue
            to be compatible once Sphinx and its components, including the
            API, are upgraded.</p></li>
<li class="listitem"><p>SPH_MATCH_EXTENDED2, matches query using the second version
            of the Extended matching mode.</p></li>
<li class="listitem"><p>SPH_MATCH_FULLSCAN, matches query, forcibly using the "full
            scan" mode as below. NB, any query terms will be ignored, such
            that filters, filter-ranges and grouping will still be applied,
            but no text-matching.</p></li>
</ul></div>
<p>The SPH_MATCH_FULLSCAN mode will be automatically activated in
      place of the specified matching mode when the following conditions are
      met: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>The query string is empty (ie. its length is zero).</p></li>
<li class="listitem"><p><a class="link" href="#conf-docinfo" title="11.2.4.&nbsp;docinfo">docinfo</a> storage is set
            to <code class="code">extern</code>.</p></li>
</ol></div>
<p> In full scan mode, all the indexed documents will be
      considered as matching. Such queries will still apply filters, sorting,
      and group by, but will not perform any full-text searching. This can be
      useful to unify full-text and non-full-text searching code, or to
      offload SQL server (there are cases when Sphinx scans will perform
      better than analogous MySQL queries). An example of using the full scan
      mode might be to find posts in a forum. By selecting the forum's user ID
      via <code class="code">SetFilter()</code> but not actually providing any search text,
      Sphinx will match every document (i.e. every post) where
      <code class="code">SetFilter()</code> would match - in this case providing every post
      from that user. By default this will be ordered by relevancy, followed
      by Sphinx document ID in ascending order (earliest first).</p></div>
<div class="sect1" title="5.2.&nbsp;Boolean query syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="boolean-syntax"></a>5.2.&nbsp;Boolean query syntax</h2></div></div></div>
<p>Boolean queries allow the following special operators to be used:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>explicit operator AND: </p><pre class="programlisting">hello &amp; world</pre></li>
<li class="listitem"><p>operator OR: </p><pre class="programlisting">hello | world</pre></li>
<li class="listitem"><p>operator NOT: </p><pre class="programlisting">hello -world
hello !world
</pre></li>
<li class="listitem"><p>grouping: </p><pre class="programlisting">( hello world )</pre></li>
</ul></div>
<p> Here's an example query which uses all these
      operators: </p><div class="example"><a name="ex-boolean-query"></a><p class="title"><b>Example&nbsp;5.1.&nbsp;Boolean query example</b></p><div class="example-contents"><pre class="programlisting">( cat -dog ) | ( cat -mouse)
</pre></div></div>
<p><br class="example-break"></p><p>There always is implicit AND operator, so "hello world" query
      actually means "hello &amp; world".</p><p>OR operator precedence is higher than AND, so "looking for cat |
      dog | mouse" means "looking for ( cat | dog | mouse )" and
      <span class="emphasis"><em>not</em></span> "(looking for cat) | dog | mouse".</p><p>Queries like "-dog", which implicitly include all documents from
      the collection, can not be evaluated. This is both for technical and
      performance reasons. Technically, Sphinx does not always keep a list of
      all IDs. Performance-wise, when the collection is huge (ie. 10-100M
      documents), evaluating such queries could take very long.</p></div>
<div class="sect1" title="5.3.&nbsp;Extended query syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="extended-syntax"></a>5.3.&nbsp;Extended query syntax</h2></div></div></div>
<p>The following special operators and modifiers can be used when
      using the extended matching mode: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>operator OR: </p><pre class="programlisting">hello | world</pre></li>
<li class="listitem"><p>operator NOT: </p><pre class="programlisting">hello -world
hello !world
</pre></li>
<li class="listitem"><p>field search operator: </p><pre class="programlisting">@title hello @body world</pre></li>
<li class="listitem"><p>field position limit modifier (introduced in version
            0.9.9-rc1): </p><pre class="programlisting">@body[50] hello</pre></li>
<li class="listitem"><p>multiple-field search operator: </p><pre class="programlisting">@(title,body) hello world</pre></li>
<li class="listitem"><p>all-field search operator: </p><pre class="programlisting">@* hello</pre></li>
<li class="listitem"><p>phrase search operator: </p><pre class="programlisting">"hello world"</pre></li>
<li class="listitem"><p>proximity search operator: </p><pre class="programlisting">"hello world"~10</pre></li>
<li class="listitem"><p>quorum matching operator: </p><pre class="programlisting">"the world is a wonderful place"/3</pre></li>
<li class="listitem"><p>strict order operator (aka operator "before"):
            </p><pre class="programlisting">aaa &lt;&lt; bbb &lt;&lt; ccc</pre></li>
<li class="listitem"><p>exact form modifier (introduced in version 0.9.9-rc1):
            </p><pre class="programlisting">raining =cats and =dogs</pre></li>
<li class="listitem"><p>field-start and field-end modifier (introduced in version
            0.9.9-rc2): </p><pre class="programlisting">^hello world$</pre></li>
<li class="listitem"><p>NEAR, generalized proximity operator (introduced in version
            2.0.1-beta): </p><pre class="programlisting">hello NEAR/3 world NEAR/4 "my test"</pre></li>
<li class="listitem"><p>SENTENCE operator (introduced in version 2.0.1-beta):
            </p><pre class="programlisting">all SENTENCE words SENTENCE "in one sentence"</pre></li>
<li class="listitem"><p>PARAGRAPH operator (introduced in version 2.0.1-beta):
            </p><pre class="programlisting">"Bill Gates" PARAGRAPH "Steve Jobs"</pre></li>
<li class="listitem"><p>zone limit operator: </p><pre class="programlisting">ZONE:(h3,h4) only in these titles</pre></li>
</ul></div>
<p> Here's an example query that uses some of these
      operators: </p><div class="example"><a name="ex-extended-query"></a><p class="title"><b>Example&nbsp;5.2.&nbsp;Extended matching mode: query example</b></p><div class="example-contents"><pre class="programlisting">"hello world" @title "example program"~5 @body python -(php|perl) @* code
</pre></div></div>
<p><br class="example-break"> The full meaning of this search is: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Find the words 'hello' and 'world' adjacently in any field
            in a document;</p></li>
<li class="listitem"><p>Additionally, the same document must also contain the words
            'example' and 'program' in the title field, with up to, but not
            including, 10 words between the words in question; (E.g. "example
            PHP program" would be matched however "example script to introduce
            outside data into the correct context for your program" would not
            because two terms have 10 or more words between them)</p></li>
<li class="listitem"><p>Additionally, the same document must contain the word
            'python' in the body field, but not contain either 'php' or
            'perl';</p></li>
<li class="listitem"><p>Additionally, the same document must contain the word 'code'
            in any field.</p></li>
</ul></div>
<p>There always is implicit AND operator, so "hello world" means that
      both "hello" and "world" must be present in matching document.</p><p>OR operator precedence is higher than AND, so "looking for cat |
      dog | mouse" means "looking for ( cat | dog | mouse )" and
      <span class="emphasis"><em>not</em></span> "(looking for cat) | dog | mouse".</p><p>Field limit operator limits subsequent searching to a given field.
      Normally, query will fail with an error message if given field name does
      not exist in the searched index. However, that can be suppressed by
      specifying "@@relaxed" option at the very beginning of the query:
      </p><pre class="programlisting">@@relaxed @nosuchfield my query
</pre><p> This can be helpful when searching through heterogeneous
      indexes with different schemas.</p><p>Field position limit, introduced in version 0.9.9-rc1, additionaly
      restricts the searching to first N position within given field (or
      fields). For example, "@body[50] hello" will <span class="bold"><strong>not</strong></span> match the
      documents where the keyword 'hello' occurs at position 51 and below in
      the body.</p><p>Proximity distance is specified in words, adjusted for word count,
      and applies to all words within quotes. For instance, "cat dog mouse"~5
      query means that there must be less than 8-word span which contains all
      3 words, ie. "CAT aaa bbb ccc DOG eee fff MOUSE" document will
      <span class="emphasis"><em>not</em></span> match this query, because this span is exactly
      8 words long.</p><p>Quorum matching operator introduces a kind of fuzzy matching. It
      will only match those documents that pass a given threshold of given
      words. The example above ("the world is a wonderful place"/3) will match
      all documents that have at least 3 of the 6 specified words.</p><p>Strict order operator (aka operator "before"), introduced in
      version 0.9.9-rc2, will match the document only if its argument keywords
      occur in the document exactly in the query order. For instance, "black
      &lt;&lt; cat" query (without quotes) will match the document "black and
      white cat" but <span class="emphasis"><em>not</em></span> the "that cat was black"
      document. Order operator has the lowest priority. It can be applied both
      to just keywords and more complex expressions, ie. this is a valid
      query: </p><pre class="programlisting">(bag of words) &lt;&lt; "exact phrase" &lt;&lt; red|green|blue
</pre><p>Exact form keyword modifier, introduced in version 0.9.9-rc1, will
      match the document only if the keyword occurred in exactly the specified
      form. The default behaviour is to match the document if the stemmed
      keyword matches. For instance, "runs" query will match both the document
      that contains "runs" <span class="emphasis"><em>and</em></span> the document that contains
      "running", because both forms stem to just "run" - while "=runs" query
      will only match the first document. Exact form operator requires <a class="link" href="#conf-index-exact-words" title="11.2.42.&nbsp;index_exact_words">index_exact_words</a> option to be
      enabled. This is a modifier that affects the keyword and thus can be
      used within operators such as phrase, proximity, and quorum
      operators.</p><p>Field-start and field-end keyword modifiers, introduced in version
      0.9.9-rc2, will make the keyword match only if it occurred at the very
      start or the very end of a fulltext field, respectively. For instance,
      the query "^hello world$" (with quotes and thus combining phrase
      operator and start/end modifiers) will only match documents that contain
      at least one field that has exactly these two keywords.</p><p>Starting with 0.9.9-rc1, arbitrarily nested brackets and negations
      are allowed. However, the query must be possible to compute without
      involving an implicit list of all documents: </p><pre class="programlisting">// correct query
aaa -(bbb -(ccc ddd))

// queries that are non-computable
-aaa
aaa | -bbb
</pre><p><span class="bold"><strong>NEAR operator</strong></span>, added in 2.0.1-beta, is a generalized
      version of a proximity operator. The syntax is <code class="code">NEAR/N</code>, it
      is case-sensitive, and no spaces are allowed beetwen the NEAR keyword,
      the slash sign, and the distance value.</p><p>The original proximity operator only worked on sets of keywords.
      NEAR is more generic and can accept arbitrary subexpressions as its two
      arguments, matching the document when both subexpressions are found
      within N words of each other, no matter in which order. NEAR is left
      associative and has the same (lowest) precedence as BEFORE.</p><p>You should also note how a <code class="code">(one NEAR/7 two NEAR/7
      three)</code> query using NEAR is not really equivalent to a <code class="code">("one
      two three"~7)</code> one using keyword proximity operator. The
      difference here is that the proximity operator allows for up to 6
      non-matching words between all the 3 matching words, but the version
      with NEAR is less restrictive: it would allow for up to 6 words between
      'one' and 'two' and then for up to 6 more between that two-word matching
      and a 'three' keyword.</p><p><span class="bold"><strong>SENTENCE and PARAGRAPH operators</strong></span>, added in 2.0.1-beta,
      matches the document when both its arguments are within the same
      sentence or the same paragraph of text, respectively. The arguments can
      be either keywords, or phrases, or the instances of the same operator.
      Here are a few examples: </p><pre class="programlisting">one SENTENCE two
one SENTENCE "two three"
one SENTENCE "two three" SENTENCE four
</pre><p> The order of the arguments within the sentence or paragraph
      does not matter. These operators only work on indexes built with <a class="link" href="#conf-index-sp" title="11.2.8.&nbsp;index_sp">index_sp</a> (sentence and paragraph indexing
      feature) enabled, and revert to a mere AND otherwise. Refer to the
      <code class="code">index_sp</code> directive documentation for the notes on what's
      considered a sentence and a paragraph.</p><p><span class="bold"><strong>ZONE limit operator</strong></span>, added in 2.0.1-beta, is quite similar
      to field limit operator, but restricts matching to a given in-field zone
      or a list of zones. Note that the subsequent subexpressions are
      <span class="emphasis"><em>not</em></span> required to match in a single contiguous span
      of a given zone, and may match in multiple spans. For instance,
      <code class="code">(ZONE:th hello world)</code> query <span class="emphasis"><em>will</em></span> match
      this example document: </p><pre class="programlisting">&lt;th&gt;Table 1. Local awareness of Hello Kitty brand.&lt;/th&gt;
.. some table data goes here ..
&lt;th&gt;Table 2. World-wide brand awareness.&lt;/th&gt;
</pre><p> ZONE operator affects the query until the next field or ZONE
      limit operator, or the closing parenthesis. It only works on the indexes
      built with zones support (see <a class="xref" href="#conf-index-zones" title="11.2.9.&nbsp;index_zones">Section&nbsp;11.2.9, “index_zones”</a>) and
      will be ignored otherwise.</p></div>
<div class="sect1" title="5.4.&nbsp;Weighting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="weighting"></a>5.4.&nbsp;Weighting</h2></div></div></div>
<p>Specific weighting function (currently) depends on the search
      mode.</p><p>There are these major parts which are used in the weighting
      functions: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>phrase rank,</p></li>
<li class="listitem"><p>statistical rank.</p></li>
</ol></div>
<p>Phrase rank is based on a length of longest common subsequence
      (LCS) of search words between document body and query phrase. So if
      there's a perfect phrase match in some document then its phrase rank
      would be the highest possible, and equal to query words count.</p><p>Statistical rank is based on classic BM25 function which only
      takes word frequencies into account. If the word is rare in the whole
      database (ie. low frequency over document collection) or mentioned a lot
      in specific document (ie. high frequency over matching document), it
      receives more weight. Final BM25 weight is a floating point number
      between 0 and 1.</p><p>In all modes, per-field weighted phrase ranks are computed as a
      product of LCS multiplied by per-field weight speficifed by user.
      Per-field weights are integer, default to 1, and can not be set lower
      than 1.</p><p>In SPH_MATCH_BOOLEAN mode, no weighting is performed at all, every
      match weight is set to 1.</p><p>In SPH_MATCH_ALL and SPH_MATCH_PHRASE modes, final weight is a sum
      of weighted phrase ranks.</p><p>In SPH_MATCH_ANY mode, the idea is essentially the same, but it
      also adds a count of matching words in each field. Before that, weighted
      phrase ranks are additionally mutliplied by a value big enough to
      guarantee that higher phrase rank in <span class="bold"><strong>any</strong></span> field will make the match ranked higher, even
      if it's field weight is low.</p><p>In SPH_MATCH_EXTENDED mode, final weight is a sum of weighted
      phrase ranks and BM25 weight, multiplied by 1000 and rounded to
      integer.</p><p>This is going to be changed, so that MATCH_ALL and MATCH_ANY modes
      use BM25 weights as well. This would improve search results in those
      match spans where phrase ranks are equal; this is especially useful for
      1-word queries.</p><p>The key idea (in all modes, besides boolean) is that better
      subphrase matches are ranked higher, and perfect matches are pulled to
      the top. Author's experience is that this phrase proximity based ranking
      provides noticeably better search quality than any statistical scheme
      alone (such as BM25, which is commonly used in other search
      engines).</p></div>
<div class="sect1" title="5.5.&nbsp;Expressions, functions, and operators"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="expressions"></a>5.5.&nbsp;Expressions, functions, and operators</h2></div></div></div>
<p>Sphinx lets you use arbitrary arithmetic expressions both via
      SphinxQL and SphinxAPI, involving attribute values, internal attributes
      (document ID and relevance weight), arithmetic operations, a number of
      built-in functions, and user-defined functions. This section documents
      the supported operators and functions. Here's the complete reference
      list for quick access. </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><a class="link" href="#expr-ari-ops">Arithmetic operators: +, -, *,
            /, %, DIV, MOD</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-comp-ops">Comparison operators: &lt;,
            &gt; &lt;=, &gt;=, =, &lt;&gt;</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-bool-ops">Boolean operators: AND, OR,
            NOT</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-bitwise-ops">Bitwise operators: &amp;,
            |</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-abs">ABS()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-bigint">BIGINT()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-ceil">CEIL()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-cos">COS()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-crc32">CRC32()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-day">DAY()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-exp">EXP()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-floor">FLOOR()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-geodist">GEODIST()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-idiv">IDIV()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-if">IF()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-in">IN()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-interval">INTERVAL()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-ln">LN()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-log10">LOG10()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-log2">LOG2()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-max">MAX()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-min">MIN()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-month">MONTH()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-now">NOW()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-pow">POW()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-sin">SIN()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-sint">SINT()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-sqrt">SQRT()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-year">YEAR()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-yearmonth">YEARMONTH()</a></p></li>
<li class="listitem"><p><a class="link" href="#expr-func-yearmonthday">YEARMONTHDAY()</a></p></li>
</ul></div>
<div class="sect2" title="5.5.1.&nbsp;Operators"><div class="titlepage"><div><div><h3 class="title"><a name="operators"></a>5.5.1.&nbsp;Operators</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-ari-ops"></a>Arithmetic operators: +, -, *, /, %, DIV,
            MOD</span></dt>
<dd><p>The standard arithmetic operators. Arithmetic calculations
              involving those can be performed in three different modes: (a)
              using single-precision, 32-bit IEEE 754 floating point values
              (the default), (b) using signed 32-bit integers, (c) using
              64-bit signed integers. The expression parser will automatically
              switch to integer mode if there are no operations the result in
              a floating point value. Otherwise, it will use the default
              floating point mode. For instance, <code class="code">a+b</code> will be
              computed using 32-bit integers if both arguments are 32-bit
              integers; or using 64-bit integers if both arguments are
              integers but one of them is 64-bit; or in floats otherwise.
              However, <code class="code">a/b</code> or <code class="code">sqrt(a)</code> will always be
              computed in floats, because these operations return a result of
              non-integer type. To avoid the first, you can either use
              <code class="code">IDIV(a,b)</code> or <code class="code">a DIV b</code> form. Also,
              <code class="code">a*b</code> will not be automatically promoted to 64-bit
              when the arguments are 32-bit. To enforce 64-bit results, you
              can use BIGINT(). (But note that if there are non-integer
              operations, BIGINT() will simply be ignored.)</p></dd><dt><span class="term"><a name="expr-comp-ops"></a>Comparison operators: &lt;, &gt; &lt;=,
            &gt;=, =, &lt;&gt;</span></dt>
<dd><p>Comparison operators (eg. = or &lt;=) return 1.0 when the
              condition is true and 0.0 otherwise. For instance,
              <code class="code">(a=b)+3</code> will evaluate to 4 when attribute 'a' is
              equal to attribute 'b', and to 3 when 'a' is not. Unlike MySQL,
              the equality comparisons (ie. = and &lt;&gt; operators)
              introduce a small equality threshold (1e-6 by default). If the
              difference between compared values is within the threshold, they
              will be considered equal.</p></dd><dt><span class="term"><a name="expr-bool-ops"></a>Boolean operators: AND, OR, NOT</span></dt>
<dd><p>Boolean operators (AND, OR, NOT) were introduced in
              0.9.9-rc2 and behave as usual. They are left-associative and
              have the least priority compared to other operators. NOT has
              more priority than AND and OR but nevertheless less than any
              other operator. AND and OR have the same priority so brackets
              use is recommended to avoid confusion in complex
              expressions.</p></dd><dt><span class="term"><a name="expr-bitwise-ops"></a>Bitwise operators: &amp;, |</span></dt>
<dd><p>These operators perform bitwise AND and OR respectively.
              The operands must be of an integer types. Introduced in version
              1.10-beta.</p></dd></dl></div></div>
<div class="sect2" title="5.5.2.&nbsp;Numeric functions"><div class="titlepage"><div><div><h3 class="title"><a name="numeric-functions"></a>5.5.2.&nbsp;Numeric functions</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-func-abs"></a>ABS()</span></dt>
<dd><p>Returns the absolute value of the argument.</p></dd><dt><span class="term"><a name="expr-func-ceil"></a>CEIL()</span></dt>
<dd><p>Returns the smallest integer value greater or equal to the
              argument.</p></dd><dt><span class="term"><a name="expr-func-cos"></a>COS()</span></dt>
<dd><p>Returns the cosine of the argument.</p></dd><dt><span class="term"><a name="expr-func-exp"></a>EXP()</span></dt>
<dd><p>Returns the exponent of the argument (e=2.718... to the
              power of the argument).</p></dd><dt><span class="term"><a name="expr-func-floor"></a>FLOOR()</span></dt>
<dd><p>Returns the largest integer value lesser or equal to the
              argument.</p></dd><dt><span class="term"><a name="expr-func-idiv"></a>IDIV()</span></dt>
<dd><p>Returns the result of an integer division of the first
              argument by the second argument. Both arguments must be of an
              integer type.</p></dd><dt><span class="term"><a name="expr-func-ln"></a>LN()</span></dt>
<dd><p>Returns the natural logarithm of the argument (with the
              base of e=2.718...).</p></dd><dt><span class="term"><a name="expr-func-log10"></a>LOG10()</span></dt>
<dd><p>Returns the common logarithm of the argument (with the
              base of 10).</p></dd><dt><span class="term"><a name="expr-func-log2"></a>LOG2()</span></dt>
<dd><p>Returns the binary logarithm of the argument (with the
              base of 2).</p></dd><dt><span class="term"><a name="expr-func-max"></a>MAX()</span></dt>
<dd><p>Returns the bigger of two arguments.</p></dd><dt><span class="term"><a name="expr-func-min"></a>MIN()</span></dt>
<dd><p>Returns the smaller of two arguments.</p></dd><dt><span class="term"><a name="expr-func-pow"></a>POW()</span></dt>
<dd><p>Returns the first argument raised to the power of the
              second argument.</p></dd><dt><span class="term"><a name="expr-func-sin"></a>SIN()</span></dt>
<dd><p>Returns the sine of the argument.</p></dd><dt><span class="term"><a name="expr-func-sqrt"></a>SQRT()</span></dt>
<dd><p>Returns the square root of the argument.</p></dd></dl></div></div>
<div class="sect2" title="5.5.3.&nbsp;Date and time functions"><div class="titlepage"><div><div><h3 class="title"><a name="date-time-functions"></a>5.5.3.&nbsp;Date and time functions</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-func-day"></a>DAY()</span></dt>
<dd><p>Returns the integer day of month (in 1..31 range) from a
              timestamp argument, according to the current timezone.
              Introduced in version 2.0.1-beta.</p></dd><dt><span class="term"><a name="expr-func-month"></a>MONTH()</span></dt>
<dd><p>Returns the integer month (in 1..12 range) from a
              timestamp argument, according to the current timezone.
              Introduced in version 2.0.1-beta.</p></dd><dt><span class="term"><a name="expr-func-now"></a>NOW()</span></dt>
<dd><p>Returns the current timestamp as an INTEGER. Introduced in
              version 0.9.9-rc1.</p></dd><dt><span class="term"><a name="expr-func-year"></a>YEAR()</span></dt>
<dd><p>Returns the integer year (in 1969..2038 range) from a
              timestamp argument, according to the current timezone.
              Introduced in version 2.0.1-beta.</p></dd><dt><span class="term"><a name="expr-func-yearmonth"></a>YEARMONTH()</span></dt>
<dd><p>Returns the integer year and month code (in 196912..203801
              range) from a timestamp argument, according to the current
              timezone. Introduced in version 2.0.1-beta.</p></dd><dt><span class="term"><a name="expr-func-yearmonthday"></a>YEARMONTHDAY()</span></dt>
<dd><p>Returns the integer year, month, and date code (in
              19691231..20380119 range) from a timestamp argument, according
              to the current timezone. Introduced in version
              2.0.1-beta.</p></dd></dl></div></div>
<div class="sect2" title="5.5.4.&nbsp;Type conversion functions"><div class="titlepage"><div><div><h3 class="title"><a name="type-conversion-functions"></a>5.5.4.&nbsp;Type conversion functions</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-func-bigint"></a>BIGINT()</span></dt>
<dd><p>Forcibly promotes the integer argument to 64-bit type, and
              does nothing on floating point argument. It's intended to help
              enforce evaluation of certain expressions (such as
              <code class="code">a*b</code>) in 64-bit mode even though all the arguments
              are 32-bit. Introduced in version 0.9.9-rc1.</p></dd><dt><span class="term"><a name="expr-func-sint"></a>SINT()</span></dt>
<dd><p>Forcibly reinterprets its 32-bit unsigned integer argument
              as signed, and also expands it to 64-bit type (because 32-bit
              type is unsigned). It's easily illustrated by the following
              example: 1-2 normally evaluates to 4294967295, but SINT(1-2)
              evaluates to -1. Introduced in version 1.10-beta.</p></dd></dl></div></div>
<div class="sect2" title="5.5.5.&nbsp;Comparison functions"><div class="titlepage"><div><div><h3 class="title"><a name="comparison-functions"></a>5.5.5.&nbsp;Comparison functions</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-func-if"></a>IF()</span></dt>
<dd><p><code class="code">IF()</code> behavior is slightly different that that
              of its MySQL counterpart. It takes 3 arguments, check whether
              the 1st argument is equal to 0.0, returns the 2nd argument if it
              is not zero, or the 3rd one when it is. Note that unlike
              comparison operators, <code class="code">IF()</code> does <span class="bold"><strong>not</strong></span> use a
              threshold! Therefore, it's safe to use comparison results as its
              1st argument, but arithmetic operators might produce unexpected
              results. For instance, the following two calls will produce
              <span class="emphasis"><em>different</em></span> results even though they are
              logically equivalent: </p><pre class="programlisting">IF ( sqrt(3)*sqrt(3)-3&lt;&gt;0, a, b )
IF ( sqrt(3)*sqrt(3)-3, a, b )
</pre><p> In the first case, the comparison operator &lt;&gt; will
              return 0.0 (false) because of a threshold, and <code class="code">IF()</code>
              will always return 'b' as a result. In the second one, the same
              <code class="code">sqrt(3)*sqrt(3)-3</code> expression will be compared with
              zero <span class="emphasis"><em>without</em></span> threshold by the
              <code class="code">IF()</code> function itself. But its value will be
              slightly different from zero because of limited floating point
              calculations precision. Because of that, the comparison with 0.0
              done by <code class="code">IF()</code> will not pass, and the second variant
              will return 'a' as a result.</p></dd><dt><span class="term"><a name="expr-func-in"></a>IN()</span></dt>
<dd><p>IN(expr,val1,val2,...), introduced in version 0.9.9-rc1,
              takes 2 or more arguments, and returns 1 if 1st argument (expr)
              is equal to any of the other arguments (val1..valN), or 0
              otherwise. Currently, all the checked values (but not the
              expression itself!) are required to be constant. (Its
              technically possible to implement arbitrary expressions too, and
              that might be implemented in the future.) Constants are
              pre-sorted and then binary search is used, so IN() even against
              a big arbitrary list of constants will be very quick. Starting
              with 0.9.9-rc2, first argument can also be a MVA attribute. In
              that case, IN() will return 1 if any of the MVA values is equal
              to any of the other arguments. Starting with 2.0.1-beta, IN()
              also supports <code class="code">IN(expr,@uservar)</code> syntax to check
              whether the value belongs to the list in the given global user
              variable.</p></dd><dt><span class="term"><a name="expr-func-interval"></a>INTERVAL()</span></dt>
<dd><p>INTERVAL(expr,point1,point2,point3,...), introduced in
              version 0.9.9-rc1, takes 2 or more arguments, and returns the
              index of the argument that is less than the first argument: it
              returns 0 if expr&lt;point1, 1 if point1&lt;=expr&lt;point2, and
              so on. It is required that point1&lt;point2&lt;...&lt;pointN for
              this function to work correctly.</p></dd></dl></div></div>
<div class="sect2" title="5.5.6.&nbsp;Miscellaneous functions"><div class="titlepage"><div><div><h3 class="title"><a name="misc-functions"></a>5.5.6.&nbsp;Miscellaneous functions</h3></div></div></div>
<div class="variablelist"><dl><dt><span class="term"><a name="expr-func-crc32"></a>CRC32()</span></dt>
<dd><p>Returns the CRC32 value of a string argument. Introduced
              in version 2.0.1-beta.</p></dd><dt><span class="term"><a name="expr-func-geodist"></a>GEODIST()</span></dt>
<dd><p>GEODIST(lat1,long1,lat2,long2) function, introduced in
              version 0.9.9-rc2, computes geosphere distance between two given
              points specified by their coordinates. Note that both latitudes
              and longitudes must be in radians and the result will be in
              meters. You can use arbitrary expression as any of the four
              coordinates. An optimized path will be selected when one pair of
              the arguments refers directly to a pair attributes and the other
              one is constant.</p></dd></dl></div></div></div>
<div class="sect1" title="5.6.&nbsp;Sorting modes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sorting-modes"></a>5.6.&nbsp;Sorting modes</h2></div></div></div>
<p>There are the following result sorting modes available:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>SPH_SORT_RELEVANCE mode, that sorts by relevance in
            descending order (best matches first);</p></li>
<li class="listitem"><p>SPH_SORT_ATTR_DESC mode, that sorts by an attribute in
            descending order (bigger attribute values first);</p></li>
<li class="listitem"><p>SPH_SORT_ATTR_ASC mode, that sorts by an attribute in
            ascending order (smaller attribute values first);</p></li>
<li class="listitem"><p>SPH_SORT_TIME_SEGMENTS mode, that sorts by time segments
            (last hour/day/week/month) in descending order, and then by
            relevance in descending order;</p></li>
<li class="listitem"><p>SPH_SORT_EXTENDED mode, that sorts by SQL-like combination
            of columns in ASC/DESC order;</p></li>
<li class="listitem"><p>SPH_SORT_EXPR mode, that sorts by an arithmetic
            expression.</p></li>
</ul></div>
<p>SPH_SORT_RELEVANCE ignores any additional parameters and always
      sorts matches by relevance rank. All other modes require an additional
      sorting clause, with the syntax depending on specific mode.
      SPH_SORT_ATTR_ASC, SPH_SORT_ATTR_DESC and SPH_SORT_TIME_SEGMENTS modes
      require simply an attribute name. SPH_SORT_RELEVANCE is equivalent to
      sorting by "@weight DESC, @id ASC" in extended sorting mode,
      SPH_SORT_ATTR_ASC is equivalent to "attribute ASC, @weight DESC, @id
      ASC", and SPH_SORT_ATTR_DESC to "attribute DESC, @weight DESC, @id ASC"
      respectively.</p><h3>SPH_SORT_TIME_SEGMENTS mode</h3><p>In SPH_SORT_TIME_SEGMENTS mode, attribute values are split into
      so-called time segments, and then sorted by time segment first, and by
      relevance second.</p><p>The segments are calculated according to the <span class="emphasis"><em>current
      timestamp</em></span> at the time when the search is performed, so the
      results would change over time. The segments are as follows:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>last hour,</p></li>
<li class="listitem"><p>last day,</p></li>
<li class="listitem"><p>last week,</p></li>
<li class="listitem"><p>last month,</p></li>
<li class="listitem"><p>last 3 months,</p></li>
<li class="listitem"><p>everything else.</p></li>
</ul></div>
<p> These segments are hardcoded, but it is trivial to
      change them if necessary.</p><p>This mode was added to support searching through blogs, news
      headlines, etc. When using time segments, recent records would be ranked
      higher because of segment, but withing the same segment, more relevant
      records would be ranked higher - unlike sorting by just the timestamp
      attribute, which would not take relevance into account at all.</p><h3><a name="sort-extended"></a>SPH_SORT_EXTENDED mode</h3><p>In SPH_SORT_EXTENDED mode, you can specify an SQL-like sort
      expression with up to 5 attributes (including internal attributes), eg:
      </p><pre class="programlisting">@relevance DESC, price ASC, @id DESC
</pre><p>Both internal attributes (that are computed by the engine on the
      fly) and user attributes that were configured for this index are
      allowed. Internal attribute names must start with magic @-symbol; user
      attribute names can be used as is. In the example above,
      <code class="option">@relevance</code> and <code class="option">@id</code> are internal
      attributes and <code class="option">price</code> is user-specified.</p><p>Known internal attributes are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>@id (match ID)</p></li>
<li class="listitem"><p>@weight (match weight)</p></li>
<li class="listitem"><p>@rank (match weight)</p></li>
<li class="listitem"><p>@relevance (match weight)</p></li>
<li class="listitem"><p>@random (return results in random order)</p></li>
</ul></div>
<p> <code class="option">@rank</code> and <code class="option">@relevance</code>
      are just additional aliases to <code class="option">@weight</code>.</p><h3><a name="sort-expr"></a>SPH_SORT_EXPR mode</h3><p>Expression sorting mode lets you sort the matches by an arbitrary
      arithmetic expression, involving attribute values, internal attributes
      (@id and @weight), arithmetic operations, and a number of built-in
      functions. Here's an example: </p><pre class="programlisting">$cl-&gt;SetSortMode ( SPH_SORT_EXPR,
	"@weight + ( user_karma + ln(pageviews) )*0.1" );
</pre><p> The operators and functions supported in the expressions are
      discussed in a separate section, <a class="xref" href="#expressions" title="5.5.&nbsp;Expressions, functions, and operators">Section&nbsp;5.5, “Expressions, functions, and operators”</a>.</p></div>
<div class="sect1" title="5.7.&nbsp;Grouping (clustering) search results"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="clustering"></a>5.7.&nbsp;Grouping (clustering) search results</h2></div></div></div>
<p>Sometimes it could be useful to group (or in other terms, cluster)
      search results and/or count per-group match counts - for instance, to
      draw a nice graph of how much maching blog posts were there per each
      month; or to group Web search results by site; or to group matching
      forum posts by author; etc.</p><p>In theory, this could be performed by doing only the full-text
      search in Sphinx and then using found IDs to group on SQL server side.
      However, in practice doing this with a big result set (10K-10M matches)
      would typically kill performance.</p><p>To avoid that, Sphinx offers so-called grouping mode. It is
      enabled with SetGroupBy() API call. When grouping, all matches are
      assigned to different groups based on group-by value. This value is
      computed from specified attribute using one of the following built-in
      functions: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>SPH_GROUPBY_DAY, extracts year, month and day in YYYYMMDD
            format from timestamp;</p></li>
<li class="listitem"><p>SPH_GROUPBY_WEEK, extracts year and first day of the week
            number (counting from year start) in YYYYNNN format from
            timestamp;</p></li>
<li class="listitem"><p>SPH_GROUPBY_MONTH, extracts month in YYYYMM format from
            timestamp;</p></li>
<li class="listitem"><p>SPH_GROUPBY_YEAR, extracts year in YYYY format from
            timestamp;</p></li>
<li class="listitem"><p>SPH_GROUPBY_ATTR, uses attribute value itself for
            grouping.</p></li>
</ul></div>
<p>The final search result set then contains one best match per
      group. Grouping function value and per-group match count are returned
      along as "virtual" attributes named <span class="bold"><strong>@group</strong></span> and <span class="bold"><strong>@count</strong></span> respectively.</p><p>The result set is sorted by group-by sorting clause, with the
      syntax similar to <a class="link" href="#sort-extended" title="5.6.&nbsp;SPH_SORT_EXTENDED mode"><code class="option">SPH_SORT_EXTENDED</code> sorting
      clause</a> syntax. In addition to <code class="option">@id</code> and
      <code class="option">@weight</code>, group-by sorting clause may also include:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>@group (groupby function value),</p></li>
<li class="listitem"><p>@count (amount of matches in group).</p></li>
</ul></div>
<p>The default mode is to sort by groupby value in descending order,
      ie. by <code class="option">"@group desc"</code>.</p><p>On completion, <code class="option">total_found</code> result parameter would
      contain total amount of matching groups over he whole index.</p><p><span class="bold"><strong>WARNING:</strong></span> grouping is done in
      fixed memory and thus its results are only approximate; so there might
      be more groups reported in <code class="option">total_found</code> than actually
      present. <code class="option">@count</code> might also be underestimated. To reduce
      inaccuracy, one should raise <code class="option">max_matches</code>. If
      <code class="option">max_matches</code> allows to store all found groups, results
      will be 100% correct.</p><p>For example, if sorting by relevance and grouping by
      <code class="code">"published"</code> attribute with <code class="code">SPH_GROUPBY_DAY</code>
      function, then the result set will contain </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>one most relevant match per each day when there were any
            matches published,</p></li>
<li class="listitem"><p>with day number and per-day match count attached,</p></li>
<li class="listitem"><p>sorted by day number in descending order (ie. recent days
            first).</p></li>
</ul></div>
<p>Starting with version 0.9.9-rc2, aggregate functions (AVG(),
      MIN(), MAX(), SUM()) are supported through <a class="link" href="#api-func-setselect" title="8.2.4.&nbsp;SetSelect">SetSelect()</a> API call when using
      GROUP BY.</p></div>
<div class="sect1" title="5.8.&nbsp;Distributed searching"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="distributed"></a>5.8.&nbsp;Distributed searching</h2></div></div></div>
<p>To scale well, Sphinx has distributed searching capabilities.
      Distributed searching is useful to improve query latency (ie. search
      time) and throughput (ie. max queries/sec) in multi-server, multi-CPU or
      multi-core environments. This is essential for applications which need
      to search through huge amounts data (ie. billions of records and
      terabytes of text).</p><p>The key idea is to horizontally partition (HP) searched data
      accross search nodes and then process it in parallel.</p><p>Partitioning is done manually. You should </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>setup several instances of Sphinx programs
            (<code class="filename">indexer</code> and <code class="filename">searchd</code>) on
            different servers;</p></li>
<li class="listitem"><p>make the instances index (and search) different parts of
            data;</p></li>
<li class="listitem"><p>configure a special distributed index on some of the
            <code class="filename">searchd</code> instances;</p></li>
<li class="listitem"><p>and query this index.</p></li>
</ul></div>
<p> This index only contains references to other local and
      remote indexes - so it could not be directly reindexed, and you should
      reindex those indexes which it references instead.</p><p>When <code class="filename">searchd</code> receives a query against
      distributed index, it does the following: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>connects to configured remote agents;</p></li>
<li class="listitem"><p>issues the query;</p></li>
<li class="listitem"><p>sequentially searches configured local indexes (while the
            remote agents are searching);</p></li>
<li class="listitem"><p>retrieves remote agents' search results;</p></li>
<li class="listitem"><p>merges all the results together, removing the
            duplicates;</p></li>
<li class="listitem"><p>sends the merged resuls to client.</p></li>
</ol></div>
<p>From the application's point of view, there are no differences
      between searching through a regular index, or a distributed index at
      all. That is, distributed indexes are fully transparent to the
      application, and actually there's no way to tell whether the index you
      queried was distributed or local. (Even though as of 0.9.9 Sphinx does
      not allow to combine searching through distributed indexes with anything
      else, this constraint will be lifted in the future.)</p><p>Any <code class="filename">searchd</code> instance could serve both as a
      master (which aggregates the results) and a slave (which only does local
      searching) at the same time. This has a number of uses: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>every machine in a cluster could serve as a master which
            searches the whole cluster, and search requests could be balanced
            between masters to achieve a kind of HA (high availability) in
            case any of the nodes fails;</p></li>
<li class="listitem"><p>if running within a single multi-CPU or multi-core machine,
            there would be only 1 searchd instance quering itself as an agent
            and thus utilizing all CPUs/core.</p></li>
</ol></div>
<p>It is scheduled to implement better HA support which would allow
      to specify which agents mirror each other, do health checks, keep track
      of alive agents, load-balance requests, etc.</p></div>
<div class="sect1" title="5.9.&nbsp;searchd query log formats"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="query-log-format"></a>5.9.&nbsp;<code class="filename">searchd</code> query log formats</h2></div></div></div>
<p>In version 2.0.1-beta and above two query log formats are
      supported. Previous versions only supported a custom plain text format.
      That format is still the default one. However, while it might be more
      convenient for manual monitoring and review, but hard to replay for
      benchmarks, it only logs <span class="emphasis"><em>search</em></span> queries but not the
      other types of requests, does not always contain the complete search
      query data, etc. The default text format is also harder (and sometimes
      impossible) to replay for benchmarking purposes. The new
      <code class="code">sphinxql</code> format alleviates that. It aims to be complete and
      automatable, even though at the cost of brevity and readability.</p><div class="sect2" title="5.9.1.&nbsp;Plain log format"><div class="titlepage"><div><div><h3 class="title"><a name="plain-log-format"></a>5.9.1.&nbsp;Plain log format</h3></div></div></div>
<p>By default, <code class="filename">searchd</code> logs all succesfully
        executed search queries into a query log file. Here's an example:
        </p><pre class="programlisting">[Fri Jun 29 21:17:58 2007] 0.004 sec [all/0/rel 35254 (0,20)] [lj] test
[Fri Jun 29 21:20:34 2007] 0.024 sec [all/0/rel 19886 (0,20) @channel_id] [lj] test
</pre><p> This log format is as follows: </p><pre class="programlisting">[query-date] query-time [match-mode/filters-count/sort-mode
    total-matches (offset,limit) @groupby-attr] [index-name] query
</pre><p> Match mode can take one of the following values:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>"all" for SPH_MATCH_ALL mode;</p></li>
<li class="listitem"><p>"any" for SPH_MATCH_ANY mode;</p></li>
<li class="listitem"><p>"phr" for SPH_MATCH_PHRASE mode;</p></li>
<li class="listitem"><p>"bool" for SPH_MATCH_BOOLEAN mode;</p></li>
<li class="listitem"><p>"ext" for SPH_MATCH_EXTENDED mode;</p></li>
<li class="listitem"><p>"ext2" for SPH_MATCH_EXTENDED2 mode;</p></li>
<li class="listitem"><p>"scan" if the full scan mode was used, either by being
              specified with SPH_MATCH_FULLSCAN, or if the query was empty (as
              documented under <a class="link" href="#matching-modes" title="5.1.&nbsp;Matching modes">Matching
              Modes</a>)</p></li>
</ul></div>
<p> Sort mode can take one of the following values:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>"rel" for SPH_SORT_RELEVANCE mode;</p></li>
<li class="listitem"><p>"attr-" for SPH_SORT_ATTR_DESC mode;</p></li>
<li class="listitem"><p>"attr+" for SPH_SORT_ATTR_ASC mode;</p></li>
<li class="listitem"><p>"tsegs" for SPH_SORT_TIME_SEGMENTS mode;</p></li>
<li class="listitem"><p>"ext" for SPH_SORT_EXTENDED mode.</p></li>
</ul></div>
<p>Additionally, if <code class="filename">searchd</code> was started with
        <code class="option">--iostats</code>, there will be a block of data after where
        the index(es) searched are listed.</p><p>A query log entry might take the form of:</p><pre class="programlisting">[Fri Jun 29 21:17:58 2007] 0.004 sec [all/0/rel 35254 (0,20)] [lj]
   [ios=6 kb=111.1 ms=0.5] test
</pre><p>This additional block is information regarding I/O operations in
        performing the search: the number of file I/O operations carried out,
        the amount of data in kilobytes read from the index files and time
        spent on I/O operations (although there is a background processing
        component, the bulk of this time is the I/O operation time).</p></div>
<div class="sect2" title="5.9.2.&nbsp;SphinxQL log format"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxql-log-format"></a>5.9.2.&nbsp;SphinxQL log format</h3></div></div></div>
<p>This is a new log format introduced in 2.0.1-beta, with the
        goals begin logging everything and then some, and in a format easy to
        automate (for insance, automatically replay). New format can either be
        enabled via the <a class="link" href="#conf-query-log-format" title="11.4.6.&nbsp;query_log_format">query_log_format</a> directive in
        the configuration file, or switched back and forth on the fly with the
        <a class="link" href="#sphinxql-set" title="7.7.&nbsp;SET syntax">
            <code class="code">SET GLOBAL query_log_format=...</code>
          </a> statement via SphinxQL. In the new format, the example from
        the previous section would look as follows. (Wrapped below for
        readability, but with just one query per line in the actual log.)
        </p><pre class="programlisting">/* Fri Jun 29 21:17:58.609 2007 2011 conn 2 wall 0.004 found 35254 */
SELECT * FROM lj WHERE MATCH('test') OPTION ranker=proximity;

/* Fri Jun 29 21:20:34 2007.555 conn 3 wall 0.024 found 19886 */
SELECT * FROM lj WHERE MATCH('test') GROUP BY channel_id
OPTION ranker=proximity;
</pre><p> Note that <span class="bold"><strong>all</strong></span> requests would be logged in this
        format, including those sent via SphinxAPI and SphinxSE, not just
        those sent via SphinxQL. Also note, that this kind of logging works
        only with plain log files and will not work if you use 'syslog' for
        logging.</p><p>The features of SphinxQL log format compared to the default text
        one are as follows. </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>All request types should be logged. (This is still work in
              progress.)</p></li>
<li class="listitem"><p>Full statement data will be logged where possible.</p></li>
<li class="listitem"><p>Errors and warnings are logged.</p></li>
<li class="listitem"><p>The log should be automatically replayable via
              SphinxQL.</p></li>
<li class="listitem"><p>Additional performance counters (currently, per-agent
              distributed query times) are logged.</p></li>
</ul></div>
<p> </p><p>Every request (including both SphinxAPI and SphinxQL) request
        must result in exactly one log line. All request types, including
        INSERT, CALL SNIPPETS, etc will eventually get logged, though as of
        time of this writing, that is a work in progress). Every log line must
        be a valid SphinxQL statement that reconstructs the full request,
        except if the logged request is too big and needs shortening for
        performance reasons. Additional messages, counters, etc can be logged
        in the comments section after the request.</p></div></div>
<div class="sect1" title="5.10.&nbsp;MySQL protocol support and SphinxQL"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql"></a>5.10.&nbsp;MySQL protocol support and SphinxQL</h2></div></div></div>
<p>Starting with version 0.9.9-rc2, Sphinx searchd daemon supports
      MySQL binary network protocol and can be accessed with regular MySQL
      API. For instance, 'mysql' CLI client program works well. Here's an
      example of querying Sphinx using MySQL client: </p><pre class="programlisting">$ mysql -P 9306
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
Server version: 0.9.9-dev (r1734)

Type 'help;' or '\h' for help. Type '\c' to clear the buffer.

mysql&gt; SELECT * FROM test1 WHERE MATCH('test') 
    -&gt; ORDER BY group_id ASC OPTION ranker=bm25;
+------+--------+----------+------------+
| id   | weight | group_id | date_added |
+------+--------+----------+------------+
|    4 |   1442 |        2 | 1231721236 |
|    2 |   2421 |      123 | 1231721236 |
|    1 |   2421 |      456 | 1231721236 |
+------+--------+----------+------------+
3 rows in set (0.00 sec)
</pre><p>Note that mysqld was not even running on the test machine.
      Everything was handled by searchd itself.</p><p>The new access method is supported <span class="emphasis"><em>in
      addition</em></span> to native APIs which all still work perfectly well.
      In fact, both access methods can be used at the same time. Also, native
      API is still the default access method. MySQL protocol support needs to
      be additionally configured. This is a matter of 1-line config change,
      adding a new <a class="link" href="#conf-listen" title="11.4.1.&nbsp;listen">listener</a> with mysql41
      specified as a protocol: </p><pre class="programlisting">listen = localhost:9306:mysql41
</pre><p>Just supporting the protocol and not the SQL syntax would be
      useless so Sphinx now also supports a subset of SQL that we dubbed
      SphinxQL. It supports the standard querying all the index types with
      SELECT, modifying RT indexes with INSERT, REPLACE, and DELETE, and much
      more. Full SphinxQL reference is available in <a class="xref" href="#sphinxql-reference" title="Chapter&nbsp;7.&nbsp;SphinxQL reference">Chapter&nbsp;7, <i>SphinxQL reference</i></a>.</p></div>
<div class="sect1" title="5.11.&nbsp;Multi-queries"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="multi-queries"></a>5.11.&nbsp;Multi-queries</h2></div></div></div>
<p>Multi-queries, or query batches, let you send multiple queries to
      Sphinx in one go (more formally, one network request).</p><p>Two API methods that implement multi-query mechanism are <a class="link" href="#api-func-addquery" title="8.6.2.&nbsp;AddQuery">AddQuery()</a> and <a class="link" href="#api-func-runqueries" title="8.6.3.&nbsp;RunQueries">RunQueries()</a>. You can also run
      multiple queries with SphinxQL, see <a class="xref" href="#sphinxql-multi-queries" title="7.18.&nbsp;Multi-statement queries">Section&nbsp;7.18, “Multi-statement queries”</a>. (In fact, regular <a class="link" href="#api-func-addquery" title="8.6.2.&nbsp;AddQuery">Query()</a> call is internally
      implemented as a single AddQuery() call immediately followed by
      RunQueries() call.) AddQuery() captures the current state of all the
      query settings set by previous API calls, and memorizes the query.
      RunQueries() actually sends all the memorized queries, and returns
      multiple result sets. There are no restrictions on the queries at all,
      except just a sanity check on a number of queries in a single batch (see
      <a class="xref" href="#conf-max-batch-queries" title="11.4.25.&nbsp;max_batch_queries">Section&nbsp;11.4.25, “max_batch_queries”</a>).</p><p>Why use multi-queries? Generally, it all boils down to
      performance. First, by sending requests to <code class="filename">searchd</code>
      in a batch instead of one by one, you always save a bit by doing less
      network roundtrips. Second, and somewhat more important, sending queries
      in a batch enables <code class="filename">searchd</code> to perform certain
      internal optimizations. As new types of optimizations are being added
      over time, it generally makes sense to pack all the queries into batches
      where possible, so that simply upgrading Sphinx to a new version would
      automatically enable new optimizations. In the case when there aren't
      any possible batch optimizations to apply, queries will be processed one
      by one internally.</p><p>Why (or rather when) not use multi-queries? Multi-queries requires
      all the queries in a batch to be independent, and sometimes they aren't.
      That is, sometimes query B is based on query A results, and so can only
      be set up after executing query A. For instance, you might want to
      display results from a secondary index if and only if there were no
      results found in a primary index. Or maybe just specify offset into 2nd
      result set based on the amount of matches in the 1st result set. In that
      case, you will have to use separate queries (or separate
      batches).</p><p>As of 0.9.10, there are two major optimizations to be aware of:
      common query optimization (available since 0.9.8); and common subtree
      optimization (available since 0.9.10).</p><p><span class="bold"><strong>Common query optimization</strong></span> means that
      <code class="filename">searchd</code> will identify all those queries in a batch
      where only the sorting and group-by settings differ, and <span class="emphasis"><em>only
      perform searching once</em></span>. For instance, if a batch consists of
      3 queries, all of them are for "ipod nano", but 1st query requests
      top-10 results sorted by price, 2nd query groups by vendor ID and
      requests top-5 vendors sorted by rating, and 3rd query requests max
      price, full-text search for "ipod nano" will only be performed once, and
      its results will be reused to build 3 different result sets.</p><p>So-called <span class="bold"><strong>faceted searching</strong></span> is a particularly important
      case that benefits from this optimization. Indeed, faceted searching can
      be implemented by running a number of queries, one to retrieve search
      results themselves, and a few other ones with same full-text query but
      different group-by settings to retrieve all the required groups of
      results (top-3 authors, top-5 vendors, etc). And as long as full-text
      query and filtering settings stay the same, common query optimization
      will trigger, and greatly improve performance.</p><p><span class="bold"><strong>Common subtree optimization</strong></span> is even more interesting. It
      lets <code class="filename">searchd</code> exploit similarities between batched
      full-text queries. It identifies common full-text query parts (subtress)
      in all queries, and caches them between queries. For instance, look at
      the following query batch: </p><pre class="programlisting">barack obama president
barack obama john mccain
barack obama speech
</pre><p> There's a common two-word part ("barack obama") that can be
      computed only once, then cached and shared across the queries. And
      common subtree optimization does just that. Per-query cache size is
      strictly controlled by <a class="link" href="#conf-subtree-docs-cache" title="11.4.26.&nbsp;subtree_docs_cache">subtree_docs_cache</a> and <a class="link" href="#conf-subtree-hits-cache" title="11.4.27.&nbsp;subtree_hits_cache">subtree_hits_cache</a> directives
      (so that caching <span class="emphasis"><em>all</em></span> sxiteen gazillions of
      documents that match "i am" does not exhaust the RAM and instantly kill
      your server).</p><p>Here's a code sample (in PHP) that fire the same query in 3
      different sorting modes: </p><pre class="programlisting">require ( "sphinxapi.php" );
$cl = new SphinxClient ();
$cl-&gt;SetMatchMode ( SPH_MATCH_EXTENDED2 );

$cl-&gt;SetSortMode ( SPH_SORT_RELEVANCE );
$cl-&gt;AddQuery ( "the", "lj" );
$cl-&gt;SetSortMode ( SPH_SORT_EXTENDED, "published desc" );
$cl-&gt;AddQuery ( "the", "lj" );
$cl-&gt;SetSortMode ( SPH_SORT_EXTENDED, "published asc" );
$cl-&gt;AddQuery ( "the", "lj" );
$res = $cl-&gt;RunQueries();
</pre><p>How to tell whether the queries in the batch were actually
      optimized? If they were, respective query log will have a "multiplier"
      field that specifies how many queries were processed together:
      </p><pre class="programlisting">[Sun Jul 12 15:18:17.000 2009] 0.040 sec x3 [ext2/0/rel 747541 (0,20)] [lj] the
[Sun Jul 12 15:18:17.000 2009] 0.040 sec x3 [ext2/0/ext 747541 (0,20)] [lj] the
[Sun Jul 12 15:18:17.000 2009] 0.040 sec x3 [ext2/0/ext 747541 (0,20)] [lj] the
</pre><p> Note the "x3" field. It means that this query was optimized
      and processed in a sub-batch of 3 queries. For reference, this is how
      the regular log would look like if the queries were not batched:
      </p><pre class="programlisting">[Sun Jul 12 15:18:17.062 2009] 0.059 sec [ext2/0/rel 747541 (0,20)] [lj] the
[Sun Jul 12 15:18:17.156 2009] 0.091 sec [ext2/0/ext 747541 (0,20)] [lj] the
[Sun Jul 12 15:18:17.250 2009] 0.092 sec [ext2/0/ext 747541 (0,20)] [lj] the
</pre><p> Note how per-query time in multi-query case was improved by
      a factor of 1.5x to 2.3x, depending on a particular sorting mode. In
      fact, for both common query and common subtree optimizations, there were
      reports of 3x and even more improvements, and that's from production
      instances, not just synthetic tests.</p></div>
<div class="sect1" title="5.12.&nbsp;Collations"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="collations"></a>5.12.&nbsp;Collations</h2></div></div></div>
<p>Introduced to Sphinx in version 2.0.1-beta to supplement string
      sorting, collations essentially affect the string attribute comparisons.
      They specify both the character set encoding and the strategy that
      Sphinx uses to compare strings when doing ORDER BY or GROUP BY with a
      string attribute involved.</p><p>String attributes are stored as is when indexing, and no character
      set or language information is attached to them. That's okay as long as
      Sphinx only needs to store and return the strings to the calling
      application verbatim. But when you ask Sphinx to sort by a string value,
      that request immediately becomes quite ambiguous.</p><p>First, single-byte (ASCII, or ISO-8859-1, or Windows-1251) strings
      need to be processed differently that the UTF-8 ones that may encode
      every character with a variable number of bytes. So we need to know what
      is the character set type to interepret the raw bytes as meaningful
      characters properly.</p><p>Second, we additionally need to know the language-specific string
      sorting rules. For instance, when sorting according to US rules in en_US
      locale, the accented character 'ï' (small letter i with diaeresis)
      should be placed somewhere after 'z'. However, when sorting with French
      rules and fr_FR locale in mind, it should be placed between 'i' and 'j'.
      And some other set of rules might choose to ignore accents at all,
      allowing 'ï' and 'i' to be mixed arbitrarily.</p><p>Third, but not least, we might need case-sensitive sorting in some
      scenarios and case-insensitive sorting in some others.</p><p>Collations combine all of the above: the character set, the
      lanugage rules, and the case sensitivity. Sphinx currently provides the
      following four collations. </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p><code class="option">libc_ci</code></p></li>
<li class="listitem"><p><code class="option">libc_cs</code></p></li>
<li class="listitem"><p><code class="option">utf8_general_ci</code></p></li>
<li class="listitem"><p><code class="option">binary</code></p></li>
</ol></div>
<p>The first two collations rely on several standard C library (libc)
      calls and can thus support any locale that is installed on your system.
      They provide case-insensitive (_ci) and case-sensitive (_cs) comparisons
      respectively. By default they will use C locale, effectively resorting
      to bytewise comparisons. To change that, you need to specify a different
      available locale using <a class="link" href="#conf-collation-libc-locale" title="11.4.34.&nbsp;collation_libc_locale">collation_libc_locale</a>
      directive. The list of locales available on your system can usually be
      obtained with the <code class="filename">locale</code> command: </p><pre class="programlisting">$ locale -a
C
en_AG
en_AU.utf8
en_BW.utf8
en_CA.utf8
en_DK.utf8
en_GB.utf8
en_HK.utf8
en_IE.utf8
en_IN
en_NG
en_NZ.utf8
en_PH.utf8
en_SG.utf8
en_US.utf8
en_ZA.utf8
en_ZW.utf8
es_ES
fr_FR
POSIX
ru_RU.utf8
ru_UA.utf8
</pre><p>The specific list of the system locales may vary. Consult your OS
      documentation to install additional needed locales.</p><p><code class="option">utf8_general_ci</code> and <code class="option">binary</code>
      locales are built-in into Sphinx. The first one is a generic collation
      for UTF-8 data (without any so-called language tailoring); it should
      behave similar to <code class="option">utf8_general_ci</code> collation in MySQL.
      The second one is a simple bytewise comparison.</p><p>Collation can be overriden via SphinxQL on a per-session basis
      using <code class="code">SET collation_connection</code> statement. All subsequent
      SphinxQL queries will use this collation. SphinxAPI and SphinxSE queries
      will use the server default collation, as specified in <a class="link" href="#conf-collation-server" title="11.4.33.&nbsp;collation_server">collation_server</a> configuration
      directive. Sphinx currently defaults to <code class="option">libc_ci</code>
      collation.</p><p>Collations should affect all string attribute comparisons,
      including those within ORDER BY and GROUP BY, so differently ordered or
      grouped results can be returned depending on the collation
      chosen.</p></div>
<div class="sect1" title="5.13.&nbsp;User-defined functions (UDF)"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="udf"></a>5.13.&nbsp;User-defined functions (UDF)</h2></div></div></div>
<p>Starting with 2.0.1-beta, Sphinx supports User-Defined Functions,
      or UDF for short. They can be loaded and unloaded dynamically into
      <code class="filename">searchd</code> without having to restart the daemon, and
      used in expressions when searching. UDF features at a glance are as
      follows. </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Functions can take integer (both 32-bit and 64-bit), float,
            string, or MVA arguments.</p></li>
<li class="listitem"><p>Functions can return integer or float values.</p></li>
<li class="listitem"><p>Functions can check the argument number, types, and names
            and raise errors.</p></li>
<li class="listitem"><p>Only simple functions (that is, non-aggregate ones) are
            currently supported.</p></li>
</ul></div>
<p>User-defined functions need your OS to support dynamically
      loadable libraries (aka shared objects). Most of the modern OSes are
      eligible, including Linux, Windows, MacOS, Solaris, BSD and others. (The
      internal testing has been done on Linux and Windows.) The UDF libraries
      must reside in a directory specified by <a class="link" href="#conf-plugin-dir" title="11.4.35.&nbsp;plugin_dir">plugin_dir</a> directive, and the server
      must be configured to use <code class="option">workers = threads</code> mode.
      Relative paths to the library files are not allowed. Once the library is
      succesfully built and copied to the trusted location, you can then
      dynamically install and deinstall the functions using <a class="link" href="#sphinxql-create-function" title="7.13.&nbsp;CREATE FUNCTION syntax">CREATE FUNCTION</a> and <a class="link" href="#sphinxql-drop-function" title="7.14.&nbsp;DROP FUNCTION syntax">DROP FUNCTION</a> statements
      respectively. A single library can contain multiple functions. A library
      gets loaded when you first install a function from it, and unloaded when
      you deinstall all the functions from that library.</p><p>The library functions that will implement a UDF visible to SQL
      statements need to follow C calling convention, and a simple naming
      convention. Sphinx source distribution provides a sample file, <a class="ulink" href="http://code.google.com/p/sphinxsearch/source/browse/trunk/src/udfexample.c" target="_top">src/udfexample.c</a>,
      that defines a few simple functions showing how to work with integer,
      string, and MVA arguments; you can use that one as a foundation for your
      new functions. It includes the UDF interface header file, <a class="ulink" href="http://code.google.com/p/sphinxsearch/source/browse/trunk/src/udfexample.c" target="_top">src/sphinxudf.h</a>,
      that defines the required types and structures.
      <code class="filename">sphinxudf.h</code> header is standalone, that is, does not
      require any other parts of Sphinx source to compile.</p><p>Every function that you intend to use in your SELECT statements
      requires at least two corresponding C/C++ functions: the initialization
      call, and the function call itself. You can also optionally define the
      deinitialization call if your function requires any post-query cleanup.
      (For instance, if you were allocating any memory in either the
      initialization call or the function calls.) Function names in SQL are
      case insensitive, C function names are not. They need to be all
      lower-case. Mistakes in function name prevent UDFs from loading. You
      also have to pay special attention to the calling convention used when
      compiling, the list and the types of arguments, and the return type of
      the main function call. Mistakes in either are likely to crash the
      server, or result in unexpected results in the best case. Last but not
      least, all functions need to be thread-safe.</p><p>Let's assume for the sake of example that your UDF name in
      SphinxQL will be <code class="code">MYFUNC</code>. The initialization, main, and
      deinitialization functions would then need to be named as follows and
      take the following arguments: </p><pre class="programlisting">/// initialization function
/// called once during query initialization
/// returns 0 on success
/// returns non-zero and fills error_message buffer on failure
int myfunc_init ( SPH_UDF_INIT * init, SPH_UDF_ARGS * args,
                  char * error_message );

/// main call function
/// returns the computed value
/// writes non-zero value into error_flag to indicate errors
RETURN_TYPE myfunc ( SPH_UDF_INIT * init, SPH_UDF_ARGS * args,
                     char * error_flag );

/// optional deinitialization function
/// called once to cleanup once query processing is done
void myfunc_deinit ( SPH_UDF_INIT * init );
</pre><p> The two mentioned structures, <code class="code">SPH_UDF_INIT</code> and
      <code class="code">SPH_UDF_ARGS</code>, are defined in the
      <code class="filename">src/sphinxudf.h</code> interface header and documented
      there. <code class="code">RETURN_TYPE</code> of the main function must be one of the
      following: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="code">int</code> for the functions that return INT.</p></li>
<li class="listitem"><p><code class="code">sphinx_int64_t</code> for the functions that return
            BIGINT.</p></li>
<li class="listitem"><p><code class="code">float</code> for the functions that return
            FLOAT.</p></li>
</ul></div>
<p>The calling sequence is as follows. <code class="code">myfunc_init()</code> is
      called once when initializing the query. It can return a non-zero code
      to indicate a failure; in that case query is not executed, and the error
      message from the <code class="code">error_message</code> buffer is returned.
      Otherwise, <code class="code">myfunc()</code> is be called for every row, and a
      <code class="code">myfunc_deinit()</code> is then called when the query ends.
      <code class="code">myfunc()</code> can indicate an error by writing a non-zero byte
      value to <code class="code">error_flag</code>, in that case, it will no more be
      called for subsequent rows, and a default value of 0 will be
      substituted. Sphinx might or might not choose to terminate such queries
      early, neither behavior is currently guaranteed.</p></div></div>
<div class="chapter" title="Chapter&nbsp;6.&nbsp;Command line tools reference"><div class="titlepage"><div><div><h2 class="title"><a name="command-line-tools"></a>Chapter&nbsp;6.&nbsp;Command line tools reference</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#ref-indexer">6.1. <code class="filename">indexer</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-searchd">6.2. <code class="filename">searchd</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-search">6.3. <code class="filename">search</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-spelldump">6.4. <code class="filename">spelldump</code> command reference</a></span></dt>
<dt><span class="sect1"><a href="#ref-indextool">6.5. <code class="filename">indextool</code> command reference</a></span></dt>
</dl></div>
<p>As mentioned elsewhere, Sphinx is not a single program called
    'sphinx', but a collection of 4 separate programs which collectively form
    Sphinx. This section covers these tools and how to use them.</p><div class="sect1" title="6.1.&nbsp;indexer command reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref-indexer"></a>6.1.&nbsp;<code class="filename">indexer</code> command reference</h2></div></div></div>
<p><code class="filename">indexer</code> is the first of the two principle
      tools as part of Sphinx. Invoked from either the command line directly,
      or as part of a larger script, <code class="filename">indexer</code> is solely
      responsible for gathering the data that will be searchable.</p><p>The calling syntax for <code class="filename">indexer</code> is as
      follows:</p><pre class="programlisting">indexer [OPTIONS] [indexname1 [indexname2 [...]]]
</pre><p>Essentially you would list the different possible indexes (that
      you would later make available to search) in
      <code class="filename">sphinx.conf</code>, so when calling
      <code class="filename">indexer</code>, as a minimum you need to be telling it
      what index (or indexes) you want to index.</p><p>If <code class="filename">sphinx.conf</code> contained details on 2
      indexes, <code class="filename">mybigindex</code> and
      <code class="filename">mysmallindex</code>, you could do the following:</p><pre class="programlisting">$ indexer mybigindex
$ indexer mysmallindex mybigindex
</pre><p>As part of the configuration file,
      <code class="filename">sphinx.conf</code>, you specify one or more indexes for
      your data. You might call <code class="filename">indexer</code> to reindex one of
      them, ad-hoc, or you can tell it to process all indexes - you are not
      limited to calling just one, or all at once, you can always pick some
      combination of the available indexes.</p><p>The majority of the options for <code class="filename">indexer</code> are
      given in the configuration file, however there are some options you
      might need to specify on the command line as well, as they can affect
      how the indexing operation is performed. These options are:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--config &lt;file&gt;</code> (<code class="option">-c
            &lt;file&gt;</code> for short) tells
            <code class="filename">indexer</code> to use the given file as its
            configuration. Normally, it will look for
            <code class="filename">sphinx.conf</code> in the installation directory
            (e.g. <code class="filename">/usr/local/sphinx/etc/sphinx.conf</code> if
            installed into <code class="filename">/usr/local/sphinx</code>), followed
            by the current directory you are in when calling
            <code class="filename">indexer</code> from the shell. This is most of use
            in shared environments where the binary files are installed
            somewhere like <code class="filename">/usr/local/sphinx/</code> but you
            want to provide users with the ability to make their own custom
            Sphinx set-ups, or if you want to run multiple instances on a
            single server. In cases like those you could allow them to create
            their own <code class="filename">sphinx.conf</code> files and pass them to
            <code class="filename">indexer</code> with this option. For example:
            </p><pre class="programlisting">$ indexer --config /home/myuser/sphinx.conf myindex
</pre></li>
<li class="listitem"><p><code class="option">--all</code> tells <code class="filename">indexer</code> to
            update every index listed in <code class="filename">sphinx.conf</code>,
            instead of listing individual indexes. This would be useful in
            small configurations, or <code class="filename">cron</code>-type or
            maintenance jobs where the entire index set will get rebuilt each
            day, or week, or whatever period is best. Example usage:
            </p><pre class="programlisting">$ indexer --config /home/myuser/sphinx.conf --all
</pre></li>
<li class="listitem"><p><code class="option">--rotate</code> is used for rotating indexes.
            Unless you have the situation where you can take the search
            function offline without troubling users, you will almost
            certainly need to keep search running whilst indexing new
            documents. <code class="option">--rotate</code> creates a second index,
            parallel to the first (in the same place, simply including
            <code class="filename">.new</code> in the filenames). Once complete,
            <code class="filename">indexer</code> notifies <code class="filename">searchd</code>
            via sending the <code class="option">SIGHUP</code> signal, and
            <code class="filename">searchd</code> will attempt to rename the indexes
            (renaming the existing ones to include <code class="filename">.old</code>
            and renaming the <code class="filename">.new</code> to replace them), and
            then start serving from the newer files. Depending on the setting
            of <a class="link" href="#conf-seamless-rotate" title="11.4.12.&nbsp;seamless_rotate">seamless_rotate</a>,
            there may be a slight delay in being able to search the newer
            indexes. Example usage: </p><pre class="programlisting">$ indexer --rotate --all
</pre></li>
<li class="listitem"><p><code class="option">--quiet</code> tells <code class="filename">indexer</code>
            not to output anything, unless there is an error. Again, most used
            for <code class="filename">cron</code>-type, or other script jobs where the
            output is irrelevant or unnecessary, except in the event of some
            kind of error. Example usage: </p><pre class="programlisting">$ indexer --rotate --all --quiet
</pre></li>
<li class="listitem"><p><code class="option">--noprogress</code> does not display progress
            details as they occur; instead, the final status details (such as
            documents indexed, speed of indexing and so on are only reported
            at completion of indexing. In instances where the script is not
            being run on a console (or 'tty'), this will be on by default.
            Example usage: </p><pre class="programlisting">$ indexer --rotate --all --noprogress
</pre></li>
<li class="listitem"><p><code class="option">--buildstops &lt;outputfile.text&gt;
            &lt;N&gt;</code> reviews the index source, as if it were
            indexing the data, and produces a list of the terms that are being
            indexed. In other words, it produces a list of all the searchable
            terms that are becoming part of the index. Note; it does not
            update the index in question, it simply processes the data 'as if'
            it were indexing, including running queries defined with
            <code class="option">sql_query_pre</code> or <code class="option">sql_query_post</code>.
            <code class="filename">outputfile.txt</code> will contain the list of
            words, one per line, sorted by frequency with most frequent first,
            and <code class="filename">N</code> specifies the maximum number of words
            that will be listed; if sufficiently large to encompass every word
            in the index, only that many words will be returned. Such a
            dictionary list could be used for client application features
            around "Did you mean..." functionality, usually in conjunction
            with <code class="option">--buildfreqs</code>, below. Example:
            </p><pre class="programlisting">$ indexer myindex --buildstops word_freq.txt 1000
</pre><p> This would produce a document in the current directory,
            <code class="filename">word_freq.txt</code> with the 1,000 most common
            words in 'myindex', ordered by most common first. Note that the
            file will pertain to the last index indexed when specified with
            multiple indexes or <code class="option">--all</code> (i.e. the last one
            listed in the configuration file)</p></li>
<li class="listitem"><p><code class="option">--buildfreqs</code> works with
            <code class="option">--buildstops</code> (and is ignored if
            <code class="option">--buildstops</code> is not specified). As
            <code class="option">--buildstops</code> provides the list of words used
            within the index, <code class="option">--buildfreqs</code> adds the quantity
            present in the index, which would be useful in establishing
            whether certain words should be considered stopwords if they are
            too prevalent. It will also help with developing "Did you mean..."
            features where you can how much more common a given word compared
            to another, similar one. Example: </p><pre class="programlisting">$ indexer myindex --buildstops word_freq.txt 1000 --buildfreqs
</pre><p> This would produce the <code class="filename">word_freq.txt</code> as
            above, however after each word would be the number of times it
            occurred in the index in question.</p></li>
<li class="listitem"><p><code class="option">--merge &lt;dst-index&gt; &lt;src-index&gt;</code>
            is used for physically merging indexes together, for example if
            you have a main+delta scheme, where the main index rarely changes,
            but the delta index is rebuilt frequently, and
            <code class="option">--merge</code> would be used to combine the two. The
            operation moves from right to left - the contents of
            <code class="filename">src-index</code> get examined and physically
            combined with the contents of <code class="filename">dst-index</code> and
            the result is left in <code class="filename">dst-index</code>. In
            pseudo-code, it might be expressed as: <code class="code">dst-index +=
            src-index</code> An example: </p><pre class="programlisting">$ indexer --merge main delta --rotate
</pre><p> In the above example, where the main is the master, rarely
            modified index, and delta is the less frequently modified one, you
            might use the above to call <code class="filename">indexer</code> to
            combine the contents of the delta into the main index and rotate
            the indexes.</p></li>
<li class="listitem"><p><code class="option">--merge-dst-range &lt;attr&gt; &lt;min&gt;
            &lt;max&gt;</code> runs the filter range given upon merging.
            Specifically, as the merge is applied to the destination index (as
            part of <code class="option">--merge</code>, and is ignored if
            <code class="option">--merge</code> is not specified),
            <code class="filename">indexer</code> will also filter the documents ending
            up in the destination index, and only documents will pass through
            the filter given will end up in the final index. This could be
            used for example, in an index where there is a 'deleted'
            attribute, where 0 means 'not deleted'. Such an index could be
            merged with: </p><pre class="programlisting">$ indexer --merge main delta --merge-dst-range deleted 0 0
</pre><p> Any documents marked as deleted (value 1) would be removed
            from the newly-merged destination index. It can be added several
            times to the command line, to add successive filters to the merge,
            all of which must be met in order for a document to become part of
            the final index.</p></li>
<li class="listitem"><p><code class="option">--dump-rows &lt;FILE&gt;</code> dumps rows fetched
            by SQL source(s) into the specified file, in a MySQL compatible
            syntax. Resulting dumps are the exact representation of data as
            received by <code class="filename">indexer</code> and help to repeat
            indexing-time issues.</p></li>
<li class="listitem"><p><code class="option">--verbose</code> guarantees that every row that
            caused problems indexing (duplicate, zero, or missing document ID;
            or file field IO issues; etc) will be reported. By default, this
            option is off, and problem summaries may be reported
            instead.</p></li>
<li class="listitem"><p><code class="option">--sighup-each</code> is useful when you are
            rebuilding many big indexes, and want each one rotated into
            <code class="filename">searchd</code> as soon as possible. With
            <code class="option">--sighup-each</code>, <code class="filename">indexer</code> will
            send a SIGHUP signal to searchd after succesfully completing the
            work on each index. (The default behavior is to send a single
            SIGHUP after all the indexes were built.)</p></li>
<li class="listitem"><p><code class="option">--print-queries</code> prints out SQL queries that
            <code class="filename">indexer</code> sends to the database, along with SQL
            connection and disconnection events. That is useful to diagnose
            and fix problems with SQL sources.</p></li>
</ul></div></div>
<div class="sect1" title="6.2.&nbsp;searchd command reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref-searchd"></a>6.2.&nbsp;<code class="filename">searchd</code> command reference</h2></div></div></div>
<p><code class="filename">searchd</code> is the second of the two principle
      tools as part of Sphinx. <code class="filename">searchd</code> is the part of the
      system which actually handles searches; it functions as a server and is
      responsible for receiving queries, processing them and returning a
      dataset back to the different APIs for client applications.</p><p>Unlike <code class="filename">indexer</code>, <code class="filename">searchd</code>
      is not designed to be run either from a regular script or command-line
      calling, but instead either as a daemon to be called from init.d (on
      Unix/Linux type systems) or to be called as a service (on Windows-type
      systems), so not all of the command line options will always apply, and
      so will be build-dependent.</p><p>Calling <code class="filename">searchd</code> is simply a case of:</p><pre class="programlisting">$ searchd [OPTIONS]
</pre><p>The options available to <code class="filename">searchd</code> on all
      builds are:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--help</code> (<code class="option">-h</code> for short) lists
          all of the parameters that can be called in your particular build of
          <code class="filename">searchd</code>.</p></li>
<li class="listitem"><p><code class="option">--config &lt;file&gt;</code> (<code class="option">-c
          &lt;file&gt;</code> for short) tells <code class="filename">searchd</code>
          to use the given file as its configuration, just as with
          <code class="filename">indexer</code> above.</p></li>
<li class="listitem"><p><code class="option">--stop</code> is used to asynchronously stop
          <code class="filename">searchd</code>, using the details of the PID file as
          specified in the <code class="filename">sphinx.conf</code> file, so you may
          also need to confirm to <code class="filename">searchd</code> which
          configuration file to use with the <code class="option">--config</code> option.
          NB, calling <code class="option">--stop</code> will also make sure any changes
          applied to the indexes with <a class="link" href="#api-func-updateatttributes" title="8.7.2.&nbsp;UpdateAttributes"><code class="code">UpdateAttributes()</code></a>
          will be applied to the index files themselves. Example:
          </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --stop
</pre></li>
<li class="listitem"><p><code class="option">--stopwait</code> is used to synchronously stop
          <code class="filename">searchd</code>. <code class="option">--stop</code> essentially
          tells the running instance to exit (by sending it a SIGTERM) and
          then immediately returns. <code class="option">--stopwait</code> will also
          attempt to wait until the running <code class="filename">searchd</code>
          instance actually finishes the shutdown (eg. saves all the pending
          attribute changes) and exits. Example: </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --stopwait
</pre><p> Possible exit codes are as follows: </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>0 on success;</p></li>
<li class="listitem"><p>1 if connection to running searchd daemon failed;</p></li>
<li class="listitem"><p>2 if daemon reported an error during shutdown;</p></li>
<li class="listitem"><p>3 if daemon crashed during shutdown.</p></li>
</ul></div></li>
<li class="listitem"><p><code class="option">--status</code> command is used to query running
          <code class="filename">searchd</code> instance status, using the connection
          details from the (optionally) provided configuration file. It will
          try to connect to the running instance using the first configured
          UNIX socket or TCP port. On success, it will query for a number of
          status and performance counter values and print them. You can use
          <a class="link" href="#api-func-status" title="8.7.5.&nbsp;Status">Status()</a> API call to access
          the very same counters from your application. Examples:
          </p><pre class="programlisting">$ searchd --status
$ searchd --config /home/myuser/sphinx.conf --status
</pre></li>
<li class="listitem"><p><code class="option">--pidfile</code> is used to explicitly state a PID
          file, where the process information is stored regarding
          <code class="filename">searchd</code>, used for inter-process communications
          (for example, <code class="filename">indexer</code> will need to know the PID
          to contact <code class="filename">searchd</code> for rotating indexes).
          Normally, <code class="filename">searchd</code> would use a PID if running in
          regular mode (i.e. not with <code class="option">--console</code>), but it is
          possible that you will be running it in console mode whilst the
          index is being updated and rotated, for which a PID file will be
          needed. </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --pidfile /home/myuser/sphinx.pid
</pre></li>
<li class="listitem"><p><code class="option">--console</code> is used to force
          <code class="filename">searchd</code> into console mode; typically it will be
          running as a conventional server application, and will aim to dump
          information into the log files (as specified in
          <code class="filename">sphinx.conf</code>). Sometimes though, when debugging
          issues in the configuration or the daemon itself, or trying to
          diagnose hard-to-track-down problems, it may be easier to force it
          to dump information directly to the console/command line from which
          it is being called. Running in console mode also means that the
          process will not be forked (so searches are done in sequence) and
          logs will not be written to. (It should be noted that console mode
          is not the intended method for running
          <code class="filename">searchd</code>.) You can invoke it as such:
          </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --console
</pre></li>
<li class="listitem"><p><code class="option">--logdebug</code> enables additional debug output in
          the daemon log. Should only be needed rarely, to assist with
          debugging issues that could not be easily reproduced on
          request.</p></li>
<li class="listitem"><p><code class="option">--iostats</code> is used in conjuction with the
          logging options (the <code class="option">query_log</code> will need to have
          been activated in <code class="filename">sphinx.conf</code>) to provide more
          detailed information on a per-query basis as to the input/output
          operations carried out in the course of that query, with a slight
          performance hit and of course bigger logs. Further details are
          available under the <a class="link" href="#query-log-format" title="5.9.&nbsp;searchd query log formats">query log
          format</a> section. You might start <code class="filename">searchd</code>
          thus: </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --iostats
</pre></li>
<li class="listitem"><p><code class="option">--cpustats</code> is used to provide actual CPU time
          report (in addition to wall time) in both query log file (for every
          given query) and status report (aggregated). It depends on
          clock_gettime() system call and might therefore be unavailable on
          certain systems. You might start <code class="filename">searchd</code> thus:
          </p><pre class="programlisting">$ searchd --config /home/myuser/sphinx.conf --cpustats
</pre></li>
<li class="listitem"><p><code class="option">--port portnumber</code> (<code class="option">-p</code> for
          short) is used to specify the port that <code class="filename">searchd</code>
          should listen on, usually for debugging purposes. This will usually
          default to 9312, but sometimes you need to run it on a different
          port. Specifying it on the command line will override anything
          specified in the configuration file. The valid range is 0 to 65535,
          but ports numbered 1024 and below usually require a privileged
          account in order to run. An example of usage: </p><pre class="programlisting">$ searchd --port 9313
</pre></li>
<li class="listitem"><p><code class="option">--listen ( address ":" port | port | path ) [ ":"
          protocol ]</code> (or <code class="option">-l</code> for short) Works as
          <code class="option">--port</code>, but allow you to specify not only the port,
          but full path, as IP address and port, or Unix-domain socket path,
          that <code class="filename">searchd</code> will listen on. Otherwords, you
          can specify either an IP address (or hostname) and port number, or
          just a port number, or Unix socket path. If you specify port number
          but not the address, searchd will listen on all network interfaces.
          Unix path is identified by a leading slash. As the last param you
          can also specify a protocol handler (listener) to be used for
          connections on this socket. Supported protocol values are 'sphinx'
          (Sphinx 0.9.x API protocol) and 'mysql41' (MySQL protocol used since
          4.1 upto at least 5.1).</p></li>
<li class="listitem"><p><code class="option">--index &lt;index&gt;</code> (or <code class="option">-i
          &lt;index&gt;</code> for short) forces this instance of
          <code class="filename">searchd</code> only to serve the specified index. Like
          <code class="option">--port</code>, above, this is usually for debugging
          purposes; more long-term changes would generally be applied to the
          configuration file itself. Example usage: </p><pre class="programlisting">$ searchd --index myindex
</pre></li>
<li class="listitem"><p><code class="option">--strip-path</code> strips the path names from all
          the file names referenced from the index (stopwords, wordforms,
          exceptions, etc). This is useful for picking up indexes built on
          another machine with possibly different path layouts.</p></li>
</ul></div>
<p>There are some options for <code class="filename">searchd</code> that are
      specific to Windows platforms, concerning handling as a service, are
      only be available on Windows binaries.</p><p>Note that on Windows searchd will default to
      <code class="option">--console</code> mode, unless you install it as a
      service.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--install</code> installs
          <code class="filename">searchd</code> as a service into the Microsoft
          Management Console (Control Panel / Administrative Tools /
          Services). Any other parameters specified on the command line, where
          <code class="option">--install</code> is specified will also become part of the
          command line on future starts of the service. For example, as part
          of calling <code class="filename">searchd</code>, you will likely also need
          to specify the configuration file with <code class="option">--config</code>,
          and you would do that as well as specifying
          <code class="option">--install</code>. Once called, the usual start/stop
          facilities will become available via the management console, so any
          methods you could use for starting, stopping and restarting services
          would also apply to <code class="filename">searchd</code>. Example:
          </p><pre class="programlisting">C:\WINDOWS\system32&gt; C:\Sphinx\bin\searchd.exe --install
   --config C:\Sphinx\sphinx.conf
</pre><p> If you wanted to have the I/O stats every time you started
          <code class="filename">searchd</code>, you would specify its option on the
          same line as the <code class="option">--install</code> command thus:
          </p><pre class="programlisting">C:\WINDOWS\system32&gt; C:\Sphinx\bin\searchd.exe --install
   --config C:\Sphinx\sphinx.conf --iostats
</pre></li>
<li class="listitem"><p><code class="option">--delete</code> removes the service from the
          Microsoft Management Console and other places where services are
          registered, after previously installed with
          <code class="option">--install</code>. Note, this does not uninstall the
          software or delete the indexes. It means the service will not be
          called from the services systems, and will not be started on the
          machine's next start. If currently running as a service, the current
          instance will not be terminated (until the next reboot, or
          <code class="filename">searchd</code> is called with
          <code class="option">--stop</code>). If the service was installed with a custom
          name (with <code class="option">--servicename</code>), the same name will need
          to be specified with <code class="option">--servicename</code> when calling to
          uninstall. Example: </p><pre class="programlisting">C:\WINDOWS\system32&gt; C:\Sphinx\bin\searchd.exe --delete
</pre></li>
<li class="listitem"><p><code class="option">--servicename &lt;name&gt;</code> applies the given
          name to <code class="filename">searchd</code> when installing or deleting the
          service, as would appear in the Management Console; this will
          default to searchd, but if being deployed on servers where multiple
          administrators may log into the system, or a system with multiple
          <code class="filename">searchd</code> instances, a more descriptive name may
          be applicable. Note that unless combined with
          <code class="option">--install</code> or <code class="option">--delete</code>, this option
          does not do anything. Example: </p><pre class="programlisting">C:\WINDOWS\system32&gt; C:\Sphinx\bin\searchd.exe --install
   --config C:\Sphinx\sphinx.conf --servicename SphinxSearch
</pre></li>
<li class="listitem"><p><code class="option">--ntservice</code> is the option that is passed by
          the Management Console to <code class="filename">searchd</code> to invoke it
          as a service on Windows platforms. It would not normally be
          necessary to call this directly; this would normally be called by
          Windows when the service would be started, although if you wanted to
          call this as a regular service from the command-line (as the
          complement to <code class="option">--console</code>) you could do so in
          theory.</p></li>
</ul></div>
<p>Last but not least, as every other daemon,
      <code class="filename">searchd</code> supports a number of signals. </p><div class="variablelist"><dl><dt><span class="term">SIGTERM</span></dt>
<dd><p>Initiates a clean shutdown. New queries will not be
              handled; but queries that are already started will not be
              forcibly interrupted.</p></dd><dt><span class="term">SIGHUP</span></dt>
<dd><p>Initiates index rotation. Depending on the value of <a class="link" href="#conf-seamless-rotate" title="11.4.12.&nbsp;seamless_rotate">seamless_rotate</a> setting,
              new queries might be shortly stalled; clients will receive
              temporary errors.</p></dd><dt><span class="term">SIGUSR1</span></dt>
<dd><p>Forces reopen of searchd log and query log files, letting
              you implement log file rotation.</p></dd></dl></div></div>
<div class="sect1" title="6.3.&nbsp;search command reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref-search"></a>6.3.&nbsp;<code class="filename">search</code> command reference</h2></div></div></div>
<p><code class="filename">search</code> is one of the helper tools within the
      Sphinx package. Whereas <code class="filename">searchd</code> is responsible for
      searches in a server-type environment, <code class="filename">search</code> is
      aimed at testing the index from the command line, and testing the index
      quickly without building a framework to make the connection to the
      server and process its response.</p><p>Note: <code class="filename">search</code> is not intended to be deployed
      as part of a client application; it is strongly recommended you do not
      write an interface to <code class="filename">search</code> instead of
      <code class="filename">searchd</code>, and none of the bundled client APIs
      support this method. (In any event, <code class="filename">search</code> will
      reload files each time, whereas <code class="filename">searchd</code> will cache
      them in memory for performance.)</p><p>That said, many types of query that you could build in the APIs
      could also be made with <code class="filename">search</code>, however for very
      complex searches it may be easier to construct them using a small script
      and the corresponding API. Additionally, some newer features may be
      available in the <code class="filename">searchd</code> system that have not yet
      been brought into <code class="filename">search</code>.</p><p>The calling syntax for <code class="filename">search</code> is as
      follows:</p><pre class="programlisting">search [OPTIONS] word1 [word2 [word3 [...]]]
</pre><p>When calling <code class="filename">search</code>, it is not necessary to
      have <code class="filename">searchd</code> running; simply make sure that the
      account running the <code class="filename">search</code> program has read access
      to the configuration file and the index files.</p><p>The default behaviour is to apply a search for word1 (AND word2
      AND word3... as specified) to all fields in all indexes as given in the
      configuration file. If constructing the equivalent in the API, this
      would be the equivalent to passing <code class="option">SPH_MATCH_ALL</code> to
      <code class="code">SetMatchMode</code>, and specifying <code class="option">*</code> as the
      indexes to query as part of <code class="code">Query</code>.</p><p>There are many options available to <code class="filename">search</code>.
      Firstly, the general options: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--config &lt;file&gt;</code> (<code class="option">-c
            &lt;file&gt;</code> for short) tells <code class="filename">search</code>
            to use the given file as its configuration, just as with
            <code class="filename">indexer</code> above.</p></li>
<li class="listitem"><p><code class="option">--index &lt;index&gt;</code> (<code class="option">-i
            &lt;index&gt;</code> for short) tells
            <code class="filename">search</code> to limit searching to the specified
            index only; normally it would attempt to search all of the
            physical indexes listed in <code class="filename">sphinx.conf</code>, not
            any distributed ones.</p></li>
<li class="listitem"><p><code class="option">--stdin</code> tells <code class="filename">search</code>
            to accept the query from the standard input, rather than the
            command line. This can be useful for testing purposes whereby you
            could feed input via pipes and from scripts.</p></li>
</ul></div>
<p>Options for setting matches: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--any</code> (<code class="option">-a</code> for short)
            changes the matching mode to match any of the words as part of the
            query (word1 OR word2 OR word3). In the API this would be
            equivalent to passing <code class="option">SPH_MATCH_ANY</code> to
            <code class="code">SetMatchMode</code>.</p></li>
<li class="listitem"><p><code class="option">--phrase</code> (<code class="option">-p</code> for short)
            changes the matching mode to match all of the words as part of the
            query, and do so in the phrase given (not including punctuation).
            In the API this would be equivalent to passing
            <code class="option">SPH_MATCH_PHRASE</code> to
            <code class="code">SetMatchMode</code>.</p></li>
<li class="listitem"><p><code class="option">--boolean</code> (<code class="option">-b</code> for short)
            changes the matching mode to <a class="link" href="#boolean-syntax" title="5.2.&nbsp;Boolean query syntax">Boolean matching</a>. Note if using
            Boolean syntax matching on the command line, you may need to
            escape the symbols (with a backslash) to avoid the shell/command
            line processor applying them, such as ampersands being escaped on
            a Unix/Linux system to avoid it forking to the
            <code class="filename">search</code> process, although this can be resolved
            by using <code class="option">--stdin</code>, as below. In the API this would
            be equivalent to passing <code class="option">SPH_MATCH_BOOLEAN</code> to
            <code class="code">SetMatchMode</code>.</p></li>
<li class="listitem"><p><code class="option">--ext</code> (<code class="option">-e</code> for short)
            changes the matching mode to <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">Extended matching</a>. In the API
            this would be equivalent to passing
            <code class="option">SPH_MATCH_EXTENDED</code> to <code class="code">SetMatchMode</code>,
            and it should be noted that use of this mode is being discouraged
            in favour of Extended2, below.</p></li>
<li class="listitem"><p><code class="option">--ext2</code> (<code class="option">-e2</code> for short)
            changes the matching mode to <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">Extended matching, version 2</a>. In
            the API this would be equivalent to passing
            <code class="option">SPH_MATCH_EXTENDED2</code> to <code class="code">SetMatchMode</code>,
            and it should be noted that use of this mode is being recommended
            in favour of Extended, due to being more efficient and providing
            other features.</p></li>
<li class="listitem"><p><code class="option">--filter &lt;attr&gt; &lt;v&gt;</code> (<code class="option">-f
            &lt;attr&gt; &lt;v&gt;</code> for short) filters the results
            such that only documents where the attribute given (attr) matches
            the value given (v). For example, <code class="option">--filter deleted
            0</code> only matches documents with an attribute called
            'deleted' where its value is 0. You can also add multiple filters
            on the command line, by specifying multiple
            <code class="option">--filter</code> multiple times, however if you apply a
            second filter to an attribute it will override the first defined
            filter.</p></li>
</ul></div>
<p>Options for handling the results: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--limit &lt;count&gt;</code> (<code class="option">-l
            count</code> for short) limits the total number of matches back
            to the number given. If a 'group' is specified, this will be the
            number of grouped results. This defaults to 20 results if not
            specified (as do the APIs)</p></li>
<li class="listitem"><p><code class="option">--offset &lt;count&gt;</code> (<code class="option">-o
            &lt;count&gt;</code> for short) offsets the result list by the
            number of places set by the count; this would be used for
            pagination through results, where if you have 20 results per
            'page', the second page would begin at offset 20, the third page
            at offset 40, etc.</p></li>
<li class="listitem"><p><code class="option">--group &lt;attr&gt;</code> (<code class="option">-g
            &lt;attr&gt;</code> for short) specifies that results should be
            grouped together based on the attribute specified. Like the GROUP
            BY clause in SQL, it will combine all results where the attribute
            given matches, and returns a set of results where each returned
            result is the best from each group. Unless otherwise specified,
            this will be the best match on relevance.</p></li>
<li class="listitem"><p><code class="option">--groupsort &lt;expr&gt;</code> (<code class="option">-gs
            &lt;expr&gt;</code> for short) instructs that when results are
            grouped with <code class="option">--group</code>, the expression given in
            &lt;expr&gt; shall determine the order of the groups. Note, this
            does not specify which is the best item within the group, only the
            order in which the groups themselves shall be returned.</p></li>
<li class="listitem"><p><code class="option">--sortby &lt;clause&gt;</code> (<code class="option">-s
            &lt;clause&gt;</code> for short) specifies that results should
            be sorted in the order listed in &lt;clause&gt;. This allows you
            to specify the order you wish results to be presented in, ordering
            by different columns. For example, you could say <code class="option">--sortby
            "@weight DESC entrytime DESC"</code> to sort entries first by
            weight (or relevance) and where two or more entries have the same
            weight, to then sort by the time with the highest time (newest)
            first. You will usually need to put the items in quotes
            (<code class="option">--sortby "@weight DESC"</code>) or use commas
            (<code class="option">--sortby @weight,DESC</code>) to avoid the items being
            treated separately. Additionally, like the regular sorting modes,
            if <code class="option">--group</code> (grouping) is being used, this will
            state how to establish the best match within each group.</p></li>
<li class="listitem"><p><code class="option">--sortexpr expr</code> (<code class="option">-S expr</code>
            for short) specifies that the search results should be presented
            in an order determined by an arithmetic expression, stated in
            expr. For example: <code class="option">--sortexpr "@weight + ( user_karma +
            ln(pageviews) )*0.1"</code> (again noting that this will have to
            be quoted to avoid the shell dealing with the asterisk). Extended
            sort mode is discussed in more detail under the
            <code class="option">SPH_SORT_EXTENDED</code> entry under the <a class="link" href="#sorting-modes" title="5.6.&nbsp;Sorting modes">Sorting modes</a> section of the
            manual.</p></li>
<li class="listitem"><p><code class="option">--sort=date</code> specifies that the results
            should be sorted by descending (i.e. most recent first) date. This
            requires that there is an attribute in the index that is set as a
            timestamp.</p></li>
<li class="listitem"><p><code class="option">--rsort=date</code> specifies that the results
            should be sorted by ascending (i.e. oldest first) date. This
            requires that there is an attribute in the index that is set as a
            timestamp.</p></li>
<li class="listitem"><p><code class="option">--sort=ts</code> specifies that the results should
            be sorted by timestamp in groups; it will return all of the
            documents whose timestamp is within the last hour, then sorted
            within that bracket for relevance. After, it would return the
            documents from the last day, sorted by relevance, then the last
            week and then the last month. It is discussed in more detail under
            the <code class="option">SPH_SORT_TIME_SEGMENTS</code> entry under the <a class="link" href="#sorting-modes" title="5.6.&nbsp;Sorting modes">Sorting modes</a> section of the
            manual.</p></li>
</ul></div>
<p>Other options: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--noinfo</code> (<code class="option">-q</code> for short)
            instructs <code class="filename">search</code> not to look-up data in your
            SQL database. Specifically, for debugging with MySQL and
            <code class="filename">search</code>, you can provide it with a query to
            look up the full article based on the returned document ID. It is
            explained in more detail under the <a class="link" href="#conf-sql-query-info" title="11.1.33.&nbsp;sql_query_info">sql_query_info</a>
            directive.</p></li>
</ul></div></div>
<div class="sect1" title="6.4.&nbsp;spelldump command reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref-spelldump"></a>6.4.&nbsp;<code class="filename">spelldump</code> command reference</h2></div></div></div>
<p><code class="filename">spelldump</code> is one of the helper tools within
      the Sphinx package.</p><p>It is used to extract the contents of a dictionary file that uses
      <code class="filename">ispell</code> or <code class="filename">MySpell</code> format,
      which can help build word lists for <em class="glossterm">wordforms</em> -
      all of the possible forms are pre-built for you.</p><p>Its general usage is:</p><pre class="programlisting">spelldump [options] &lt;dictionary&gt; &lt;affix&gt; [result] [locale-name]
</pre><p>The two main parameters are the dictionary's main file and its
      affix file; usually these are named as
      <code class="filename">[language-prefix].dict</code> and
      <code class="filename">[language-prefix].aff</code> and will be available with
      most common Linux distributions, as well as various places
      online.</p><p><code class="option">[result]</code> specifies where the dictionary data
      should be output to, and <code class="option">[locale-name]</code> additionally
      specifies the locale details you wish to use.</p><p>There is an additional option, <code class="option">-c [file]</code>, which
      specifies a file for case conversion details.</p><p>Examples of its usage are:</p><pre class="programlisting">spelldump en.dict en.aff
spelldump ru.dict ru.aff ru.txt ru_RU.CP1251
spelldump ru.dict ru.aff ru.txt .1251
</pre><p>The results file will contain a list of all the words in the
      dictionary in alphabetical order, output in the format of a wordforms
      file, which you can use to customise for your specific circumstances. An
      example of the result file:</p><pre class="programlisting">zone &gt; zone
zoned &gt; zoned
zoning &gt; zoning
</pre></div>
<div class="sect1" title="6.5.&nbsp;indextool command reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref-indextool"></a>6.5.&nbsp;<code class="filename">indextool</code> command reference</h2></div></div></div>
<p><code class="filename">indextool</code> is one of the helper tools within
      the Sphinx package, introduced in version 0.9.9-rc2. It is used to dump
      miscellaneous debug information about the physical index. (Additional
      functionality such as index verification is planned in the future, hence
      the indextool name rather than just indexdump.) Its general usage
      is:</p><pre class="programlisting">indextool &lt;command&gt; [options]
</pre><p>The only currently available option applies to all commands and
      lets you specify the configuration file: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--config &lt;file&gt;</code> (<code class="option">-c
            &lt;file&gt;</code> for short) overrides the built-in config
            file names.</p></li>
</ul></div>
<p>The commands are as follows:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="option">--dumpheader FILENAME.sph</code> quickly dumps the
          provided index header file without touching any other index files or
          even the configuration file. The report provides a breakdown of all
          the index settings, in particular the entire attribute and field
          list. Prior to 0.9.9-rc2, this command was present in CLI search
          utility.</p></li>
<li class="listitem"><p><code class="option">--dumpconfig FILENAME.sph</code> dumps the index
          definition from the given index header file in (almost) compliant
          <code class="filename">sphinx.conf</code> file format. Added in version
          2.0.1-beta.</p></li>
<li class="listitem"><p><code class="option">--dumpheader INDEXNAME</code> dumps index header by
          index name with looking up the header path in the configuration
          file.</p></li>
<li class="listitem"><p><code class="option">--dumpdocids INDEXNAME</code> dumps document IDs by
          index name. It takes the data from attribute (.spa) file and
          therefore requires docinfo=extern to work.</p></li>
<li class="listitem"><p><code class="option">--dumphitlist INDEXNAME KEYWORD</code> dumps all the
          hits (occurences) of a given keyword in a given index, with keyword
          specified as text.</p></li>
<li class="listitem"><p><code class="option">--dumphitlist INDEXNAME --wordid ID</code> dumps all
          the hits (occurences) of a given keyword in a given index, with
          keyword specified as internal numeric ID.</p></li>
<li class="listitem"><p><code class="option">--htmlstrip INDEXNAME</code> filters stdin using
          HTML stripper settings for a given index, and prints the filtering
          results to stdout. Note that the settings will be taken from
          sphinx.conf, and not the index header.</p></li>
<li class="listitem"><p><code class="option">--check INDEXNAME</code> checks the index data files
          for consistency errors that might be introduced either by bugs in
          <code class="filename">indexer</code> and/or hardware faults.</p></li>
<li class="listitem"><p><code class="option">--strip-path</code> strips the path names from all
          the file names referenced from the index (stopwords, wordforms,
          exceptions, etc). This is useful for checking indexes built on
          another machine with possibly different path layouts.</p></li>
</ul></div></div></div>
<div class="chapter" title="Chapter&nbsp;7.&nbsp;SphinxQL reference"><div class="titlepage"><div><div><h2 class="title"><a name="sphinxql-reference"></a>Chapter&nbsp;7.&nbsp;SphinxQL reference</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#sphinxql-select">7.1. SELECT syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-meta">7.2. SHOW META syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-warnings">7.3. SHOW WARNINGS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-status">7.4. SHOW STATUS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-insert">7.5. INSERT and REPLACE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-delete">7.6. DELETE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-set">7.7. SET syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-commit">7.8. BEGIN, COMMIT, and ROLLBACK syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-call-snippets">7.9. CALL SNIPPETS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-call-keywords">7.10. CALL KEYWORDS syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-tables">7.11. SHOW TABLES syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-describe">7.12. DESCRIBE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-create-function">7.13. CREATE FUNCTION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-drop-function">7.14. DROP FUNCTION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-variables">7.15. SHOW VARIABLES syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-show-collation">7.16. SHOW COLLATION syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-update">7.17. UPDATE syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-multi-queries">7.18. Multi-statement queries</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-comment-syntax">7.19. Comment syntax</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-reserved-keywords">7.20. List of SphinxQL reserved keywords</a></span></dt>
<dt><span class="sect1"><a href="#sphinxql-upgrading-magics">7.21. SphinxQL upgrade notes, version 2.0.1-beta</a></span></dt>
</dl></div>
<p>SphinxQL is our SQL dialect that exposes all of the search daemon
    functionality using a standard SQL syntax with a few Sphinx-specific
    extensions. Everything available via the SphinxAPI is also available
    SphinxQL but not vice versa; for instance, writes into RT indexes are only
    available via SphinxQL. This chapter documents supported SphinxQL
    statements syntax.</p><div class="sect1" title="7.1.&nbsp;SELECT syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-select"></a>7.1.&nbsp;SELECT syntax</h2></div></div></div>
<pre class="programlisting">SELECT
    select_expr [, select_expr ...]
    FROM index [, index2 ...]
    [WHERE where_condition]
    [GROUP BY {col_name | expr_alias}]
    [ORDER BY {col_name | expr_alias} {ASC | DESC} [, ...]]
    [WITHIN GROUP ORDER BY {col_name | expr_alias} {ASC | DESC}]
    [LIMIT offset, row_count]
    [OPTION opt_name = opt_value [, ...]]
</pre><p><span class="bold"><strong>SELECT</strong></span> statement was introduced in version 0.9.9-rc2. It's
      syntax is based upon regular SQL but adds several Sphinx-specific
      extensions and has a few omissions (such as (currently) missing support
      for JOINs). Specifically, </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Column list clause. Column names, arbitrary expressions, and
            star ('*') are all allowed (ie. <code class="code">SELECT @id, group_id*123+456
            AS expr1 FROM test1</code> will work). Unlike in regular SQL, all
            computed expressions must be aliased with a valid identifier.
            Starting with version 2.0.1-beta, <code class="code">AS</code> is optional.
            Special names such as @id and @weight should currently be used
            with leading at-sign. This at-sign requirement will be lifted in
            the future.</p></li>
<li class="listitem"><p>FROM clause. FROM clause should contain the list of indexes
            to search through. Unlike in regular SQL, comma means enumeration
            of full-text indexes as in <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query">Query()</a> API call rather than
            JOIN.</p></li>
<li class="listitem"><p>WHERE clause. This clause will map both to fulltext query
            and filters. Comparison operators (=, !=, &lt;, &gt;, &lt;=,
            &gt;=), IN, AND, NOT, and BETWEEN are all supported and map
            directly to filters. OR is not supported yet but will be in the
            future. MATCH('query') is supported and maps to fulltext query.
            Query will be interpreted according to <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">full-text query language rules</a>.
            There must be at most one MATCH() in the clause. Starting with
            version 2.0.1-beta, <code class="code">{col_name | expr_alias} [NOT] IN
            @uservar</code> condition syntax is supported. (Refer to <a class="xref" href="#sphinxql-set" title="7.7.&nbsp;SET syntax">Section&nbsp;7.7, “SET syntax”</a> for a discussion of global user
            variables.)</p></li>
<li class="listitem"><p>GROUP BY clause. Currently only supports grouping by a
            single column. The column however can be a computed expression:
            </p><pre class="programlisting">SELECT *, group_id*1000+article_type AS gkey FROM example GROUP BY gkey
</pre><p> Aggregate functions (AVG(), MIN(), MAX(), SUM()) in column
            list clause are supported. Arguments to aggregate functions can be
            either plain attributes or arbitrary expressions. COUNT(*) is
            implicitly supported as using GROUP BY will add @count column to
            result set. Explicit support might be added in the future.
            COUNT(DISTINCT attr) is supported. Currently there can be at most
            one COUNT(DISTINCT) per query and an argument needs to be an
            attribute. Both current restrictions on COUNT(DISTINCT) might be
            lifted in the future. </p><pre class="programlisting">SELECT *, AVG(price) AS avgprice, COUNT(DISTINCT storeid)
FROM products
WHERE MATCH('ipod')
GROUP BY vendorid
</pre><p> Starting with 2.0.1-beta, GROUP BY on a string attribute is
            supported, with respect for current collation (see <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a>).</p></li>
<li class="listitem"><p>WITHIN GROUP ORDER BY clause. This is a Sphinx specific
            extension that lets you control how the best row within a group
            will to be selected. The syntax matches that of regular ORDER BY
            clause: </p><pre class="programlisting">SELECT *, INTERVAL(posted,NOW()-7*86400,NOW()-86400) AS timeseg
FROM example WHERE MATCH('my search query')
GROUP BY siteid
WITHIN GROUP ORDER BY @weight DESC
ORDER BY timeseg DESC, @weight DESC
</pre><p> Starting with 2.0.1-beta, WITHIN GROUP ORDER BY on a string
            attribute is supported, with respect for current collation (see
            <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a>).</p></li>
<li class="listitem"><p>ORDER BY clause. Unlike in regular SQL, only column names
            (not expressions) are allowed and explicit ASC and DESC are
            required. The columns however can be computed expressions:
            </p><pre class="programlisting">SELECT *, @weight*10+docboost AS skey FROM example ORDER BY skey
</pre><p> Starting with 2.0.1-beta, ORDER BY on a string attribute is
            supported, with respect for current collation (see <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a>).</p></li>
<li class="listitem"><p>LIMIT clause. Both LIMIT N and LIMIT M,N forms are
            supported. Unlike in regular SQL (but like in Sphinx API), an
            implicit LIMIT 0,20 is present by default.</p></li>
<li class="listitem"><p>OPTION clause. This is a Sphinx specific extension that lets
            you control a number of per-query options. The syntax is:
            </p><pre class="programlisting">OPTION &lt;optionname&gt;=&lt;value&gt; [ , ... ]
</pre><p> Supported options and respectively allowed values are:
            </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>'ranker' - any of 'proximity_bm25', 'bm25', 'none',
                  'wordcount', 'proximity', 'matchany', or 'fieldmask'</p></li>
<li class="listitem"><p>'max_matches' - integer (per-query max matches
                  value)</p></li>
<li class="listitem"><p>'cutoff' - integer (max found matches
                  threshold)</p></li>
<li class="listitem"><p>'max_query_time' - integer (max search time threshold,
                  msec)</p></li>
<li class="listitem"><p>'retry_count' - integer (distributed retries
                  count)</p></li>
<li class="listitem"><p>'retry_delay' - integer (distributed retry delay,
                  msec)</p></li>
<li class="listitem"><p>'field_weights' - a named integer list (per-field user
                  weights for ranking)</p></li>
<li class="listitem"><p>'index_weights' - a named integer list (per-index user
                  weights for ranking)</p></li>
<li class="listitem"><p>'reverse_scan' - 0 or 1, lets you control the order in
                  which full-scan query processes the rows</p></li>
</ul></div>
<p> Example: </p><pre class="programlisting">SELECT * FROM test WHERE MATCH('@title hello @body world')
OPTION ranker=bm25, max_matches=3000,
    field_weights=(title=10, body=3)
</pre></li>
</ul></div></div>
<div class="sect1" title="7.2.&nbsp;SHOW META syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-meta"></a>7.2.&nbsp;SHOW META syntax</h2></div></div></div>
<pre class="programlisting">SHOW META
</pre><p><span class="bold"><strong>SHOW META</strong></span> shows additional meta-information about the
      latest query such as query time and keyword statistics: </p><pre class="programlisting">mysql&gt; SELECT * FROM test1 WHERE MATCH('test|one|two');
+------+--------+----------+------------+
| id   | weight | group_id | date_added |
+------+--------+----------+------------+
|    1 |   3563 |      456 | 1231721236 |
|    2 |   2563 |      123 | 1231721236 |
|    4 |   1480 |        2 | 1231721236 |
+------+--------+----------+------------+
3 rows in set (0.01 sec)

mysql&gt; SHOW META;
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| total         | 3     |
| total_found   | 3     |
| time          | 0.005 |
| keyword[0]    | test  |
| docs[0]       | 3     |
| hits[0]       | 5     |
| keyword[1]    | one   |
| docs[1]       | 1     |
| hits[1]       | 2     |
| keyword[2]    | two   |
| docs[2]       | 1     |
| hits[2]       | 2     |
+---------------+-------+
12 rows in set (0.00 sec)
</pre></div>
<div class="sect1" title="7.3.&nbsp;SHOW WARNINGS syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-warnings"></a>7.3.&nbsp;SHOW WARNINGS syntax</h2></div></div></div>
<pre class="programlisting">SHOW WARNINGS
</pre><p><span class="bold"><strong>SHOW WARNINGS</strong></span> statement, introduced in version 0.9.9-rc2,
      can be used to retrieve the warning produced by the latest query. The
      error message will be returned along with the query itself:
      </p><pre class="programlisting">mysql&gt; SELECT * FROM test1 WHERE MATCH('@@title hello') \G
ERROR 1064 (42000): index test1: syntax error, unexpected TOK_FIELDLIMIT
near '@title hello'

mysql&gt; SELECT * FROM test1 WHERE MATCH('@title -hello') \G
ERROR 1064 (42000): index test1: query is non-computable (single NOT operator)

mysql&gt; SELECT * FROM test1 WHERE MATCH('"test doc"/3') \G
*************************** 1. row ***************************
        id: 4
    weight: 2500
  group_id: 2
date_added: 1231721236
1 row in set, 1 warning (0.00 sec)

mysql&gt; SHOW WARNINGS \G
*************************** 1. row ***************************
  Level: warning
   Code: 1000
Message: quorum threshold too high (words=2, thresh=3); replacing quorum operator
         with AND operator
1 row in set (0.00 sec)
</pre></div>
<div class="sect1" title="7.4.&nbsp;SHOW STATUS syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-status"></a>7.4.&nbsp;SHOW STATUS syntax</h2></div></div></div>
<p><span class="bold"><strong>SHOW STATUS</strong></span>, introduced in version 0.9.9-rc2, displays a
      number of useful performance counters. IO and CPU counters will only be
      available if searchd was started with --iostats and --cpustats switches
      respectively. </p><pre class="programlisting">mysql&gt; SHOW STATUS;
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| uptime             | 216   |
| connections        | 3     |
| maxed_out          | 0     |
| command_search     | 0     |
| command_excerpt    | 0     |
| command_update     | 0     |
| command_keywords   | 0     |
| command_persist    | 0     |
| command_status     | 0     |
| agent_connect      | 0     |
| agent_retry        | 0     |
| queries            | 10    |
| dist_queries       | 0     |
| query_wall         | 0.075 |
| query_cpu          | OFF   |
| dist_wall          | 0.000 |
| dist_local         | 0.000 |
| dist_wait          | 0.000 |
| query_reads        | OFF   |
| query_readkb       | OFF   |
| query_readtime     | OFF   |
| avg_query_wall     | 0.007 |
| avg_query_cpu      | OFF   |
| avg_dist_wall      | 0.000 |
| avg_dist_local     | 0.000 |
| avg_dist_wait      | 0.000 |
| avg_query_reads    | OFF   |
| avg_query_readkb   | OFF   |
| avg_query_readtime | OFF   |
+--------------------+-------+
29 rows in set (0.00 sec)
</pre></div>
<div class="sect1" title="7.5.&nbsp;INSERT and REPLACE syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-insert"></a>7.5.&nbsp;INSERT and REPLACE syntax</h2></div></div></div>
<pre class="programlisting">{INSERT | REPLACE} INTO index [(column, ...)]
	VALUES (value, ...)
	[, (...)]
</pre><p>INSERT statement, introduced in version 1.10-beta, is only
      supported for RT indexes. It inserts new rows (documents) into an
      existing index, with the provided column values.</p><p>ID column must be present in all cases. Rows with duplicate IDs
      will <span class="bold"><strong>not</strong></span> be overwritten by INSERT; use REPLACE to do that.</p><p><code class="option">index</code> is the name of RT index into which the new
      row(s) should be inserted. The optional column names list lets you only
      explicitly specify values for some of the columns present in the index.
      All the other columns will be filled with their default values (0 for
      scalar types, empty string for text types).</p><p>Expressions are not currently supported in INSERT and values
      should be explicitly specified.</p><p>Multiple rows can be inserted using a single INSERT statement by
      providing several comma-separated, parens-enclosed lists of rows
      values.</p></div>
<div class="sect1" title="7.6.&nbsp;DELETE syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-delete"></a>7.6.&nbsp;DELETE syntax</h2></div></div></div>
<pre class="programlisting">DELETE FROM index WHERE {id = value | id IN (val1 [, val2 [, ...]])}
</pre><p>DELETE statement, introduced in version 1.10-beta, is only
      supported for RT indexes. It deletes existing rows (documents) from an
      existing index based on ID.</p><p><code class="option">index</code> is the name of RT index from which the row
      should be deleted. <code class="option">value</code> is the row ID to be deleted.
      Support for batch <code class="code">id IN (2,3,5)</code> syntax was added in version
      2.0.1-beta.</p><p>Additional types of WHERE conditions (such as conditions on
      attributes, etc) are planned, but not supported yet as of
      1.10-beta.</p></div>
<div class="sect1" title="7.7.&nbsp;SET syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-set"></a>7.7.&nbsp;SET syntax</h2></div></div></div>
<pre class="programlisting">SET [GLOBAL] server_variable_name = value
SET GLOBAL @user_variable_name = (int_val1 [, int_val2, ...])
</pre><p>SET statement, introduced in version 1.10-beta, modifies a server
      variable value. The variable names are case-insensitive. No variable
      value changes survive server restart. There are the following classes of
      the variables: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>per-session server variable (1.10-beta and above)</p></li>
<li class="listitem"><p>global server variable (2.0.1-beta and above)</p></li>
<li class="listitem"><p>global user variable (2.0.1-beta and above)</p></li>
</ol></div>
<p>Global user variables are shared between concurrent sessions.
      Currently, the only supported value type is the list of BIGINTs, and
      these variables can only be used along with IN() for filtering purpose.
      The intended usage scenario is uploading huge lists of values to
      <code class="filename">searchd</code> (once) and reusing them (many times) later,
      saving on network overheads. Example: </p><pre class="programlisting">// in session 1
mysql&gt; SET GLOBAL @myfilter=(2,3,5,7,11,13);
Query OK, 0 rows affected (0.00 sec)

// later in session 2
mysql&gt; SELECT * FROM test1 WHERE group_id IN @myfilter;
+------+--------+----------+------------+-----------------+------+
| id   | weight | group_id | date_added | title           | tag  |
+------+--------+----------+------------+-----------------+------+
|    3 |      1 |        2 | 1299338153 | another doc     | 15   |
|    4 |      1 |        2 | 1299338153 | doc number four | 7,40 |
+------+--------+----------+------------+-----------------+------+
2 rows in set (0.02 sec)
</pre><p>Per-session and global server variables affect certain server
      settings in the respective scope. Known per-session server variables
      are: </p><div class="variablelist"><dl><dt><span class="term"><code class="code">AUTOCOMMIT = {0 | 1}</code></span></dt>
<dd><p>Whether any data modification statement should be
              implicitly wrapped by BEGIN and COMMIT. Introduced in version
              1.10-beta.</p></dd><dt><span class="term"><code class="code">COLLATION_CONNECTION = collation_name</code></span></dt>
<dd><p>Selects the collation to be used for ORDER BY or GROUP BY
              on string values in the subsequent queries. Refer to <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a> for a list of known collation names.
              Introduced in version 2.0.1-beta.</p></dd><dt><span class="term"><code class="code">CHARACTER_SET_RESULTS = charset_name</code></span></dt>
<dd><p>Does nothing; a placeholder to support frameworks,
              clients, and connectors that attempt to automatically enforce a
              charset when connecting to a Sphinx server. Introduced in
              version 2.0.1-beta.</p></dd></dl></div>
<p>Known global server variables are: </p><div class="variablelist"><dl><dt><span class="term"><code class="code">QUERY_LOG_FORMAT = {plain | sphinxql}</code></span></dt>
<dd><p>Changes the current log format. Introduced in version
              2.0.1-beta.</p></dd><dt><span class="term"><code class="code">LOG_LEVEL = {info | debug | debugv |
            debugvv}</code></span></dt>
<dd><p>Changes the current log verboseness level. Introduced in
              version 2.0.1-beta.</p></dd></dl></div>
<p>Examples: </p><pre class="programlisting">mysql&gt; SET autocommit=0;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; SET GLOBAL query_log_format=sphinxql;
Query OK, 0 rows affected (0.00 sec)
</pre></div>
<div class="sect1" title="7.8.&nbsp;BEGIN, COMMIT, and ROLLBACK syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-commit"></a>7.8.&nbsp;BEGIN, COMMIT, and ROLLBACK syntax</h2></div></div></div>
<pre class="programlisting">START TRANSACTION | BEGIN
COMMIT
ROLLBACK
SET AUTOCOMMIT = {0 | 1}
</pre><p>BEGIN, COMMIT, and ROLLBACK statements were introduced in version
      1.10-beta. BEGIN statement (or its START TRANSACTION alias) forcibly
      commits pending transaction, if any, and begins a new one. COMMIT
      statement commits the current transaction, making all its changes
      permanent. ROLLBACK statement rolls back the current transaction,
      canceling all its changes. SET AUTOCOMMIT controls the autocommit mode
      in the active session.</p><p>AUTOCOMMIT is set to 1 by default, meaning that every statement
      that perfoms any changes on any index is implicitly wrapped in BEGIN and
      COMMIT.</p><p>Transactions are limited to a single RT index, and also limited in
      size. They are atomic, consistent, overly isolated, and durable. Overly
      isolated means that the changes are not only invisible to the concurrent
      transactions but even to the current session itself.</p></div>
<div class="sect1" title="7.9.&nbsp;CALL SNIPPETS syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-call-snippets"></a>7.9.&nbsp;CALL SNIPPETS syntax</h2></div></div></div>
<pre class="programlisting">CALL SNIPPETS(data, index, query[, opt_value AS opt_name[, ...]])
</pre><p>CALL SNIPPETS statement, introduced in version 1.10-beta, builds a
      snippet from provided data and query, using specified index
      settings.</p><p><code class="option">data</code> is the source data string to extract a
      snippet from. <code class="option">index</code> is the name of the index from which
      to take the text processing settings. <code class="option">query</code> is the
      full-text query to build snippets for. Additional options are documented
      in <a class="xref" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">Section&nbsp;8.7.1, “BuildExcerpts”</a>. Usage example:</p><pre class="programlisting">CALL SNIPPETS('this is my document text', 'test1', 'hello world',
    5 AS around, 200 AS limit)
</pre></div>
<div class="sect1" title="7.10.&nbsp;CALL KEYWORDS syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-call-keywords"></a>7.10.&nbsp;CALL KEYWORDS syntax</h2></div></div></div>
<pre class="programlisting">CALL KEYWORDS(text, index, [hits])
</pre><p>CALL KEYWORDS statement, introduced in version 1.10-beta, splits
      text into particular keywords. It returns tokenized and normalized forms
      of the keywords, and, optionally, keyword statistics.</p><p><code class="option">text</code> is the text to break down to keywords.
      <code class="option">index</code> is the name of the index from which to take the
      text processing settings. <code class="option">hits</code> is an optional boolean
      parameter that specifies whether to return document and hit occurrence
      statistics.</p></div>
<div class="sect1" title="7.11.&nbsp;SHOW TABLES syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-tables"></a>7.11.&nbsp;SHOW TABLES syntax</h2></div></div></div>
<pre class="programlisting">SHOW TABLES
</pre><p>SHOW TABLES statement, introduced in version 2.0.1-beta,
      enumerates all currently active indexes along with their types. As of
      2.0.1-beta, existing index types are <code class="option">local</code>,
      <code class="option">distributed</code>, and <code class="option">rt</code> respectively.
      Example: </p><pre class="programlisting">mysql&gt; SHOW TABLES;
+-------+-------------+
| Index | Type        |
+-------+-------------+
| dist1 | distributed |
| rt    | rt          |
| test1 | local       |
| test2 | local       |
+-------+-------------+
4 rows in set (0.00 sec)
</pre></div>
<div class="sect1" title="7.12.&nbsp;DESCRIBE syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-describe"></a>7.12.&nbsp;DESCRIBE syntax</h2></div></div></div>
<pre class="programlisting">{DESC | DESCRIBE} index
</pre><p>DESCRIBE statement, introduced in version 2.0.1-beta, lists index
      columns and their associated types. Columns are document ID, full-text
      fields, and attributes. The order matches that in which fields and
      attributes are expected by INSERT and REPLACE statements. As of
      2.0.1-beta, column types are <code class="option">field</code>,
      <code class="option">integer</code>, <code class="option">timestamp</code>,
      <code class="option">ordinal</code>, <code class="option">bool</code>, <code class="option">float</code>,
      <code class="option">bigint</code>, <code class="option">string</code>, and
      <code class="option">mva</code>. ID column will be typed either
      <code class="option">integer</code> or <code class="option">bigint</code> based on whether the
      binaries were built with 32-bit or 64-bit document ID support.
      Example:</p><pre class="programlisting">mysql&gt; DESC rt;
+---------+---------+
| Field   | Type    |
+---------+---------+
| id      | integer |
| title   | field   |
| content | field   |
| gid     | integer |
+---------+---------+
4 rows in set (0.00 sec)
</pre></div>
<div class="sect1" title="7.13.&nbsp;CREATE FUNCTION syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-create-function"></a>7.13.&nbsp;CREATE FUNCTION syntax</h2></div></div></div>
<pre class="programlisting">CREATE FUNCTION udf_name
	RETURNS {INT | BIGINT | FLOAT}
	SONAME 'udf_lib_file'
</pre><p>CREATE FUNCTION statement, introduced in version 2.0.1-beta,
      installs a <a class="link" href="#udf" title="5.13.&nbsp;User-defined functions (UDF)">user-defined function (UDF)</a> with
      the given name and type from the given library file. The library file
      must reside in a trusted <a class="link" href="#conf-plugin-dir" title="11.4.35.&nbsp;plugin_dir">plugin_dir</a> directory. On success, the
      function is available for use in all subsequent queries that the server
      receives. Example:</p><pre class="programlisting">mysql&gt; CREATE FUNCTION avgmva RETURNS INT SONAME 'udfexample.dll';
Query OK, 0 rows affected (0.03 sec)

mysql&gt; SELECT *, AVGMVA(tag) AS q from test1;
+------+--------+---------+-----------+
| id   | weight | tag     | q         |
+------+--------+---------+-----------+
|    1 |      1 | 1,3,5,7 | 4.000000  |
|    2 |      1 | 2,4,6   | 4.000000  |
|    3 |      1 | 15      | 15.000000 |
|    4 |      1 | 7,40    | 23.500000 |
+------+--------+---------+-----------+
</pre></div>
<div class="sect1" title="7.14.&nbsp;DROP FUNCTION syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-drop-function"></a>7.14.&nbsp;DROP FUNCTION syntax</h2></div></div></div>
<pre class="programlisting">DROP FUNCTION udf_name
</pre><p>DROP FUNCTION statement, introduced in version 2.0.1-beta,
      deinstalls a <a class="link" href="#udf" title="5.13.&nbsp;User-defined functions (UDF)">user-defined function (UDF)</a> with
      the given name. On success, the function is no longer available for use
      in subsequent queries. Pending concurrent queries will not be affected
      and the library unload, if necessary, will be postponed until those
      queries complete. Example:</p><pre class="programlisting">mysql&gt; DROP FUNCTION avgmva;
Query OK, 0 rows affected (0.00 sec)
</pre></div>
<div class="sect1" title="7.15.&nbsp;SHOW VARIABLES syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-variables"></a>7.15.&nbsp;SHOW VARIABLES syntax</h2></div></div></div>
<pre class="programlisting">SHOW VARIABLES
</pre><p>Added in version 2.0.1-beta, this is currently a placeholder query
      that does nothing and reports success. That is in order to keep
      compatibility with frameworks and connectors that automatically execute
      this statement.</p><pre class="programlisting">mysql&gt; SHOW VARIABLES;
Query OK, 0 rows affected (0.00 sec)
</pre></div>
<div class="sect1" title="7.16.&nbsp;SHOW COLLATION syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-show-collation"></a>7.16.&nbsp;SHOW COLLATION syntax</h2></div></div></div>
<pre class="programlisting">SHOW COLLATION
</pre><p>Added in version 2.0.1-beta, this is currently a placeholder query
      that does nothing and reports success. That is in order to keep
      compatibility with frameworks and connectors that automatically execute
      this statement.</p><pre class="programlisting">mysql&gt; SHOW COLLATION;
Query OK, 0 rows affected (0.00 sec)
</pre></div>
<div class="sect1" title="7.17.&nbsp;UPDATE syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-update"></a>7.17.&nbsp;UPDATE syntax</h2></div></div></div>
<pre class="programlisting">UPDATE index SET col1 = newval1 [, ...] WHERE ID = docid
</pre><p>UPDATE statement was added in version 2.0.1-beta. It can currently
      update 32-bit integer attributes only. Multiple attributes and values
      can be specified. Both RT and disk indexes are supported. Updates on
      other attribute types are also planned.</p><pre class="programlisting">mysql&gt; UPDATE myindex SET enabled=0 WHERE id=123;
Query OK, 1 rows affected (0.00 sec)
</pre></div>
<div class="sect1" title="7.18.&nbsp;Multi-statement queries"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-multi-queries"></a>7.18.&nbsp;Multi-statement queries</h2></div></div></div>
<p>Starting version 2.0.1-beta, SphinxQL supports multi-statement
      queries, or batches. Possible inter-statement optimizations described in
      <a class="xref" href="#multi-queries" title="5.11.&nbsp;Multi-queries">Section&nbsp;5.11, “Multi-queries”</a> do apply to SphinxQL just as well. The
      batched queries should be separated by a semicolon. Your MySQL client
      library needs to support MySQL multi-query mechanism and multiple result
      set. For instance, mysqli interface in PHP and DBI/DBD libraries in Perl
      are known to work.</p><p>Here's a PHP sample showing how to utilize mysqli interface with
      Sphinx. </p><pre class="programlisting">&lt;?php

$link = mysqli_connect ( "127.0.0.1", "root", "", "", 9306 );
if ( mysqli_connect_errno() )
    die ( "connect failed: " . mysqli_connect_error() );

$batch = "SELECT * FROM test1 ORDER BY group_id ASC;";
$batch .= "SELECT * FROM test1 ORDER BY group_id DESC";

if ( !mysqli_multi_query ( $link, $batch ) )
    die ( "query failed" );

do
{
    // fetch and print result set
    if ( $result = mysqli_store_result($link) )
    {
        while ( $row = mysqli_fetch_row($result) )
            printf ( "id=%s\n", $row[0] );
        mysqli_free_result($result);
    }

    // print divider
    if ( mysqli_more_results($link) )
        printf ( "------\n" );

} while ( mysqli_next_result($link) );
</pre><p> Its output with the sample <code class="code">test1</code> index included
      with Sphinx is as follows. </p><pre class="programlisting">$ php test_multi.php
id=1
id=2
id=3
id=4
------
id=3
id=4
id=1
id=2
</pre><p>The following statements can currently be used in a batch: SELECT,
      SHOW WARNINGS, SHOW STATUS, and SHOW META. Arbitrary sequence of these
      statements are allowed. The results sets returned should match those
      that would be returned if the batched queries were sent one by
      one.</p></div>
<div class="sect1" title="7.19.&nbsp;Comment syntax"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-comment-syntax"></a>7.19.&nbsp;Comment syntax</h2></div></div></div>
<p>Since version 2.0.1-beta, SphinxQL supports C-style comment
      syntax. Everything from an opening <code class="code">/*</code> sequence to a closing
      <code class="code">*/</code> sequence is ignored. Comments can span multiple lines,
      can not nest, and should not get logged. MySQL specific <code class="code">/*! ...
      */</code> comments are also currently ignored. (As the comments support
      was rather added for better compatibility with
      <code class="filename">mysqldump</code> produced dumps, rather than improving
      generaly query interoperability between Sphinx and MySQL.)
      </p><pre class="programlisting">SELECT /*! SQL_CALC_FOUND_ROWS */ col1 FROM table1 WHERE ...
</pre></div>
<div class="sect1" title="7.20.&nbsp;List of SphinxQL reserved keywords"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-reserved-keywords"></a>7.20.&nbsp;List of SphinxQL reserved keywords</h2></div></div></div>
<p>A complete alphabetical list of keywords that are currently
      reserved in SphinxQL syntax (and therefore can not be used as
      identifiers). </p><pre class="programlisting">AND
AS
ASC
AVG
BEGIN
BETWEEN
BY
CALL
COLLATION
COMMIT
COUNT
DELETE
DESC
DESCRIBE
DISTINCT
FALSE
FROM
GLOBAL
GROUP
ID
IN
INSERT
INTO
LIMIT
MATCH
MAX
META
MIN
NOT
NULL
OPTION
OR
ORDER
REPLACE
ROLLBACK
SELECT
SET
SHOW
START
STATUS
SUM
TABLES
TRANSACTION
TRUE
UPDATE
VALUES
VARIABLES
WARNINGS
WEIGHT
WHERE
WITHIN
</pre></div>
<div class="sect1" title="7.21.&nbsp;SphinxQL upgrade notes, version 2.0.1-beta"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxql-upgrading-magics"></a>7.21.&nbsp;SphinxQL upgrade notes, version 2.0.1-beta</h2></div></div></div>
<p>This section only applies to existing applications that use
      SphinxQL versions prior to 2.0.1-beta.</p><p>In previous versions, SphinxQL just wrapped around SphinxAPI and
      inherited its magic columns and column set quirks. Essentially, SphinxQL
      queries could return (slightly) different columns and in a (slightly)
      different order than it was explicitly requested in the query. Namely,
      <code class="code">weight</code> magic column (which is not a real column in any
      index) was added at all times, and GROUP BY related <code class="code">@count</code>,
      <code class="code">@group</code>, and <code class="code">@distinct</code> magic columns were
      conditionally added when grouping. Also, the order of columns
      (attributes) in the result set was actually taken from the index rather
      than the query. (So if you asked for columns C, B, A in your query but
      they were in the A, B, C order in the index, they would have been
      returned in the A, B, C order.)</p><p>In version 2.0.1-beta, we fixed that. SphinxQL is now more SQL
      compliant (and will be further brought in as much compliance with
      standard SQL syntax as possible). That is not yet a breaking change,
      because <code class="filename">searchd</code> now supports <a class="link" href="#conf-compat-sphinxql-magics" title="11.4.40.&nbsp;compat_sphinxql_magics"><code class="code">compat_sphinxql_magics</code></a>
      directive that flips between the old "compatibility" mode and the new
      "compliance" mode. However, the compatibility mode support is going to
      be removed in future, so it's strongly advised to update SphinxQL
      applications and switch to the compliance mode.</p><p>The important changes are as follows: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><span class="bold"><strong><code class="code">@ID</code> magic name is deprecated in favor of
            <code class="code">ID</code>.</strong></span> Document ID is considered an
            attribute.</p></li>
<li class="listitem"><p><span class="bold"><strong><code class="code">WEIGHT</code> is no longer implicitly returned</strong></span>,
            because it is not actually a column (an index attribute), but
            rather an internal function computed per each row (a match). You
            have to explicitly ask for it, using the <code class="code">WEIGHT()</code>
            function. (The requirement to alias the result will be lifted in
            the next release.) </p><pre class="programlisting">SELECT id, WEIGHT() w FROM myindex WHERE MATCH('test')
</pre></li>
<li class="listitem"><p><span class="bold"><strong>You can now use quoted reserved keywords as aliases.</strong></span>
            The quote character is backtick ("`", ASCII code 96 decimal, 60
            hex). One particularly useful example would be returning
            <code class="code">weight</code> column like the old mode: </p><pre class="programlisting">SELECT id, WEIGHT() `weight` FROM myindex WHERE MATCH('test')
</pre></li>
<li class="listitem"><p>The column order is now different and should now match the
            one expliclitly defined in the query. So if you are accessing
            columns based on their position in the result set rather than the
            name (for instance, by using <code class="code">mysql_fetch_row()</code> rather
            than <code class="code">mysql_fetch_assoc()</code> in PHP), <span class="bold"><strong>check and fix
            the order of columns in your queries.</strong></span></p></li>
<li class="listitem"><p><code class="code">SELECT *</code> return the columns in index order, as
            it used to, including the ID column. However, <span class="bold"><strong><code class="code">SELECT
            *</code> does not automatically return WEIGHT().</strong></span> To update
            such queries in case you access columns by names, simply add it to
            the query: </p><pre class="programlisting">SELECT *, WEIGHT() `weight` FROM myindex WHERE MATCH('test')
</pre><p> Otherwise, i.e., in case you rely on column order, select
            ID, weight, and then other columns: </p><pre class="programlisting">SELECT id, *, WEIGHT() `weight` FROM myindex WHERE MATCH('test')
</pre></li>
<li class="listitem"><p><span class="bold"><strong>Magic <code class="code">@count</code> and <code class="code">@distinct</code>
            attributes are no longer implicitly returned</strong></span>. You now have to
            explicitly ask for them when using GROUP BY. (Also note that you
            currently have to alias them; that requirement will be lifted in
            the future.) </p><pre class="programlisting">SELECT gid, COUNT(*) q FROM myindex WHERE MATCH('test')
GROUP BY gid ORDER BY q DESC
</pre></li>
</ul></div></div></div>
<div class="chapter" title="Chapter&nbsp;8.&nbsp;API reference"><div class="titlepage"><div><div><h2 class="title"><a name="api-reference"></a>Chapter&nbsp;8.&nbsp;API reference</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#api-funcgroup-general">8.1. General API functions</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-getlasterror">8.1.1. GetLastError</a></span></dt>
<dt><span class="sect2"><a href="#api-func-getlastwarning">8.1.2. GetLastWarning</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setserver">8.1.3. SetServer</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setretries">8.1.4. SetRetries</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setconnecttimeout">8.1.5. SetConnectTimeout</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setarrayresult">8.1.6. SetArrayResult</a></span></dt>
<dt><span class="sect2"><a href="#api-func-isconnecterror">8.1.7. IsConnectError</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-general-query-settings">8.2. General query settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setlimits">8.2.1. SetLimits</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setmaxquerytime">8.2.2. SetMaxQueryTime</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setoverride">8.2.3. SetOverride</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setselect">8.2.4. SetSelect</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-fulltext-query-settings">8.3. Full-text search query settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setmatchmode">8.3.1. SetMatchMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setrankingmode">8.3.2. SetRankingMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setsortmode">8.3.3. SetSortMode</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setweights">8.3.4. SetWeights</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfieldweights">8.3.5. SetFieldWeights</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setindexweights">8.3.6. SetIndexWeights</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-filtering">8.4. Result set filtering settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setidrange">8.4.1. SetIDRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilter">8.4.2. SetFilter</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilterrange">8.4.3. SetFilterRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setfilterfloatrange">8.4.4. SetFilterFloatRange</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setgeoanchor">8.4.5. SetGeoAnchor</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-groupby">8.5. GROUP BY settings</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-setgroupby">8.5.1. SetGroupBy</a></span></dt>
<dt><span class="sect2"><a href="#api-func-setgroupdistinct">8.5.2. SetGroupDistinct</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-querying">8.6. Querying</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-query">8.6.1. Query</a></span></dt>
<dt><span class="sect2"><a href="#api-func-addquery">8.6.2. AddQuery</a></span></dt>
<dt><span class="sect2"><a href="#api-func-runqueries">8.6.3. RunQueries</a></span></dt>
<dt><span class="sect2"><a href="#api-func-resetfilters">8.6.4. ResetFilters</a></span></dt>
<dt><span class="sect2"><a href="#api-func-resetgroupby">8.6.5. ResetGroupBy</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-additional-functionality">8.7. Additional functionality</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-buildexcerpts">8.7.1. BuildExcerpts</a></span></dt>
<dt><span class="sect2"><a href="#api-func-updateatttributes">8.7.2. UpdateAttributes</a></span></dt>
<dt><span class="sect2"><a href="#api-func-buildkeywords">8.7.3. BuildKeywords</a></span></dt>
<dt><span class="sect2"><a href="#api-func-escapestring">8.7.4. EscapeString</a></span></dt>
<dt><span class="sect2"><a href="#api-func-status">8.7.5. Status</a></span></dt>
<dt><span class="sect2"><a href="#api-func-flushattributes">8.7.6. FlushAttributes</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#api-funcgroup-pconn">8.8. Persistent connections</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#api-func-open">8.8.1. Open</a></span></dt>
<dt><span class="sect2"><a href="#api-func-close">8.8.2. Close</a></span></dt>
</dl></dd></dl></div>
<p>There is a number of native searchd client API implementations for
    Sphinx. As of time of this writing, we officially support our own PHP,
    Python, and Java implementations. There also are third party free,
    open-source API implementations for Perl, Ruby, and C++.</p><p>The reference API implementation is in PHP, because (we believe)
    Sphinx is most widely used with PHP than any other language. This
    reference documentation is in turn based on reference PHP API, and all
    code samples in this section will be given in PHP.</p><p>However, all other APIs provide the same methods and implement the
    very same network protocol. Therefore the documentation does apply to them
    as well. There might be minor differences as to the method naming
    conventions or specific data structures used. But the provided
    functionality must not differ across languages.</p><div class="sect1" title="8.1.&nbsp;General API functions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-general"></a>8.1.&nbsp;General API functions</h2></div></div></div>
<div class="sect2" title="8.1.1.&nbsp;GetLastError"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-getlasterror"></a>8.1.1.&nbsp;GetLastError</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function GetLastError()</p><p>Returns last error message, as a string, in human readable
        format. If there were no errors during the previous API call, empty
        string is returned.</p><p>You should call it when any other function (such as <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query">Query()</a>) fails (typically, the failing
        function returns false). The returned string will contain the error
        description.</p><p>The error message is <span class="emphasis"><em>not</em></span> reset by this
        call; so you can safely call it several times if needed.</p></div>
<div class="sect2" title="8.1.2.&nbsp;GetLastWarning"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-getlastwarning"></a>8.1.2.&nbsp;GetLastWarning</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function GetLastWarning ()</p><p>Returns last warning message, as a string, in human readable
        format. If there were no warnings during the previous API call, empty
        string is returned.</p><p>You should call it to verify whether your request (such as <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query">Query()</a>) was completed but with
        warnings. For instance, search query against a distributed index might
        complete succesfully even if several remote agents timed out. In that
        case, a warning message would be produced.</p><p>The warning message is <span class="emphasis"><em>not</em></span> reset by this
        call; so you can safely call it several times if needed.</p></div>
<div class="sect2" title="8.1.3.&nbsp;SetServer"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setserver"></a>8.1.3.&nbsp;SetServer</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetServer ( $host, $port )</p><p>Sets <code class="filename">searchd</code> host name and TCP port. All
        subsequent requests will use the new host and port settings. Default
        host and port are 'localhost' and 9312, respectively.</p></div>
<div class="sect2" title="8.1.4.&nbsp;SetRetries"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setretries"></a>8.1.4.&nbsp;SetRetries</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetRetries ( $count, $delay=0
        )</p><p>Sets distributed retry count and delay.</p><p>On temporary failures <code class="filename">searchd</code> will attempt
        up to <code class="code">$count</code> retries per agent. <code class="code">$delay</code> is
        the delay between the retries, in milliseconds. Retries are disabled
        by default. Note that this call will <span class="bold"><strong>not</strong></span> make the API itself
        retry on temporary failure; it only tells <code class="filename">searchd</code>
        to do so. Currently, the list of temporary failures includes all kinds
        of connect() failures and maxed out (too busy) remote agents.</p></div>
<div class="sect2" title="8.1.5.&nbsp;SetConnectTimeout"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setconnecttimeout"></a>8.1.5.&nbsp;SetConnectTimeout</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetConnectTimeout ( $timeout )</p><p>Sets the time allowed to spend connecting to the server before
        giving up.</p><p>Under some circumstances, the server can be delayed in
        responding, either due to network delays, or a query backlog. In
        either instance, this allows the client application programmer some
        degree of control over how their program interacts with
        <code class="filename">searchd</code> when not available, and can ensure that
        the client application does not fail due to exceeding the script
        execution limits (especially in PHP).</p><p>In the event of a failure to connect, an appropriate error code
        should be returned back to the application in order for
        application-level error handling to advise the user.</p></div>
<div class="sect2" title="8.1.6.&nbsp;SetArrayResult"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setarrayresult"></a>8.1.6.&nbsp;SetArrayResult</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetArrayResult ( $arrayresult
        )</p><p>PHP specific. Controls matches format in the search results set
        (whether matches should be returned as an array or a hash).</p><p><code class="code">$arrayresult</code> argument must be boolean. If
        <code class="code">$arrayresult</code> is <code class="code">false</code> (the default mode),
        matches will returned in PHP hash format with document IDs as keys,
        and other information (weight, attributes) as values. If
        <code class="code">$arrayresult</code> is true, matches will be returned as a plain
        array with complete per-match information including document
        ID.</p><p>Introduced along with GROUP BY support on MVA attributes.
        Group-by-MVA result sets may contain duplicate document IDs. Thus they
        need to be returned as plain arrays, because hashes will only keep one
        entry per document ID.</p></div>
<div class="sect2" title="8.1.7.&nbsp;IsConnectError"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-isconnecterror"></a>8.1.7.&nbsp;IsConnectError</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function IsConnectError ()</p><p>Checks whether the last error was a network error on API side,
        or a remote error reported by searchd. Returns true if the last
        connection attempt to searchd failed on API side, false otherwise (if
        the error was remote, or there were no connection attempts at all).
        Introduced in version 0.9.9-rc1.</p></div></div>
<div class="sect1" title="8.2.&nbsp;General query settings"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-general-query-settings"></a>8.2.&nbsp;General query settings</h2></div></div></div>
<div class="sect2" title="8.2.1.&nbsp;SetLimits"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setlimits"></a>8.2.1.&nbsp;SetLimits</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetLimits ( $offset, $limit,
        $max_matches=0, $cutoff=0 )</p><p>Sets offset into server-side result set (<code class="code">$offset</code>)
        and amount of matches to return to client starting from that offset
        (<code class="code">$limit</code>). Can additionally control maximum server-side
        result set size for current query (<code class="code">$max_matches</code>) and the
        threshold amount of matches to stop searching at
        (<code class="code">$cutoff</code>). All parameters must be non-negative
        integers.</p><p>First two parameters to SetLimits() are identical in behavior to
        MySQL LIMIT clause. They instruct <code class="filename">searchd</code> to
        return at most <code class="code">$limit</code> matches starting from match number
        <code class="code">$offset</code>. The default offset and limit settings are 0 and
        20, that is, to return first 20 matches.</p><p><code class="code">max_matches</code> setting controls how much matches
        <code class="filename">searchd</code> will keep in RAM while searching.
        <span class="bold"><strong>All</strong></span> matching documents will be normally processed, ranked,
        filtered, and sorted even if <code class="code">max_matches</code> is set to 1. But
        only best N documents are stored in memory at any given moment for
        performance and RAM usage reasons, and this setting controls that N.
        Note that there are <span class="bold"><strong>two</strong></span> places where <code class="code">max_matches</code>
        limit is enforced. Per-query limit is controlled by this API call, but
        there also is per-server limit controlled by <code class="code">max_matches</code>
        setting in the config file. To prevent RAM usage abuse, server will
        not allow to set per-query limit higher than the per-server
        limit.</p><p>You can't retrieve more than <code class="code">max_matches</code> matches to
        the client application. The default limit is set to 1000. Normally,
        you must not have to go over this limit. One thousand records is
        enough to present to the end user. And if you're thinking about
        pulling the results to application for further sorting or filtering,
        that would be <span class="bold"><strong>much</strong></span> more efficient if performed on Sphinx
        side.</p><p><code class="code">$cutoff</code> setting is intended for advanced
        performance control. It tells <code class="filename">searchd</code> to forcibly
        stop search query once <code class="code">$cutoff</code> matches had been found and
        processed.</p></div>
<div class="sect2" title="8.2.2.&nbsp;SetMaxQueryTime"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setmaxquerytime"></a>8.2.2.&nbsp;SetMaxQueryTime</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetMaxQueryTime ( $max_query_time
        )</p><p>Sets maximum search query time, in milliseconds. Parameter must
        be a non-negative integer. Default valus is 0 which means "do not
        limit".</p><p>Similar to <code class="code">$cutoff</code> setting from <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a>, but limits elapsed
        query time instead of processed matches count. Local search queries
        will be stopped once that much time has elapsed. Note that if you're
        performing a search which queries several local indexes, this limit
        applies to each index separately.</p></div>
<div class="sect2" title="8.2.3.&nbsp;SetOverride"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setoverride"></a>8.2.3.&nbsp;SetOverride</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetOverride ( $attrname, $attrtype,
        $values )</p><p>Sets temporary (per-query) per-document attribute value
        overrides. Only supports scalar attributes. $values must be a hash
        that maps document IDs to overridden attribute values. Introduced in
        version 0.9.9-rc1.</p><p>Override feature lets you "temporary" update attribute values
        for some documents within a single query, leaving all other queries
        unaffected. This might be useful for personalized data. For example,
        assume you're implementing a personalized search function that wants
        to boost the posts that the user's friends recommend. Such data is not
        just dynamic, but also personal; so you can't simply put it in the
        index because you don't want everyone's searches affected. Overrides,
        on the other hand, are local to a single query and invisible to
        everyone else. So you can, say, setup a "friends_weight" value for
        every document, defaulting to 0, then temporary override it with 1 for
        documents 123, 456 and 789 (recommended by exactly the friends of
        current user), and use that value when ranking.</p></div>
<div class="sect2" title="8.2.4.&nbsp;SetSelect"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setselect"></a>8.2.4.&nbsp;SetSelect</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetSelect ( $clause )</p><p>Sets the select clause, listing specific attributes to fetch,
        and <a class="link" href="#sort-expr" title="5.6.&nbsp;SPH_SORT_EXPR mode">expressions</a> to compute and fetch.
        Clause syntax mimics SQL. Introduced in version 0.9.9-rc1.</p><p>SetSelect() is very similar to the part of a typical SQL query
        between SELECT and FROM. It lets you choose what attributes (columns)
        to fetch, and also what expressions over the columns to compute and
        fetch. A certain difference from SQL is that expressions <span class="bold"><strong>must</strong></span>
        always be aliased to a correct identifier (consisting of letters and
        digits) using 'AS' keyword. SQL also lets you do that but does not
        require to. Sphinx enforces aliases so that the computation results
        can always be returned under a "normal" name in the result set, used
        in other clauses, etc.</p><p>Everything else is basically identical to SQL. Star ('*') is
        supported. Functions are supported. Arbitrary amount of expressions is
        supported. Computed expressions can be used for sorting, filtering,
        and grouping, just as the regular attributes.</p><p>Starting with version 0.9.9-rc2, aggregate functions (AVG(),
        MIN(), MAX(), SUM()) are supported when using GROUP BY.</p><p>Expression sorting (<a class="xref" href="#sort-expr" title="5.6.&nbsp;SPH_SORT_EXPR mode">Section&nbsp;5.6, “SPH_SORT_EXPR mode”</a>) and
        geodistance functions (<a class="xref" href="#api-func-setgeoanchor" title="8.4.5.&nbsp;SetGeoAnchor">Section&nbsp;8.4.5, “SetGeoAnchor”</a>) are
        now internally implemented using this computed expressions mechanism,
        using magic names '@expr' and '@geodist' respectively.</p><h4>Example:</h4><pre class="programlisting">$cl-&gt;SetSelect ( "*, @weight+(user_karma+ln(pageviews))*0.1 AS myweight" );
$cl-&gt;SetSelect ( "exp_years, salary_gbp*{$gbp_usd_rate} AS salary_usd,
   IF(age&gt;40,1,0) AS over40" );
$cl-&gt;SetSelect ( "*, AVG(price) AS avgprice" );
</pre></div></div>
<div class="sect1" title="8.3.&nbsp;Full-text search query settings"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-fulltext-query-settings"></a>8.3.&nbsp;Full-text search query settings</h2></div></div></div>
<div class="sect2" title="8.3.1.&nbsp;SetMatchMode"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setmatchmode"></a>8.3.1.&nbsp;SetMatchMode</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetMatchMode ( $mode )</p><p>Sets full-text query matching mode, as described in <a class="xref" href="#matching-modes" title="5.1.&nbsp;Matching modes">Section&nbsp;5.1, “Matching modes”</a>. Parameter must be a constant specifying
        one of the known modes.</p><p><span class="bold"><strong>WARNING:</strong></span> (PHP specific) you <span class="bold"><strong>must not</strong></span> take the
        matching mode constant name in quotes, that syntax specifies a string
        and is incorrect: </p><pre class="programlisting">$cl-&gt;SetMatchMode ( "SPH_MATCH_ANY" ); // INCORRECT! will not work as expected
$cl-&gt;SetMatchMode ( SPH_MATCH_ANY ); // correct, works OK
</pre></div>
<div class="sect2" title="8.3.2.&nbsp;SetRankingMode"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setrankingmode"></a>8.3.2.&nbsp;SetRankingMode</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetRankingMode ( $ranker )</p><p>Sets ranking mode. Only available in SPH_MATCH_EXTENDED2
        matching mode at the time of this writing. Parameter must be a
        constant specifying one of the known modes.</p><p>By default, Sphinx computes two factors which contribute to the
        final match weight. The major part is query phrase proximity to
        document text. The minor part is so-called BM25 statistical function,
        which varies from 0 to 1 depending on the keyword frequency within
        document (more occurrences yield higher weight) and within the whole
        index (more rare keywords yield higher weight).</p><p>However, in some cases you'd want to compute weight differently
        - or maybe avoid computing it at all for performance reasons because
        you're sorting the result set by something else anyway. This can be
        accomplished by setting the appropriate ranking mode.</p><p>Currently implemented modes are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>SPH_RANK_PROXIMITY_BM25, default ranking mode which uses
              and combines both phrase proximity and BM25 ranking.</p></li>
<li class="listitem"><p>SPH_RANK_BM25, statistical ranking mode which uses BM25
              ranking only (similar to most other full-text engines). This
              mode is faster but may result in worse quality on queries which
              contain more than 1 keyword.</p></li>
<li class="listitem"><p>SPH_RANK_NONE, disabled ranking mode. This mode is the
              fastest. It is essentially equivalent to boolean searching. A
              weight of 1 is assigned to all matches.</p></li>
<li class="listitem"><p>SPH_RANK_WORDCOUNT, ranking by keyword occurrences count.
              This ranker computes the amount of per-field keyword
              occurrences, then multiplies the amounts by field weights, then
              sums the resulting values for the final result.</p></li>
<li class="listitem"><p>SPH_RANK_PROXIMITY, added in version 0.9.9-rc1, returns
              raw phrase proximity value as a result. This mode is internally
              used to emulate SPH_MATCH_ALL queries.</p></li>
<li class="listitem"><p>SPH_RANK_MATCHANY, added in version 0.9.9-rc1, returns
              rank as it was computed in SPH_MATCH_ANY mode ealier, and is
              internally used to emulate SPH_MATCH_ANY queries.</p></li>
<li class="listitem"><p>SPH_RANK_FIELDMASK, added in version 0.9.9-rc2, returns a
              32-bit mask with N-th bit corresponding to N-th fulltext field,
              numbering from 0. The bit will only be set when the respective
              field has any keyword occurences satisfiying the query.</p></li>
<li class="listitem"><p>SPH_RANK_SPH04, added in version 1.10-beta, is generally
              based on the default SPH_RANK_PROXIMITY_BM25 ranker, but
              additionally boosts the matches when they occur in the very
              beginning or the very end of a text field. Thus, if a field
              equals the exact query, SPH04 should rank it higher than a field
              that contains the exact query but is not equal to it. (For
              instance, when the query is "Hyde Park", a document entitled
              "Hyde Park" should be ranked higher than a one entitled "Hyde
              Park, London" or "The Hyde Park Cafe".)</p></li>
</ul></div></div>
<div class="sect2" title="8.3.3.&nbsp;SetSortMode"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setsortmode"></a>8.3.3.&nbsp;SetSortMode</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetSortMode ( $mode, $sortby=""
        )</p><p>Set matches sorting mode, as described in <a class="xref" href="#sorting-modes" title="5.6.&nbsp;Sorting modes">Section&nbsp;5.6, “Sorting modes”</a>. Parameter must be a constant specifying
        one of the known modes.</p><p><span class="bold"><strong>WARNING:</strong></span> (PHP specific) you <span class="bold"><strong>must not</strong></span> take the
        matching mode constant name in quotes, that syntax specifies a string
        and is incorrect: </p><pre class="programlisting">$cl-&gt;SetSortMode ( "SPH_SORT_ATTR_DESC" ); // INCORRECT! will not work as expected
$cl-&gt;SetSortMode ( SPH_SORT_ATTR_ASC ); // correct, works OK
</pre></div>
<div class="sect2" title="8.3.4.&nbsp;SetWeights"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setweights"></a>8.3.4.&nbsp;SetWeights</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetWeights ( $weights )</p><p>Binds per-field weights in the order of appearance in the index.
        <span class="bold"><strong>DEPRECATED</strong></span>, use <a class="link" href="#api-func-setfieldweights" title="8.3.5.&nbsp;SetFieldWeights">SetFieldWeights()</a>
        instead.</p></div>
<div class="sect2" title="8.3.5.&nbsp;SetFieldWeights"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setfieldweights"></a>8.3.5.&nbsp;SetFieldWeights</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetFieldWeights ( $weights )</p><p>Binds per-field weights by name. Parameter must be a hash
        (associative array) mapping string field names to integer
        weights.</p><p>Match ranking can be affected by per-field weights. For
        instance, see <a class="xref" href="#weighting" title="5.4.&nbsp;Weighting">Section&nbsp;5.4, “Weighting”</a> for an explanation how
        phrase proximity ranking is affected. This call lets you specify what
        non-default weights to assign to different full-text fields.</p><p>The weights must be positive 32-bit integers. The final weight
        will be a 32-bit integer too. Default weight value is 1. Unknown field
        names will be silently ignored.</p><p>There is no enforced limit on the maximum weight value at the
        moment. However, beware that if you set it too high you can start
        hitting 32-bit wraparound issues. For instance, if you set a weight of
        10,000,000 and search in extended mode, then maximum possible weight
        will be equal to 10 million (your weight) by 1 thousand (internal BM25
        scaling factor, see <a class="xref" href="#weighting" title="5.4.&nbsp;Weighting">Section&nbsp;5.4, “Weighting”</a>) by 1 or more (phrase
        proximity rank). The result is at least 10 billion that does not fit
        in 32 bits and will be wrapped around, producing unexpected
        results.</p></div>
<div class="sect2" title="8.3.6.&nbsp;SetIndexWeights"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setindexweights"></a>8.3.6.&nbsp;SetIndexWeights</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetIndexWeights ( $weights )</p><p>Sets per-index weights, and enables weighted summing of match
        weights across different indexes. Parameter must be a hash
        (associative array) mapping string index names to integer weights.
        Default is empty array that means to disable weighting summing.</p><p>When a match with the same document ID is found in several
        different local indexes, by default Sphinx simply chooses the match
        from the index specified last in the query. This is to support
        searching through partially overlapping index partitions.</p><p>However in some cases the indexes are not just partitions, and
        you might want to sum the weights across the indexes instead of
        picking one. <code class="code">SetIndexWeights()</code> lets you do that. With
        summing enabled, final match weight in result set will be computed as
        a sum of match weight coming from the given index multiplied by
        respective per-index weight specified in this call. Ie. if the
        document 123 is found in index A with the weight of 2, and also in
        index B with the weight of 3, and you called <code class="code">SetIndexWeights (
        array ( "A"=&gt;100, "B"=&gt;10 ) )</code>, the final weight return to
        the client will be 2*100+3*10 = 230.</p></div></div>
<div class="sect1" title="8.4.&nbsp;Result set filtering settings"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-filtering"></a>8.4.&nbsp;Result set filtering settings</h2></div></div></div>
<div class="sect2" title="8.4.1.&nbsp;SetIDRange"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setidrange"></a>8.4.1.&nbsp;SetIDRange</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetIDRange ( $min, $max )</p><p>Sets an accepted range of document IDs. Parameters must be
        integers. Defaults are 0 and 0; that combination means to not limit by
        range.</p><p>After this call, only those records that have document ID
        between <code class="code">$min</code> and <code class="code">$max</code> (including IDs exactly
        equal to <code class="code">$min</code> or <code class="code">$max</code>) will be
        matched.</p></div>
<div class="sect2" title="8.4.2.&nbsp;SetFilter"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setfilter"></a>8.4.2.&nbsp;SetFilter</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetFilter ( $attribute, $values,
        $exclude=false )</p><p>Adds new integer values set filter.</p><p>On this call, additional new filter is added to the existing
        list of filters. <code class="code">$attribute</code> must be a string with
        attribute name. <code class="code">$values</code> must be a plain array containing
        integer values. <code class="code">$exclude</code> must be a boolean value; it
        controls whether to accept the matching documents (default mode, when
        <code class="code">$exclude</code> is false) or reject them.</p><p>Only those documents where <code class="code">$attribute</code> column value
        stored in the index matches any of the values from
        <code class="code">$values</code> array will be matched (or rejected, if
        <code class="code">$exclude</code> is true).</p></div>
<div class="sect2" title="8.4.3.&nbsp;SetFilterRange"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setfilterrange"></a>8.4.3.&nbsp;SetFilterRange</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetFilterRange ( $attribute, $min,
        $max, $exclude=false )</p><p>Adds new integer range filter.</p><p>On this call, additional new filter is added to the existing
        list of filters. <code class="code">$attribute</code> must be a string with
        attribute name. <code class="code">$min</code> and <code class="code">$max</code> must be
        integers that define the acceptable attribute values range (including
        the boundaries). <code class="code">$exclude</code> must be a boolean value; it
        controls whether to accept the matching documents (default mode, when
        <code class="code">$exclude</code> is false) or reject them.</p><p>Only those documents where <code class="code">$attribute</code> column value
        stored in the index is between <code class="code">$min</code> and <code class="code">$max</code>
        (including values that are exactly equal to <code class="code">$min</code> or
        <code class="code">$max</code>) will be matched (or rejected, if
        <code class="code">$exclude</code> is true).</p></div>
<div class="sect2" title="8.4.4.&nbsp;SetFilterFloatRange"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setfilterfloatrange"></a>8.4.4.&nbsp;SetFilterFloatRange</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetFilterFloatRange ( $attribute,
        $min, $max, $exclude=false )</p><p>Adds new float range filter.</p><p>On this call, additional new filter is added to the existing
        list of filters. <code class="code">$attribute</code> must be a string with
        attribute name. <code class="code">$min</code> and <code class="code">$max</code> must be floats
        that define the acceptable attribute values range (including the
        boundaries). <code class="code">$exclude</code> must be a boolean value; it
        controls whether to accept the matching documents (default mode, when
        <code class="code">$exclude</code> is false) or reject them.</p><p>Only those documents where <code class="code">$attribute</code> column value
        stored in the index is between <code class="code">$min</code> and <code class="code">$max</code>
        (including values that are exactly equal to <code class="code">$min</code> or
        <code class="code">$max</code>) will be matched (or rejected, if
        <code class="code">$exclude</code> is true).</p></div>
<div class="sect2" title="8.4.5.&nbsp;SetGeoAnchor"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setgeoanchor"></a>8.4.5.&nbsp;SetGeoAnchor</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetGeoAnchor ( $attrlat, $attrlong,
        $lat, $long )</p><p>Sets anchor point for and geosphere distance (geodistance)
        calculations, and enable them.</p><p><code class="code">$attrlat</code> and <code class="code">$attrlong</code> must be strings
        that contain the names of latitude and longitude attributes,
        respectively. <code class="code">$lat</code> and <code class="code">$long</code> are floats that
        specify anchor point latitude and longitude, in radians.</p><p>Once an anchor point is set, you can use magic
        <code class="code">"@geodist"</code> attribute name in your filters and/or sorting
        expressions. Sphinx will compute geosphere distance between the given
        anchor point and a point specified by latitude and lognitude
        attributes from each full-text match, and attach this value to the
        resulting match. The latitude and longitude values both in
        <code class="code">SetGeoAnchor</code> and the index attribute data are expected to
        be in radians. The result will be returned in meters, so geodistance
        value of 1000.0 means 1 km. 1 mile is approximately 1609.344
        meters.</p></div></div>
<div class="sect1" title="8.5.&nbsp;GROUP BY settings"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-groupby"></a>8.5.&nbsp;GROUP BY settings</h2></div></div></div>
<div class="sect2" title="8.5.1.&nbsp;SetGroupBy"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setgroupby"></a>8.5.1.&nbsp;SetGroupBy</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetGroupBy ( $attribute, $func,
        $groupsort="@group desc" )</p><p>Sets grouping attribute, function, and groups sorting mode; and
        enables grouping (as described in <a class="xref" href="#clustering" title="5.7.&nbsp;Grouping (clustering) search results">Section&nbsp;5.7, “Grouping (clustering) search results”</a>).</p><p><code class="code">$attribute</code> is a string that contains group-by
        attribute name. <code class="code">$func</code> is a constant that chooses a
        function applied to the attribute value in order to compute group-by
        key. <code class="code">$groupsort</code> is a clause that controls how the groups
        will be sorted. Its syntax is similar to that described in <a class="xref" href="#sort-extended" title="5.6.&nbsp;SPH_SORT_EXTENDED mode">Section&nbsp;5.6, “SPH_SORT_EXTENDED mode”</a>.</p><p>Grouping feature is very similar in nature to GROUP BY clause
        from SQL. Results produces by this function call are going to be the
        same as produced by the following pseudo code: </p><pre class="programlisting">SELECT ... GROUP BY $func($attribute) ORDER BY $groupsort
</pre><p> Note that it's <code class="code">$groupsort</code> that affects the
        order of matches in the final result set. Sorting mode (see <a class="xref" href="#api-func-setsortmode" title="8.3.3.&nbsp;SetSortMode">Section&nbsp;8.3.3, “SetSortMode”</a>) affect the ordering of matches
        <span class="emphasis"><em>within</em></span> group, ie. what match will be selected as
        the best one from the group. So you can for instance order the groups
        by matches count and select the most relevant match within each group
        at the same time.</p><p>Starting with version 0.9.9-rc2, aggregate functions (AVG(),
        MIN(), MAX(), SUM()) are supported through <a class="link" href="#api-func-setselect" title="8.2.4.&nbsp;SetSelect">SetSelect()</a> API call when using
        GROUP BY.</p><p>Starting with version 2.0.1-beta, grouping on string attributes
        is supported, with respect to current collation.</p></div>
<div class="sect2" title="8.5.2.&nbsp;SetGroupDistinct"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-setgroupdistinct"></a>8.5.2.&nbsp;SetGroupDistinct</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function SetGroupDistinct ( $attribute
        )</p><p>Sets attribute name for per-group distinct values count
        calculations. Only available for grouping queries.</p><p><code class="code">$attribute</code> is a string that contains the attribute
        name. For each group, all values of this attribute will be stored (as
        RAM limits permit), then the amount of distinct values will be
        calculated and returned to the client. This feature is similar to
        <code class="code">COUNT(DISTINCT)</code> clause in standard SQL; so these Sphinx
        calls: </p><pre class="programlisting">$cl-&gt;SetGroupBy ( "category", SPH_GROUPBY_ATTR, "@count desc" );
$cl-&gt;SetGroupDistinct ( "vendor" );
</pre><p> can be expressed using the following SQL clauses:
        </p><pre class="programlisting">SELECT id, weight, all-attributes,
	COUNT(DISTINCT vendor) AS @distinct,
	COUNT(*) AS @count
FROM products
GROUP BY category
ORDER BY @count DESC
</pre><p> In the sample pseudo code shown just above,
        <code class="code">SetGroupDistinct()</code> call corresponds to
        <code class="code">COUNT(DISINCT vendor)</code> clause only. <code class="code">GROUP BY</code>,
        <code class="code">ORDER BY</code>, and <code class="code">COUNT(*)</code> clauses are all an
        equivalent of <code class="code">SetGroupBy()</code> settings. Both queries will
        return one matching row for each category. In addition to indexed
        attributes, matches will also contain total per-category matches
        count, and the count of distinct vendor IDs within each
        category.</p></div></div>
<div class="sect1" title="8.6.&nbsp;Querying"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-querying"></a>8.6.&nbsp;Querying</h2></div></div></div>
<div class="sect2" title="8.6.1.&nbsp;Query"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-query"></a>8.6.1.&nbsp;Query</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function Query ( $query, $index="*",
        $comment="" )</p><p>Connects to <code class="filename">searchd</code> server, runs given
        search query with current settings, obtains and returns the result
        set.</p><p><code class="code">$query</code> is a query string. <code class="code">$index</code> is an
        index name (or names) string. Returns false and sets
        <code class="code">GetLastError()</code> message on general error. Returns search
        result set on success. Additionally, the contents of
        <code class="code">$comment</code> are sent to the query log, marked in square
        brackets, just before the search terms, which can be very useful for
        debugging. Currently, the comment is limited to 128 characters.</p><p>Default value for <code class="code">$index</code> is <code class="code">"*"</code> that
        means to query all local indexes. Characters allowed in index names
        include Latin letters (a-z), numbers (0-9), minus sign (-), and
        underscore (_); everything else is considered a separator. Therefore,
        all of the following samples calls are valid and will search the same
        two indexes: </p><pre class="programlisting">$cl-&gt;Query ( "test query", "main delta" );
$cl-&gt;Query ( "test query", "main;delta" );
$cl-&gt;Query ( "test query", "main, delta" );
</pre><p> Index specification order matters. If document with
        identical IDs are found in two or more indexes, weight and attribute
        values from the very last matching index will be used for sorting and
        returning to client (unless explicitly overridden with <a class="link" href="#api-func-setindexweights" title="8.3.6.&nbsp;SetIndexWeights">SetIndexWeights()</a>).
        Therefore, in the example above, matches from "delta" index will
        always win over matches from "main".</p><p>On success, <code class="code">Query()</code> returns a result set that
        contains some of the found matches (as requested by <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a>) and additional
        general per-query statistics. The result set is a hash (PHP specific;
        other languages might utilize other structures instead of hash) with
        the following keys and values: </p><div class="variablelist"><dl><dt><span class="term">"matches":</span></dt>
<dd><p>Hash which maps found document IDs to another small hash
                containing document weight and attribute values (or an array
                of the similar small hashes if <a class="link" href="#api-func-setarrayresult" title="8.1.6.&nbsp;SetArrayResult">SetArrayResult()</a> was
                enabled).</p></dd><dt><span class="term">"total":</span></dt>
<dd><p>Total amount of matches retrieved <span class="emphasis"><em>on
                server</em></span> (ie. to the server side result set) by this
                query. You can retrieve up to this amount of matches from
                server for this query text with current query settings.</p></dd><dt><span class="term">"total_found":</span></dt>
<dd><p>Total amount of matching documents in index (that were
                found and procesed on server).</p></dd><dt><span class="term">"words":</span></dt>
<dd><p>Hash which maps query keywords (case-folded, stemmed,
                and otherwise processed) to a small hash with per-keyword
                statitics ("docs", "hits").</p></dd><dt><span class="term">"error":</span></dt>
<dd><p>Query error message reported by
                <code class="filename">searchd</code> (string, human readable). Empty
                if there were no errors.</p></dd><dt><span class="term">"warning":</span></dt>
<dd><p>Query warning message reported by
                <code class="filename">searchd</code> (string, human readable). Empty
                if there were no warnings.</p></dd></dl></div>
<p>It should be noted that <code class="code">Query()</code> carries out the
        same actions as <code class="code">AddQuery()</code> and <code class="code">RunQueries()</code>
        without the intermediate steps; it is analoguous to a single
        <code class="code">AddQuery()</code> call, followed by a corresponding
        <code class="code">RunQueries()</code>, then returning the first array element of
        matches (from the first, and only, query.)</p></div>
<div class="sect2" title="8.6.2.&nbsp;AddQuery"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-addquery"></a>8.6.2.&nbsp;AddQuery</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function AddQuery ( $query, $index="*",
        $comment="" )</p><p>Adds additional query with current settings to multi-query
        batch. <code class="code">$query</code> is a query string. <code class="code">$index</code> is
        an index name (or names) string. Additionally if provided, the
        contents of <code class="code">$comment</code> are sent to the query log, marked in
        square brackets, just before the search terms, which can be very
        useful for debugging. Currently, this is limited to 128 characters.
        Returns index to results array returned from <a class="link" href="#api-func-runqueries" title="8.6.3.&nbsp;RunQueries">RunQueries()</a>.</p><p>Batch queries (or multi-queries) enable
        <code class="filename">searchd</code> to perform internal optimizations if
        possible. They also reduce network connection overheads and search
        process creation overheads in all cases. They do not result in any
        additional overheads compared to simple queries. Thus, if you run
        several different queries from your web page, you should always
        consider using multi-queries.</p><p>For instance, running the same full-text query but with
        different sorting or group-by settings will enable
        <code class="filename">searchd</code> to perform expensive full-text search and
        ranking operation only once, but compute multiple group-by results
        from its output.</p><p>This can be a big saver when you need to display not just plain
        search results but also some per-category counts, such as the amount
        of products grouped by vendor. Without multi-query, you would have to
        run several queries which perform essentially the same search and
        retrieve the same matches, but create result sets differently. With
        multi-query, you simply pass all these querys in a single batch and
        Sphinx optimizes the redundant full-text search internally.</p><p><code class="code">AddQuery()</code> internally saves full current settings
        state along with the query, and you can safely change them afterwards
        for subsequent <code class="code">AddQuery()</code> calls. Already added queries
        will not be affected; there's actually no way to change them at all.
        Here's an example: </p><pre class="programlisting">$cl-&gt;SetSortMode ( SPH_SORT_RELEVANCE );
$cl-&gt;AddQuery ( "hello world", "documents" );

$cl-&gt;SetSortMode ( SPH_SORT_ATTR_DESC, "price" );
$cl-&gt;AddQuery ( "ipod", "products" );

$cl-&gt;AddQuery ( "harry potter", "books" );

$results = $cl-&gt;RunQueries ();
</pre><p> With the code above, 1st query will search for "hello world"
        in "documents" index and sort results by relevance, 2nd query will
        search for "ipod" in "products" index and sort results by price, and
        3rd query will search for "harry potter" in "books" index while still
        sorting by price. Note that 2nd <code class="code">SetSortMode()</code> call does
        not affect the first query (because it's already added) but affects
        both other subsequent queries.</p><p>Additionally, any filters set up before an
        <code class="code">AddQuery()</code> will fall through to subsequent queries. So,
        if <code class="code">SetFilter()</code> is called before the first query, the same
        filter will be in place for the second (and subsequent) queries
        batched through <code class="code">AddQuery()</code> unless you call
        <code class="code">ResetFilters()</code> first. Alternatively, you can add
        additional filters as well.</p><p>This would also be true for grouping options and sorting
        options; no current sorting, filtering, and grouping settings are
        affected by this call; so subsequent queries will reuse current query
        settings.</p><p><code class="code">AddQuery()</code> returns an index into an array of
        results that will be returned from <code class="code">RunQueries()</code> call. It
        is simply a sequentially increasing 0-based integer, ie. first call
        will return 0, second will return 1, and so on. Just a small helper so
        you won't have to track the indexes manualy if you need then.</p></div>
<div class="sect2" title="8.6.3.&nbsp;RunQueries"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-runqueries"></a>8.6.3.&nbsp;RunQueries</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function RunQueries ()</p><p>Connect to searchd, runs a batch of all queries added using
        <code class="code">AddQuery()</code>, obtains and returns the result sets. Returns
        false and sets <code class="code">GetLastError()</code> message on general error
        (such as network I/O failure). Returns a plain array of result sets on
        success.</p><p>Each result set in the returned array is exactly the same as the
        result set returned from <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query"><code class="code">Query()</code></a>.</p><p>Note that the batch query request itself almost always succeds -
        unless there's a network error, blocking index rotation in progress,
        or another general failure which prevents the whole request from being
        processed.</p><p>However individual queries within the batch might very well
        fail. In this case their respective result sets will contain non-empty
        <code class="code">"error"</code> message, but no matches or query statistics. In
        the extreme case all queries within the batch could fail. There still
        will be no general error reported, because API was able to succesfully
        connect to <code class="filename">searchd</code>, submit the batch, and receive
        the results - but every result set will have a specific error
        message.</p></div>
<div class="sect2" title="8.6.4.&nbsp;ResetFilters"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-resetfilters"></a>8.6.4.&nbsp;ResetFilters</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function ResetFilters ()</p><p>Clears all currently set filters.</p><p>This call is only normally required when using multi-queries.
        You might want to set different filters for different queries in the
        batch. To do that, you should call <code class="code">ResetFilters()</code> and add
        new filters using the respective calls.</p></div>
<div class="sect2" title="8.6.5.&nbsp;ResetGroupBy"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-resetgroupby"></a>8.6.5.&nbsp;ResetGroupBy</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function ResetGroupBy ()</p><p>Clears all currently group-by settings, and disables
        group-by.</p><p>This call is only normally required when using multi-queries.
        You can change individual group-by settings using
        <code class="code">SetGroupBy()</code> and <code class="code">SetGroupDistinct()</code> calls,
        but you can not disable group-by using those calls.
        <code class="code">ResetGroupBy()</code> fully resets previous group-by settings
        and disables group-by mode in the current state, so that subsequent
        <code class="code">AddQuery()</code> calls can perform non-grouping
        searches.</p></div></div>
<div class="sect1" title="8.7.&nbsp;Additional functionality"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-additional-functionality"></a>8.7.&nbsp;Additional functionality</h2></div></div></div>
<div class="sect2" title="8.7.1.&nbsp;BuildExcerpts"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-buildexcerpts"></a>8.7.1.&nbsp;BuildExcerpts</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function BuildExcerpts ( $docs, $index,
        $words, $opts=array() )</p><p>Excerpts (snippets) builder function. Connects to
        <code class="filename">searchd</code>, asks it to generate excerpts (snippets)
        from given documents, and returns the results.</p><p><code class="code">$docs</code> is a plain array of strings that carry the
        documents' contents. <code class="code">$index</code> is an index name string.
        Different settings (such as charset, morphology, wordforms) from given
        index will be used. <code class="code">$words</code> is a string that contains the
        keywords to highlight. They will be processed with respect to index
        settings. For instance, if English stemming is enabled in the index,
        "shoes" will be highlighted even if keyword is "shoe". Starting with
        version 0.9.9-rc1, keywords can contain wildcards, that work similarly
        to <a class="link" href="#conf-enable-star" title="11.2.22.&nbsp;enable_star">star-syntax</a> available in
        queries. <code class="code">$opts</code> is a hash which contains additional
        optional highlighting parameters: </p><div class="variablelist"><dl><dt><span class="term">"before_match":</span></dt>
<dd><p>A string to insert before a keyword match. Starting with
                version 1.10-beta, a %PASSAGE_ID% macro can be used in this
                string. The macro is replaced with an incrementing passage
                number within a current snippet. Numbering starts at 1 by
                default but can be overridden with "start_passage_id" option.
                In a multi-document call, %PASSAGE_ID% would restart at every
                given document. Default is "&lt;b&gt;".</p></dd><dt><span class="term">"after_match":</span></dt>
<dd><p>A string to insert after a keyword match. Starting with
                version 1.10-beta, a %PASSAGE_ID% macro can be used in this
                string. Default is "&lt;/b&gt;".</p></dd><dt><span class="term">"chunk_separator":</span></dt>
<dd><p>A string to insert between snippet chunks (passages).
                Default is "&nbsp;...&nbsp;".</p></dd><dt><span class="term">"limit":</span></dt>
<dd><p>Maximum snippet size, in symbols (codepoints). Integer,
                default is 256.</p></dd><dt><span class="term">"around":</span></dt>
<dd><p>How much words to pick around each matching keywords
                block. Integer, default is 5.</p></dd><dt><span class="term">"exact_phrase":</span></dt>
<dd><p>Whether to highlight exact query phrase matches only
                instead of individual keywords. Boolean, default is
                false.</p></dd><dt><span class="term">"single_passage":</span></dt>
<dd><p>Whether to extract single best passage only. Boolean,
                default is false.</p></dd><dt><span class="term">"use_boundaries":</span></dt>
<dd><p>Whether to additionaly break passages by phrase boundary
                characters, as configured in index settings with <a class="link" href="#conf-phrase-boundary" title="11.2.25.&nbsp;phrase_boundary">phrase_boundary</a>
                directive. Boolean, default is false.</p></dd><dt><span class="term">"weight_order":</span></dt>
<dd><p>Whether to sort the extracted passages in order of
                relevance (decreasing weight), or in order of appearance in
                the document (increasing position). Boolean, default is
                false.</p></dd><dt><span class="term">"query_mode":</span></dt>
<dd><p>Added in version 1.10-beta. Whether to handle $words as
                a query in <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">extended
                syntax</a>, or as a bag of words (default behavior). For
                instance, in query mode ("one two" | "three four") will only
                highlight and include those occurrences "one two" or "three
                four" when the two words from each pair are adjacent to each
                other. In default mode, any single occurrence of "one", "two",
                "three", or "four" would be highlighted. Boolean, default is
                false.</p></dd><dt><span class="term">"force_all_words":</span></dt>
<dd><p>Added in version 1.10-beta. Ignores the snippet length
                limit until it includes all the keywords. Boolean, default is
                false.</p></dd><dt><span class="term">"limit_passages":</span></dt>
<dd><p>Added in version 1.10-beta. Limits the maximum number of
                passages that can be included into the snippet. Integer,
                default is 0 (no limit).</p></dd><dt><span class="term">"limit_words":</span></dt>
<dd><p>Added in version 1.10-beta. Limits the maximum number of
                keywords that can be included into the snippet. Integer,
                default is 0 (no limit).</p></dd><dt><span class="term">"start_passage_id":</span></dt>
<dd><p>Added in version 1.10-beta. Specifies the starting value
                of %PASSAGE_ID% macro (that gets detected and expanded in
                <code class="option">before_match</code>, <code class="option">after_match</code>
                strings). Integer, default is 1.</p></dd><dt><span class="term">"load_files":</span></dt>
<dd><p>Added in version 1.10-beta. Whether to handle $docs as
                data to extract snippets from (default behavior), or to treat
                it as file names, and load data from specified files on the
                server side. Starting with version 2.0.1-beta, up to <a class="link" href="#conf-dist-threads" title="11.4.29.&nbsp;dist_threads">dist_threads</a> worker threads
                per request will be created to parallelize the work when this
                flag is enabled. Boolean, default is false.</p></dd><dt><span class="term">"html_strip_mode":</span></dt>
<dd><p>Added in version 1.10-beta. HTML stripping mode setting.
                Defaults to "index", which means that index settings will be
                used. The other values are "none" and "strip", that forcibly
                skip or apply stripping irregardless of index settings; and
                "retain", that retains HTML markup and protects it from
                highlighting. The "retain" mode can only be used when
                highlighting full documents and thus requires that no snippet
                size limits are set. String, allowed values are "none",
                "strip", "index", and "retain".</p></dd><dt><span class="term">"allow_empty":</span></dt>
<dd><p>Added in version 1.10-beta. Allows empty string to be
                returned as highlighting result when a snippet could not be
                generated (no keywords match, or no passages fit the limit).
                By default, the beginning of original text would be returned
                instead of an empty string. Boolean, default is false.</p></dd><dt><span class="term">"passage_boundary":</span></dt>
<dd><p>Added in version 2.0.1-beta. Ensures that passages do
                not cross a sentence, paragraph, or zone boundary (when used
                with an index that has the respective indexing settings
                enabled). String, allowed values are "sentence", "paragraph",
                and "zone".</p></dd><dt><span class="term">"passage_boundary":</span></dt>
<dd><p>Added in version 2.0.1-beta. Ensures that passages do
                not cross a sentence, paragraph, or zone boundary (when used
                with an index that has the respective indexing settings
                enabled). String, allowed values are "sentence", "paragraph",
                and "zone".</p></dd><dt><span class="term">"emit_zones":</span></dt>
<dd><p>Added in version 2.0.1-beta. Emits an HTML tag with an
                enclosing zone name before each passage. Boolean, default is
                false.</p></dd></dl></div>
<p>Snippets extraction algorithm currently favors better passages
        (with closer phrase matches), and then passages with keywords not yet
        in snippet. Generally, it will try to highlight the best match with
        the query, and it will also to highlight all the query keywords, as
        made possible by the limtis. In case the document does not match the
        query, beginning of the document trimmed down according to the limits
        will be return by default. Starting with 1.10-beta, you can also
        return an empty snippet instead case by setting "allow_empty" option
        to true.</p><p>Returns false on failure. Returns a plain array of strings with
        excerpts (snippets) on success.</p></div>
<div class="sect2" title="8.7.2.&nbsp;UpdateAttributes"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-updateatttributes"></a>8.7.2.&nbsp;UpdateAttributes</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function UpdateAttributes ( $index, $attrs,
        $values )</p><p>Instantly updates given attribute values in given documents.
        Returns number of actually updated documents (0 or more) on success,
        or -1 on failure.</p><p><code class="code">$index</code> is a name of the index (or indexes) to be
        updated. <code class="code">$attrs</code> is a plain array with string attribute
        names, listing attributes that are updated. <code class="code">$values</code> is a
        hash where key is document ID, and value is a plain array of new
        attribute values.</p><p><code class="code">$index</code> can be either a single index name or a list,
        like in <code class="code">Query()</code>. Unlike <code class="code">Query()</code>, wildcard is
        not allowed and all the indexes to update must be specified
        explicitly. The list of indexes can include distributed index names.
        Updates on distributed indexes will be pushed to all agents.</p><p>The updates only work with <code class="code">docinfo=extern</code> storage
        strategy. They are very fast because they're working fully in RAM, but
        they can also be made persistent: updates are saved on disk on clean
        <code class="filename">searchd</code> shutdown initiated by SIGTERM signal.
        With additional restrictions, updates are also possible on MVA
        attributes; refer to <a class="link" href="#conf-mva-updates-pool" title="11.4.18.&nbsp;mva_updates_pool">mva_updates_pool</a> directive for
        details.</p><p>Usage example: </p><pre class="programlisting">$cl-&gt;UpdateAttributes ( "test1", array("group_id"), array(1=&gt;array(456)) );
$cl-&gt;UpdateAttributes ( "products", array ( "price", "amount_in_stock" ),
	array ( 1001=&gt;array(123,5), 1002=&gt;array(37,11), 1003=&gt;(25,129) ) );
</pre><p> The first sample statement will update document 1 in index
        "test1", setting "group_id" to 456. The second one will update
        documents 1001, 1002 and 1003 in index "products". For document 1001,
        the new price will be set to 123 and the new amount in stock to 5; for
        document 1002, the new price will be 37 and the new amount will be 11;
        etc.</p></div>
<div class="sect2" title="8.7.3.&nbsp;BuildKeywords"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-buildkeywords"></a>8.7.3.&nbsp;BuildKeywords</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function BuildKeywords ( $query, $index, $hits
        )</p><p>Extracts keywords from query using tokenizer settings for given
        index, optionally with per-keyword occurrence statistics. Returns an
        array of hashes with per-keyword information.</p><p><code class="code">$query</code> is a query to extract keywords from.
        <code class="code">$index</code> is a name of the index to get tokenizing settings
        and keyword occurrence statistics from. <code class="code">$hits</code> is a
        boolean flag that indicates whether keyword occurrence statistics are
        required.</p><p>Usage example:</p><pre class="programlisting">$keywords = $cl-&gt;BuildKeywords ( "this.is.my query", "test1", false );
</pre></div>
<div class="sect2" title="8.7.4.&nbsp;EscapeString"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-escapestring"></a>8.7.4.&nbsp;EscapeString</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function EscapeString ( $string )</p><p>Escapes characters that are treated as special operators by the
        query language parser. Returns an escaped string.</p><p><code class="code">$string</code> is a string to escape.</p><p>This function might seem redundant because it's trivial to
        implement in any calling application. However, as the set of special
        characters might change over time, it makes sense to have an API call
        that is guaranteed to escape all such characters at all times.</p><p>Usage example:</p><pre class="programlisting">$escaped = $cl-&gt;EscapeString ( "escaping-sample@query/string" );
</pre></div>
<div class="sect2" title="8.7.5.&nbsp;Status"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-status"></a>8.7.5.&nbsp;Status</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function Status ()</p><p>Queries searchd status, and returns an array of status variable
        name and value pairs.</p><p>Usage example:</p><pre class="programlisting">$status = $cl-&gt;Status ();
foreach ( $status as $row )
	print join ( ": ", $row ) . "\n";
</pre></div>
<div class="sect2" title="8.7.6.&nbsp;FlushAttributes"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-flushattributes"></a>8.7.6.&nbsp;FlushAttributes</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function FlushAttributes ()</p><p>Forces <code class="filename">searchd</code> to flush pending attribute
        updates to disk, and blocks until completion. Returns a non-negative
        internal "flush tag" on success. Returns -1 and sets an error message
        on error. Introduced in version 1.10-beta.</p><p>Attribute values updated using <a class="link" href="#api-func-updateatttributes" title="8.7.2.&nbsp;UpdateAttributes">UpdateAttributes()</a> API
        call are only kept in RAM until a so-called flush (which writes the
        current, possibly updated attribute values back to disk).
        FlushAttributes() call lets you enforce a flush. The call will block
        until <code class="filename">searchd</code> finishes writing the data to disk,
        which might take seconds or even minutes depending on the total data
        size (.spa file size). All the currently updated indexes will be
        flushed.</p><p>Flush tag should be treated as an ever growing magic number that
        does not mean anything. It's guaranteed to be non-negative. It is
        guaranteed to grow over time, though not necessarily in a sequential
        fashion; for instance, two calls that return 10 and then 1000
        respectively are a valid situation. If two calls to FlushAttrs()
        return the same tag, it means that there were no actual attribute
        updates in between them, and therefore current flushed state remained
        the same (for all indexes).</p><p>Usage example:</p><pre class="programlisting">$status = $cl-&gt;FlushAttributes ();
if ( $status&lt;0 )
	print "ERROR: " . $cl-&gt;GetLastError(); 
</pre></div></div>
<div class="sect1" title="8.8.&nbsp;Persistent connections"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="api-funcgroup-pconn"></a>8.8.&nbsp;Persistent connections</h2></div></div></div>
<p>Persistent connections allow to use single network connection to
      run multiple commands that would otherwise require reconnects.</p><div class="sect2" title="8.8.1.&nbsp;Open"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-open"></a>8.8.1.&nbsp;Open</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function Open ()</p><p>Opens persistent connection to the server.</p></div>
<div class="sect2" title="8.8.2.&nbsp;Close"><div class="titlepage"><div><div><h3 class="title"><a name="api-func-close"></a>8.8.2.&nbsp;Close</h3></div></div></div>
<p><span class="bold"><strong>Prototype:</strong></span> function Close ()</p><p>Closes previously opened persistent connection.</p></div></div></div>
<div class="chapter" title="Chapter&nbsp;9.&nbsp;MySQL storage engine (SphinxSE)"><div class="titlepage"><div><div><h2 class="title"><a name="sphinxse"></a>Chapter&nbsp;9.&nbsp;MySQL storage engine (SphinxSE)</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#sphinxse-overview">9.1. SphinxSE overview</a></span></dt>
<dt><span class="sect1"><a href="#sphinxse-installing">9.2. Installing SphinxSE</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#sphinxse-mysql50">9.2.1. Compiling MySQL 5.0.x with SphinxSE</a></span></dt>
<dt><span class="sect2"><a href="#sphinxse-mysql51">9.2.2. Compiling MySQL 5.1.x with SphinxSE</a></span></dt>
<dt><span class="sect2"><a href="#sphinxse-checking">9.2.3. Checking SphinxSE installation</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#sphinxse-using">9.3. Using SphinxSE</a></span></dt>
<dt><span class="sect1"><a href="#sphinxse-snippets">9.4. Building snippets (excerpts) via MySQL</a></span></dt>
</dl></div>
<div class="sect1" title="9.1.&nbsp;SphinxSE overview"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxse-overview"></a>9.1.&nbsp;SphinxSE overview</h2></div></div></div>
<p>SphinxSE is MySQL storage engine which can be compiled into MySQL
      server 5.x using its pluggable architecure. It is not available for
      MySQL 4.x series. It also requires MySQL 5.0.22 or higher in 5.0.x
      series, or MySQL 5.1.12 or higher in 5.1.x series.</p><p>Despite the name, SphinxSE does <span class="emphasis"><em>not</em></span> actually
      store any data itself. It is actually a built-in client which allows
      MySQL server to talk to <code class="filename">searchd</code>, run search
      queries, and obtain search results. All indexing and searching happen
      outside MySQL.</p><p>Obvious SphinxSE applications include: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>easier porting of MySQL FTS applications to Sphinx;</p></li>
<li class="listitem"><p>allowing Sphinx use with progamming languages for which
            native APIs are not available yet;</p></li>
<li class="listitem"><p>optimizations when additional Sphinx result set processing
            on MySQL side is required (eg. JOINs with original document
            tables, additional MySQL-side filtering, etc).</p></li>
</ul></div></div>
<div class="sect1" title="9.2.&nbsp;Installing SphinxSE"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxse-installing"></a>9.2.&nbsp;Installing SphinxSE</h2></div></div></div>
<p>You will need to obtain a copy of MySQL sources, prepare those,
      and then recompile MySQL binary. MySQL sources (mysql-5.x.yy.tar.gz)
      could be obtained from <a class="ulink" href="http://dev.mysql.com" target="_top">dev.mysql.com</a> Web site.</p><p>For some MySQL versions, there are delta tarballs with already
      prepared source versions available from Sphinx Web site. After unzipping
      those over original sources MySQL would be ready to be configured and
      built with Sphinx support.</p><p>If such tarball is not available, or does not work for you for any
      reason, you would have to prepare sources manually. You will need to GNU
      Autotools framework (autoconf, automake and libtool) installed to do
      that.</p><div class="sect2" title="9.2.1.&nbsp;Compiling MySQL 5.0.x with SphinxSE"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-mysql50"></a>9.2.1.&nbsp;Compiling MySQL 5.0.x with SphinxSE</h3></div></div></div>
<p>Skips steps 1-3 if using already prepared delta tarball.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>copy <code class="filename">sphinx.5.0.yy.diff</code> patch file into
            MySQL sources directory and run </p><pre class="programlisting">patch -p1 &lt; sphinx.5.0.yy.diff
</pre><p> If there's no .diff file exactly for the specific version
            you need to build, try applying .diff with closest version
            numbers. It is important that the patch should apply with no
            rejects.</p></li>
<li class="listitem"><p>in MySQL sources directory, run </p><pre class="programlisting">sh BUILD/autorun.sh
</pre></li>
<li class="listitem"><p>in MySQL sources directory, create
            <code class="filename">sql/sphinx</code> directory in and copy all files in
            <code class="filename">mysqlse</code> directory from Sphinx sources there.
            Example: </p><pre class="programlisting">cp -R /root/builds/sphinx-0.9.7/mysqlse /root/builds/mysql-5.0.24/sql/sphinx
</pre></li>
<li class="listitem"><p>configure MySQL and enable Sphinx engine: </p><pre class="programlisting">./configure --with-sphinx-storage-engine
</pre></li>
<li class="listitem"><p>build and install MySQL: </p><pre class="programlisting">make
make install
</pre></li>
</ol></div></div>
<div class="sect2" title="9.2.2.&nbsp;Compiling MySQL 5.1.x with SphinxSE"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-mysql51"></a>9.2.2.&nbsp;Compiling MySQL 5.1.x with SphinxSE</h3></div></div></div>
<p>Skip steps 1-2 if using already prepared delta tarball.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>in MySQL sources directory, create
            <code class="filename">storage/sphinx</code> directory in and copy all
            files in <code class="filename">mysqlse</code> directory from Sphinx
            sources there. Example: </p><pre class="programlisting">cp -R /root/builds/sphinx-0.9.7/mysqlse /root/builds/mysql-5.1.14/storage/sphinx
</pre></li>
<li class="listitem"><p>in MySQL sources directory, run </p><pre class="programlisting">sh BUILD/autorun.sh
</pre></li>
<li class="listitem"><p>configure MySQL and enable Sphinx engine: </p><pre class="programlisting">./configure --with-plugins=sphinx
</pre></li>
<li class="listitem"><p>build and install MySQL: </p><pre class="programlisting">make
make install
</pre></li>
</ol></div></div>
<div class="sect2" title="9.2.3.&nbsp;Checking SphinxSE installation"><div class="titlepage"><div><div><h3 class="title"><a name="sphinxse-checking"></a>9.2.3.&nbsp;Checking SphinxSE installation</h3></div></div></div>
<p>To check whether SphinxSE has been succesfully compiled into
        MySQL, launch newly built servers, run mysql client and issue
        <code class="code">SHOW ENGINES</code> query. You should see a list of all
        available engines. Sphinx should be present and "Support" column
        should contain "YES":</p><pre class="programlisting">mysql&gt; show engines;
+------------+----------+-------------------------------------------------------------+
| Engine     | Support  | Comment                                                     |
+------------+----------+-------------------------------------------------------------+
| MyISAM     | DEFAULT  | Default engine as of MySQL 3.23 with great performance      |
  ...
| SPHINX     | YES      | Sphinx storage engine                                       |
  ...
+------------+----------+-------------------------------------------------------------+
13 rows in set (0.00 sec)
</pre></div></div>
<div class="sect1" title="9.3.&nbsp;Using SphinxSE"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxse-using"></a>9.3.&nbsp;Using SphinxSE</h2></div></div></div>
<p>To search via SphinxSE, you would need to create special
      ENGINE=SPHINX "search table", and then SELECT from it with full text
      query put into WHERE clause for query column.</p><p>Let's begin with an example create statement and search query:
      </p><pre class="programlisting">CREATE TABLE t1
(
    id          INTEGER UNSIGNED NOT NULL,
    weight      INTEGER NOT NULL,
    query       VARCHAR(3072) NOT NULL,
    group_id    INTEGER,
    INDEX(query)
) ENGINE=SPHINX CONNECTION="sphinx://localhost:9312/test";

SELECT * FROM t1 WHERE query='test it;mode=any';
</pre><p>First 3 columns of search table <span class="emphasis"><em>must</em></span> have a
      types of <code class="code">INTEGER UNSINGED</code> or <code class="code">BIGINT</code> for the
      1st column (document id), <code class="code">INTEGER</code> or <code class="code">BIGINT</code>
      for the 2nd column (match weight), and <code class="code">VARCHAR</code> or
      <code class="code">TEXT</code> for the 3rd column (your query), respectively. This
      mapping is fixed; you can not omit any of these three required columns,
      or move them around, or change types. Also, query column must be
      indexed; all the others must be kept unindexed. Columns' names are
      ignored so you can use arbitrary ones.</p><p>Additional columns must be either <code class="code">INTEGER</code>,
      <code class="code">TIMESTAMP</code>, <code class="code">BIGINT</code>, <code class="code">VARCHAR</code>, or
      <code class="code">FLOAT</code>. They will be bound to attributes provided in Sphinx
      result set by name, so their names must match attribute names specified
      in <code class="filename">sphinx.conf</code>. If there's no such attribute name
      in Sphinx search results, column will have <code class="code">NULL</code>
      values.</p><p>Special "virtual" attributes names can also be bound to SphinxSE
      columns. <code class="code">_sph_</code> needs to be used instead of <code class="code">@</code>
      for that. For instance, to obtain the values of <code class="code">@groupby</code>,
      <code class="code">@count</code>, or <code class="code">@distinct</code> virtual attributes, use
      <code class="code">_sph_groupby</code>, <code class="code">_sph_count</code> or
      <code class="code">_sph_distinct</code> column names, respectively.</p><p><code class="code">CONNECTION</code> string parameter can be used to specify
      default searchd host, port and indexes for queries issued using this
      table. If no connection string is specified in <code class="code">CREATE
      TABLE</code>, index name "*" (ie. search all indexes) and localhost:9312
      are assumed. Connection string syntax is as follows: </p><pre class="programlisting">CONNECTION="sphinx://HOST:PORT/INDEXNAME"
</pre><p> You can change the default connection string later:
      </p><pre class="programlisting">ALTER TABLE t1 CONNECTION="sphinx://NEWHOST:NEWPORT/NEWINDEXNAME";
</pre><p> You can also override all these parameters per-query.</p><p>As seen in example, both query text and search options should be
      put into WHERE clause on search query column (ie. 3rd column); the
      options are separated by semicolons; and their names from values by
      equality sign. Any number of options can be specified. Available options
      are: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>query - query text;</p></li>
<li class="listitem"><p>mode - matching mode. Must be one of "all", "any", "phrase",
            "boolean", "extended", or "extended2". Default is "all";</p></li>
<li class="listitem"><p>sort - match sorting mode. Must be one of "relevance",
            "attr_desc", "attr_asc", "time_segments", or "extended". In all
            modes besides "relevance" attribute name (or sorting clause for
            "extended") is also required after a colon: </p><pre class="programlisting">... WHERE query='test;sort=attr_asc:group_id';
... WHERE query='test;sort=extended:@weight desc, group_id asc';
</pre></li>
<li class="listitem"><p>offset - offset into result set, default is 0;</p></li>
<li class="listitem"><p>limit - amount of matches to retrieve from result set,
            default is 20;</p></li>
<li class="listitem"><p>index - names of the indexes to search: </p><pre class="programlisting">... WHERE query='test;index=test1;';
... WHERE query='test;index=test1,test2,test3;';
</pre></li>
<li class="listitem"><p>minid, maxid - min and max document ID to match;</p></li>
<li class="listitem"><p>weights - comma-separated list of weights to be assigned to
            Sphinx full-text fields: </p><pre class="programlisting">... WHERE query='test;weights=1,2,3;';
</pre></li>
<li class="listitem"><p>filter, !filter - comma-separated attribute name and a set
            of values to match: </p><pre class="programlisting"># only include groups 1, 5 and 19
... WHERE query='test;filter=group_id,1,5,19;';

# exclude groups 3 and 11
... WHERE query='test;!filter=group_id,3,11;';
</pre></li>
<li class="listitem"><p>range, !range - comma-separated attribute name, min and max
            value to match: </p><pre class="programlisting"># include groups from 3 to 7, inclusive
... WHERE query='test;range=group_id,3,7;';

# exclude groups from 5 to 25
... WHERE query='test;!range=group_id,5,25;';
</pre></li>
<li class="listitem"><p>maxmatches - per-query max matches value, as in max_matches
            parameter to <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a>
            API call: </p><pre class="programlisting">... WHERE query='test;maxmatches=2000;';
</pre></li>
<li class="listitem"><p>cutoff - maximum allowed matches, as in cutoff parameter to
            <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a> API call:
            </p><pre class="programlisting">... WHERE query='test;cutoff=10000;';
</pre></li>
<li class="listitem"><p>maxquerytme - maximum allowed query time (in milliseconds),
            as in <a class="link" href="#api-func-setmaxquerytime" title="8.2.2.&nbsp;SetMaxQueryTime">SetMaxQueryTime()</a> API
            call: </p><pre class="programlisting">... WHERE query='test;maxquerytime=1000;';
</pre></li>
<li class="listitem"><p>groupby - group-by function and attribute, corresponding to
            <a class="link" href="#api-func-setgroupby" title="8.5.1.&nbsp;SetGroupBy">SetGroupBy()</a> API call:
            </p><pre class="programlisting">... WHERE query='test;groupby=day:published_ts;';
... WHERE query='test;groupby=attr:group_id;';
</pre></li>
<li class="listitem"><p>groupsort - group-by sorting clause: </p><pre class="programlisting">... WHERE query='test;groupsort=@count desc;';
</pre></li>
<li class="listitem"><p>distinct - an attribute to compute COUNT(DISTINCT) for when
            doing group-by, as in <a class="link" href="#api-func-setgroupdistinct" title="8.5.2.&nbsp;SetGroupDistinct">SetGroupDistinct()</a> API
            call: </p><pre class="programlisting">... WHERE query='test;groupby=attr:country_id;distinct=site_id';
</pre></li>
<li class="listitem"><p>indexweights - comma-separated list of index names and
            weights to use when searching through several indexes:
            </p><pre class="programlisting">... WHERE query='test;indexweights=idx_exact,2,idx_stemmed,1;';
</pre></li>
<li class="listitem"><p>comment - a string to mark this query in query log (mapping
            to $comment parameter in <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query">Query()</a> API call):
            </p><pre class="programlisting">... WHERE query='test;comment=marker001;';
</pre></li>
<li class="listitem"><p>select - a string with expressions to compute (mapping to
            <a class="link" href="#api-func-setselect" title="8.2.4.&nbsp;SetSelect">SetSelect()</a> API call):
            </p><pre class="programlisting">... WHERE query='test;select=2*a+3*b as myexpr;';
</pre></li>
<li class="listitem"><p>host, port - remote <code class="filename">searchd</code> host name
            and TCP port, respectively: </p><pre class="programlisting">... WHERE query='test;host=sphinx-test.loc;port=7312;';
</pre></li>
<li class="listitem"><p>ranker - a ranking function to use when matching mode is
            extended2 (i.e. with query syntax), as in <a class="link" href="#api-func-setrankingmode" title="8.3.2.&nbsp;SetRankingMode">SetRankingMode()</a> API
            call. Known values are "proximity_bm25", "bm25", "none",
            "wordcount", "proximity", "matchany", and "fieldmask".
            </p><pre class="programlisting">... WHERE query='test;mode=extended2;ranker=bm25;';
</pre></li>
<li class="listitem"><p>geoanchor - geodistance anchor, as in <a class="link" href="#api-func-setgeoanchor" title="8.4.5.&nbsp;SetGeoAnchor">SetGeoAnchor()</a> API call.
            Takes 4 parameters which are latitude and longiture attribute
            names, and anchor point coordinates respectively: </p><pre class="programlisting">... WHERE query='test;geoanchor=latattr,lonattr,0.123,0.456';
</pre></li>
</ul></div>
<p>One <span class="bold"><strong>very important</strong></span> note that it
      is <span class="bold"><strong>much</strong></span> more efficient to allow Sphinx
      to perform sorting, filtering and slicing the result set than to raise
      max matches count and use WHERE, ORDER BY and LIMIT clauses on MySQL
      side. This is for two reasons. First, Sphinx does a number of
      optimizations and performs better than MySQL on these tasks. Second,
      less data would need to be packed by searchd, transferred and unpacked
      by SphinxSE.</p><p>Starting with version 0.9.9-rc1, additional query info besides
      result set could be retrieved with <code class="code">SHOW ENGINE SPHINX
      STATUS</code> statement: </p><pre class="programlisting">mysql&gt; SHOW ENGINE SPHINX STATUS;
+--------+-------+-------------------------------------------------+
| Type   | Name  | Status                                          |
+--------+-------+-------------------------------------------------+
| SPHINX | stats | total: 25, total found: 25, time: 126, words: 2 | 
| SPHINX | words | sphinx:591:1256 soft:11076:15945                | 
+--------+-------+-------------------------------------------------+
2 rows in set (0.00 sec)
</pre><p> This information can also be accessed through status
      variables. Note that this method does not require super-user privileges.
      </p><pre class="programlisting">mysql&gt; SHOW STATUS LIKE 'sphinx_%';
+--------------------+----------------------------------+
| Variable_name      | Value                            |
+--------------------+----------------------------------+
| sphinx_total       | 25                               | 
| sphinx_total_found | 25                               | 
| sphinx_time        | 126                              | 
| sphinx_word_count  | 2                                | 
| sphinx_words       | sphinx:591:1256 soft:11076:15945 | 
+--------------------+----------------------------------+
5 rows in set (0.00 sec)
</pre><p>You could perform JOINs on SphinxSE search table and tables using
      other engines. Here's an example with "documents" from example.sql:
      </p><pre class="programlisting">mysql&gt; SELECT content, date_added FROM test.documents docs
-&gt; JOIN t1 ON (docs.id=t1.id) 
-&gt; WHERE query="one document;mode=any";
+-------------------------------------+---------------------+
| content                             | docdate             |
+-------------------------------------+---------------------+
| this is my test document number two | 2006-06-17 14:04:28 | 
| this is my test document number one | 2006-06-17 14:04:28 | 
+-------------------------------------+---------------------+
2 rows in set (0.00 sec)

mysql&gt; SHOW ENGINE SPHINX STATUS;
+--------+-------+---------------------------------------------+
| Type   | Name  | Status                                      |
+--------+-------+---------------------------------------------+
| SPHINX | stats | total: 2, total found: 2, time: 0, words: 2 | 
| SPHINX | words | one:1:2 document:2:2                        | 
+--------+-------+---------------------------------------------+
2 rows in set (0.00 sec)
</pre></div>
<div class="sect1" title="9.4.&nbsp;Building snippets (excerpts) via MySQL"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sphinxse-snippets"></a>9.4.&nbsp;Building snippets (excerpts) via MySQL</h2></div></div></div>
<p>Starting with version 0.9.9-rc2, SphinxSE also includes a UDF
      function that lets you create snippets through MySQL. The functionality
      is fully similar to <a class="link" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">BuildExcerprts</a> API call but
      accesible through MySQL+SphinxSE.</p><p>The binary that provides the UDF is named
      <code class="filename">sphinx.so</code> and should be automatically built and
      installed to proper location along with SphinxSE itself. If it does not
      get installed automatically for some reason, look for
      <code class="filename">sphinx.so</code> in the build directory and copy it to the
      plugins directory of your MySQL instance. After that, register the UDF
      using the following statement: </p><pre class="programlisting">CREATE FUNCTION sphinx_snippets RETURNS STRING SONAME 'sphinx.so';
</pre><p>Function name <span class="emphasis"><em>must</em></span> be sphinx_snippets, you
      can not use an arbitrary name. Function arguments are as follows:</p><p><span class="bold"><strong>Prototype:</strong></span> function sphinx_snippets ( document, index,
      words, [options] );</p><p>Document and words arguments can be either strings or table
      columns. Options must be specified like this: <code class="code">'value' AS
      option_name</code>. For a list of supported options, refer to <a class="link" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">BuildExcerprts()</a> API call. The
      only UDF-specific additional option is named <code class="code">'sphinx'</code> and
      lets you specify searchd location (host and port).</p><p>Usage examples: </p><pre class="programlisting">SELECT sphinx_snippets('hello world doc', 'main', 'world',
    'sphinx://192.168.1.1/' AS sphinx, true AS exact_phrase,
    '[b]' AS before_match, '[/b]' AS after_match)
FROM documents;

SELECT title, sphinx_snippets(text, 'index', 'mysql php') AS text
    FROM sphinx, documents
    WHERE query='mysql php' AND sphinx.id=documents.id;
</pre></div></div>
<div class="chapter" title="Chapter&nbsp;10.&nbsp;Reporting bugs"><div class="titlepage"><div><div><h2 class="title"><a name="reporting-bugs"></a>Chapter&nbsp;10.&nbsp;Reporting bugs</h2></div></div></div>
<p>Unfortunately, Sphinx is not yet 100% bug free (even though I'm
    working hard towards that), so you might occasionally run into some
    issues.</p><p>Reporting as much as possible about each bug is very important -
    because to fix it, I need to be able either to reproduce and debug the
    bug, or to deduce what's causing it from the information that you provide.
    So here are some instructions on how to do that.</p><h2>Build-time issues</h2><p>If Sphinx fails to build for some reason, please do the
    following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>check that headers and libraries for your DBMS are properly
        installed (for instance, check that <code class="filename">mysql-devel</code>
        package is present);</p></li>
<li class="listitem"><p>report Sphinx version and config file (be sure to remove the
        passwords!), MySQL (or PostgreSQL) configuration info, gcc version, OS
        version and CPU type (ie. x86, x86-64, PowerPC, etc): </p><pre class="programlisting">mysql_config
gcc --version
uname -a
</pre></li>
<li class="listitem"><p>report the error message which is produced by
        <code class="filename">configure</code> or <code class="filename">gcc</code> (it should
        be to include error message itself only, not the whole build
        log).</p></li>
</ol></div>
<h2>Run-time issues</h2><p>If Sphinx builds and runs, but there are any problems running it,
    please do the following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>describe the bug (ie. both the expected behavior and actual
        behavior) and all the steps necessary to reproduce it;</p></li>
<li class="listitem"><p>include Sphinx version and config file (be sure to remove the
        passwords!), MySQL (or PostgreSQL) version, gcc version, OS version
        and CPU type (ie. x86, x86-64, PowerPC, etc): </p><pre class="programlisting">mysql --version
gcc --version
uname -a
</pre></li>
<li class="listitem"><p>build, install and run debug versions of all Sphinx programs
        (this is to enable a lot of additional internal checks, so-called
        assertions): </p><pre class="programlisting">make distclean
./configure --with-debug
make install
killall -TERM searchd
</pre></li>
<li class="listitem"><p>reindex to check if any assertions are triggered (in this case,
        it's likely that the index is corrupted and causing problems);</p></li>
<li class="listitem"><p>if the bug does not reproduce with debug versions, revert to
        non-debug and mention it in your report;</p></li>
<li class="listitem"><p>if the bug could be easily reproduced with a small (1-100
        record) part of your database, please provide a gzipped dump of that
        part;</p></li>
<li class="listitem"><p>if the problem is related to <code class="filename">searchd</code>,
        include relevant entries from <code class="filename">searchd.log</code> and
        <code class="filename">query.log</code> in your bug report;</p></li>
<li class="listitem"><p>if the problem is related to <code class="filename">searchd</code>, try
        running it in console mode and check if it dies with an assertion:
        </p><pre class="programlisting">./searchd --console
</pre></li>
<li class="listitem"><p>if any program dies with an assertion, provide the assertion
        message.</p></li>
</ol></div>
<h2>Debugging assertions, crashes and hangups</h2><p>If any program dies with an assertion, crashes without an assertion
    or hangs up, you would additionally need to generate a core dump and
    examine it.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>enable core dumps. On most Linux systems, this is done using
        <code class="filename">ulimit</code>: </p><pre class="programlisting">ulimit -c 32768
</pre></li>
<li class="listitem"><p>run the program and try to reproduce the bug;</p></li>
<li class="listitem"><p>if the program crashes (either with or without an assertion),
        find the core file in current directory (it should typically print out
        "Segmentation fault (core dumped)" message);</p></li>
<li class="listitem"><p>if the program hangs, use <code class="filename">kill -SEGV</code> from
        another console to force it to exit and dump core: </p><pre class="programlisting">kill -SEGV HANGED-PROCESS-ID
</pre></li>
<li class="listitem"><p>use <code class="filename">gdb</code> to examine the core file and obtain
        a backtrace: </p><pre class="programlisting">gdb ./CRASHED-PROGRAM-FILE-NAME CORE-DUMP-FILE-NAME
(gdb) bt
(gdb) quit
</pre></li>
</ol></div>
<p>Note that HANGED-PROCESS-ID, CRASHED-PROGRAM-FILE-NAME and
    CORE-DUMP-FILE-NAME must all be replaced with specific numbers and file
    names. For example, hanged searchd debugging session would look like:
    </p><pre class="programlisting"># kill -SEGV 12345
# ls *core*
core.12345
# gdb ./searchd core.12345
(gdb) bt
...
(gdb) quit
</pre><p>Note that <code class="filename">ulimit</code> is not server-wide and only
    affects current shell session. This means that you will not have to
    restore any server-wide limits - but if you relogin, you will have to set
    <code class="filename">ulimit</code> again.</p><p>Core dumps should be placed in current working directory (and Sphinx
    programs do not change it), so this is where you would look for
    them.</p><p>Please do not immediately remove the core file because there could
    be additional helpful information which could be retrieved from it. You do
    not need to send me this file (as the debug info there is closely tied to
    your system) but I might need to ask you a few additional questions about
    it.</p></div>
<div class="chapter" title="Chapter&nbsp;11.&nbsp;sphinx.conf options reference"><div class="titlepage"><div><div><h2 class="title"><a name="conf-reference"></a>Chapter&nbsp;11.&nbsp;<code class="filename">sphinx.conf</code> options reference</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#confgroup-source">11.1. Data source configuration options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-source-type">11.1.1. type</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-host">11.1.2. sql_host</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-port">11.1.3. sql_port</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-user">11.1.4. sql_user</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-pass">11.1.5. sql_pass</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-db">11.1.6. sql_db</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-sock">11.1.7. sql_sock</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-connect-flags">11.1.8. mysql_connect_flags</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-ssl">11.1.9. mysql_ssl_cert, mysql_ssl_key, mysql_ssl_ca</a></span></dt>
<dt><span class="sect2"><a href="#conf-odbc-dsn">11.1.10. odbc_dsn</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-pre">11.1.11. sql_query_pre</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query">11.1.12. sql_query</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-joined-field">11.1.13. sql_joined_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-range">11.1.14. sql_query_range</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-range-step">11.1.15. sql_range_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-killlist">11.1.16. sql_query_killlist</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-uint">11.1.17. sql_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-bool">11.1.18. sql_attr_bool</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-bigint">11.1.19. sql_attr_bigint</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-timestamp">11.1.20. sql_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-str2ordinal">11.1.21. sql_attr_str2ordinal</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-float">11.1.22. sql_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-multi">11.1.23. sql_attr_multi</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-string">11.1.24. sql_attr_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-attr-str2wordcount">11.1.25. sql_attr_str2wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-column-buffers">11.1.26. sql_column_buffers</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-field-string">11.1.27. sql_field_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-field-str2wordcount">11.1.28. sql_field_str2wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-file-field">11.1.29. sql_file_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-post">11.1.30. sql_query_post</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-post-index">11.1.31. sql_query_post_index</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-ranged-throttle">11.1.32. sql_ranged_throttle</a></span></dt>
<dt><span class="sect2"><a href="#conf-sql-query-info">11.1.33. sql_query_info</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-command">11.1.34. xmlpipe_command</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field">11.1.35. xmlpipe_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field-string">11.1.36. xmlpipe_field_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-field-wordcount">11.1.37. xmlpipe_field_wordcount</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-uint">11.1.38. xmlpipe_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-bool">11.1.39. xmlpipe_attr_bool</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-timestamp">11.1.40. xmlpipe_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-str2ordinal">11.1.41. xmlpipe_attr_str2ordinal</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-float">11.1.42. xmlpipe_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-multi">11.1.43. xmlpipe_attr_multi</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-attr-string">11.1.44. xmlpipe_attr_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-xmlpipe-fixup-utf8">11.1.45. xmlpipe_fixup_utf8</a></span></dt>
<dt><span class="sect2"><a href="#conf-mssql-winauth">11.1.46. mssql_winauth</a></span></dt>
<dt><span class="sect2"><a href="#conf-mssql-unicode">11.1.47. mssql_unicode</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-zlib">11.1.48. unpack_zlib</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-mysqlcompress">11.1.49. unpack_mysqlcompress</a></span></dt>
<dt><span class="sect2"><a href="#conf-unpack-mysqlcompress-maxsize">11.1.50. unpack_mysqlcompress_maxsize</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-index">11.2. Index configuration options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-index-type">11.2.1. type</a></span></dt>
<dt><span class="sect2"><a href="#conf-source">11.2.2. source</a></span></dt>
<dt><span class="sect2"><a href="#conf-path">11.2.3. path</a></span></dt>
<dt><span class="sect2"><a href="#conf-docinfo">11.2.4. docinfo</a></span></dt>
<dt><span class="sect2"><a href="#conf-mlock">11.2.5. mlock</a></span></dt>
<dt><span class="sect2"><a href="#conf-morphology">11.2.6. morphology</a></span></dt>
<dt><span class="sect2"><a href="#conf-dict">11.2.7. dict</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-sp">11.2.8. index_sp</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-zones">11.2.9. index_zones</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-stemming-len">11.2.10. min_stemming_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-stopwords">11.2.11. stopwords</a></span></dt>
<dt><span class="sect2"><a href="#conf-wordforms">11.2.12. wordforms</a></span></dt>
<dt><span class="sect2"><a href="#conf-exceptions">11.2.13. exceptions</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-word-len">11.2.14. min_word_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-charset-type">11.2.15. charset_type</a></span></dt>
<dt><span class="sect2"><a href="#conf-charset-table">11.2.16. charset_table</a></span></dt>
<dt><span class="sect2"><a href="#conf-ignore-chars">11.2.17. ignore_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-prefix-len">11.2.18. min_prefix_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-min-infix-len">11.2.19. min_infix_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-prefix-fields">11.2.20. prefix_fields</a></span></dt>
<dt><span class="sect2"><a href="#conf-infix-fields">11.2.21. infix_fields</a></span></dt>
<dt><span class="sect2"><a href="#conf-enable-star">11.2.22. enable_star</a></span></dt>
<dt><span class="sect2"><a href="#conf-ngram-len">11.2.23. ngram_len</a></span></dt>
<dt><span class="sect2"><a href="#conf-ngram-chars">11.2.24. ngram_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-phrase-boundary">11.2.25. phrase_boundary</a></span></dt>
<dt><span class="sect2"><a href="#conf-phrase-boundary-step">11.2.26. phrase_boundary_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-strip">11.2.27. html_strip</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-index-attrs">11.2.28. html_index_attrs</a></span></dt>
<dt><span class="sect2"><a href="#conf-html-remove-elements">11.2.29. html_remove_elements</a></span></dt>
<dt><span class="sect2"><a href="#conf-local">11.2.30. local</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent">11.2.31. agent</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-blackhole">11.2.32. agent_blackhole</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-connect-timeout">11.2.33. agent_connect_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-agent-query-timeout">11.2.34. agent_query_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-preopen">11.2.35. preopen</a></span></dt>
<dt><span class="sect2"><a href="#conf-ondisk-dict">11.2.36. ondisk_dict</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-enable">11.2.37. inplace_enable</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-hit-gap">11.2.38. inplace_hit_gap</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-docinfo-gap">11.2.39. inplace_docinfo_gap</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-reloc-factor">11.2.40. inplace_reloc_factor</a></span></dt>
<dt><span class="sect2"><a href="#conf-inplace-write-factor">11.2.41. inplace_write_factor</a></span></dt>
<dt><span class="sect2"><a href="#conf-index-exact-words">11.2.42. index_exact_words</a></span></dt>
<dt><span class="sect2"><a href="#conf-overshort-step">11.2.43. overshort_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-stopword-step">11.2.44. stopword_step</a></span></dt>
<dt><span class="sect2"><a href="#conf-hitless-words">11.2.45. hitless_words</a></span></dt>
<dt><span class="sect2"><a href="#conf-expand-keywords">11.2.46. expand_keywords</a></span></dt>
<dt><span class="sect2"><a href="#conf-blend-chars">11.2.47. blend_chars</a></span></dt>
<dt><span class="sect2"><a href="#conf-blend-mode">11.2.48. blend_mode</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-mem-limit">11.2.49. rt_mem_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-field">11.2.50. rt_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-uint">11.2.51. rt_attr_uint</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-bigint">11.2.52. rt_attr_bigint</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-float">11.2.53. rt_attr_float</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-timestamp">11.2.54. rt_attr_timestamp</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-attr-string">11.2.55. rt_attr_string</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-indexer">11.3. <code class="filename">indexer</code> program configuration
      options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-mem-limit">11.3.1. mem_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-iops">11.3.2. max_iops</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-iosize">11.3.3. max_iosize</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-xmlpipe2-field">11.3.4. max_xmlpipe2_field</a></span></dt>
<dt><span class="sect2"><a href="#conf-write-buffer">11.3.5. write_buffer</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-file-field-buffer">11.3.6. max_file_field_buffer</a></span></dt>
</dl></dd><dt><span class="sect1"><a href="#confgroup-searchd">11.4. <code class="filename">searchd</code> program configuration
      options</a></span></dt>
<dd><dl><dt><span class="sect2"><a href="#conf-listen">11.4.1. listen</a></span></dt>
<dt><span class="sect2"><a href="#conf-address">11.4.2. address</a></span></dt>
<dt><span class="sect2"><a href="#conf-port">11.4.3. port</a></span></dt>
<dt><span class="sect2"><a href="#conf-log">11.4.4. log</a></span></dt>
<dt><span class="sect2"><a href="#conf-query-log">11.4.5. query_log</a></span></dt>
<dt><span class="sect2"><a href="#conf-query-log-format">11.4.6. query_log_format</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-timeout">11.4.7. read_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-client-timeout">11.4.8. client_timeout</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-children">11.4.9. max_children</a></span></dt>
<dt><span class="sect2"><a href="#conf-pid-file">11.4.10. pid_file</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-matches">11.4.11. max_matches</a></span></dt>
<dt><span class="sect2"><a href="#conf-seamless-rotate">11.4.12. seamless_rotate</a></span></dt>
<dt><span class="sect2"><a href="#conf-preopen-indexes">11.4.13. preopen_indexes</a></span></dt>
<dt><span class="sect2"><a href="#conf-unlink-old">11.4.14. unlink_old</a></span></dt>
<dt><span class="sect2"><a href="#conf-attr-flush-period">11.4.15. attr_flush_period</a></span></dt>
<dt><span class="sect2"><a href="#conf-ondisk-dict-default">11.4.16. ondisk_dict_default</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-packet-size">11.4.17. max_packet_size</a></span></dt>
<dt><span class="sect2"><a href="#conf-mva-updates-pool">11.4.18. mva_updates_pool</a></span></dt>
<dt><span class="sect2"><a href="#conf-crash-log-path">11.4.19. crash_log_path</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-filters">11.4.20. max_filters</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-filter-values">11.4.21. max_filter_values</a></span></dt>
<dt><span class="sect2"><a href="#conf-listen-backlog">11.4.22. listen_backlog</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-buffer">11.4.23. read_buffer</a></span></dt>
<dt><span class="sect2"><a href="#conf-read-unhinted">11.4.24. read_unhinted</a></span></dt>
<dt><span class="sect2"><a href="#conf-max-batch-queries">11.4.25. max_batch_queries</a></span></dt>
<dt><span class="sect2"><a href="#conf-subtree-docs-cache">11.4.26. subtree_docs_cache</a></span></dt>
<dt><span class="sect2"><a href="#conf-subtree-hits-cache">11.4.27. subtree_hits_cache</a></span></dt>
<dt><span class="sect2"><a href="#conf-workers">11.4.28. workers</a></span></dt>
<dt><span class="sect2"><a href="#conf-dist-threads">11.4.29. dist_threads</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-path">11.4.30. binlog_path</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-flush">11.4.31. binlog_flush</a></span></dt>
<dt><span class="sect2"><a href="#conf-binlog-max-log-size">11.4.32. binlog_max_log_size</a></span></dt>
<dt><span class="sect2"><a href="#conf-collation-server">11.4.33. collation_server</a></span></dt>
<dt><span class="sect2"><a href="#conf-collation-libc-locale">11.4.34. collation_libc_locale</a></span></dt>
<dt><span class="sect2"><a href="#conf-plugin-dir">11.4.35. plugin_dir</a></span></dt>
<dt><span class="sect2"><a href="#conf-mysql-version-string">11.4.36. mysql_version_string</a></span></dt>
<dt><span class="sect2"><a href="#conf-rt-flush-period">11.4.37. rt_flush_period</a></span></dt>
<dt><span class="sect2"><a href="#conf-thread-stack">11.4.38. thread_stack</a></span></dt>
<dt><span class="sect2"><a href="#conf-expansion-limit">11.4.39. expansion_limit</a></span></dt>
<dt><span class="sect2"><a href="#conf-compat-sphinxql-magics">11.4.40. compat_sphinxql_magics</a></span></dt>
<dt><span class="sect2"><a href="#conf-watchdog">11.4.41. watchdog</a></span></dt>
</dl></dd></dl></div>
<div class="sect1" title="11.1.&nbsp;Data source configuration options"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="confgroup-source"></a>11.1.&nbsp;Data source configuration options</h2></div></div></div>
<div class="sect2" title="11.1.1.&nbsp;type"><div class="titlepage"><div><div><h3 class="title"><a name="conf-source-type"></a>11.1.1.&nbsp;type</h3></div></div></div>
<p>Data source type. Mandatory, no default value. Known types are
        <code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>, <code class="option">xmlpipe</code> and
        <code class="option">xmlpipe2</code>, and <code class="option">odbc</code>.</p><p>All other per-source options depend on source type selected by
        this option. Names of the options used for SQL sources (ie. MySQL,
        PostgreSQL, MS SQL) start with "sql_"; names of the ones used for
        xmlpipe and xmlpipe2 start with "xmlpipe_". All source types except
        <code class="option">xmlpipe</code> are conditional; they might or might not be
        supported depending on your build settings, installed client
        libraries, etc. <code class="option">mssql</code> type is currently only
        available on Windows. <code class="option">odbc</code> type is available both on
        Windows natively and on Linux through <a class="ulink" href="http://www.unixodbc.org/" target="_top">UnixODBC library</a>.</p><h4>Example:</h4><pre class="programlisting">type = mysql
</pre></div>
<div class="sect2" title="11.1.2.&nbsp;sql_host"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-host"></a>11.1.2.&nbsp;sql_host</h3></div></div></div>
<p>SQL server host to connect to. Mandatory, no default value.
        Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only.</p><p>In the simplest case when Sphinx resides on the same host with
        your MySQL or PostgreSQL installation, you would simply specify
        "localhost". Note that MySQL client library chooses whether to connect
        over TCP/IP or over UNIX socket based on the host name. Specifically
        "localhost" will force it to use UNIX socket (this is the default and
        generally recommended mode) and "127.0.0.1" will force TCP/IP usage.
        Refer to <a class="ulink" href="http://dev.mysql.com/doc/refman/5.0/en/mysql-real-connect.html" target="_top">MySQL
        manual</a> for more details.</p><h4>Example:</h4><pre class="programlisting">sql_host = localhost
</pre></div>
<div class="sect2" title="11.1.3.&nbsp;sql_port"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-port"></a>11.1.3.&nbsp;sql_port</h3></div></div></div>
<p>SQL server IP port to connect to. Optional, default is 3306 for
        <code class="option">mysql</code> source type and 5432 for <code class="option">pgsql</code>
        type. Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only. Note that it
        depends on <a class="link" href="#conf-sql-host" title="11.1.2.&nbsp;sql_host">sql_host</a> setting
        whether this value will actually be used.</p><h4>Example:</h4><pre class="programlisting">sql_port = 3306
</pre></div>
<div class="sect2" title="11.1.4.&nbsp;sql_user"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-user"></a>11.1.4.&nbsp;sql_user</h3></div></div></div>
<p>SQL user to use when connecting to <a class="link" href="#conf-sql-host" title="11.1.2.&nbsp;sql_host">sql_host</a>. Mandatory, no default value.
        Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only.</p><h4>Example:</h4><pre class="programlisting">sql_user = test
</pre></div>
<div class="sect2" title="11.1.5.&nbsp;sql_pass"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-pass"></a>11.1.5.&nbsp;sql_pass</h3></div></div></div>
<p>SQL user password to use when connecting to <a class="link" href="#conf-sql-host" title="11.1.2.&nbsp;sql_host">sql_host</a>. Mandatory, no default value.
        Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only.</p><h4>Example:</h4><pre class="programlisting">sql_pass = mysecretpassword
</pre></div>
<div class="sect2" title="11.1.6.&nbsp;sql_db"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-db"></a>11.1.6.&nbsp;sql_db</h3></div></div></div>
<p>SQL database (in MySQL terms) to use after the connection and
        perform further queries within. Mandatory, no default value. Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><h4>Example:</h4><pre class="programlisting">sql_db = test
</pre></div>
<div class="sect2" title="11.1.7.&nbsp;sql_sock"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-sock"></a>11.1.7.&nbsp;sql_sock</h3></div></div></div>
<p>UNIX socket name to connect to for local SQL servers. Optional,
        default value is empty (use client library default settings). Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>On Linux, it would typically be
        <code class="filename">/var/lib/mysql/mysql.sock</code>. On FreeBSD, it would
        typically be <code class="filename">/tmp/mysql.sock</code>. Note that it
        depends on <a class="link" href="#conf-sql-host" title="11.1.2.&nbsp;sql_host">sql_host</a> setting
        whether this value will actually be used.</p><h4>Example:</h4><pre class="programlisting">sql_sock = /tmp/mysql.sock
</pre></div>
<div class="sect2" title="11.1.8.&nbsp;mysql_connect_flags"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mysql-connect-flags"></a>11.1.8.&nbsp;mysql_connect_flags</h3></div></div></div>
<p>MySQL client connection flags. Optional, default value is 0 (do
        not set any flags). Applies to <code class="option">mysql</code> source type
        only.</p><p>This option must contain an integer value with the sum of the
        flags. The value will be passed to <a class="ulink" href="http://dev.mysql.com/doc/refman/5.0/en/mysql-real-connect.html" target="_top">mysql_real_connect()</a>
        verbatim. The flags are enumerated in mysql_com.h include file. Flags
        that are especially interesting in regard to indexing, with their
        respective values, are as follows: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>CLIENT_COMPRESS = 32; can use compression protocol</p></li>
<li class="listitem"><p>CLIENT_SSL = 2048; switch to SSL after handshake</p></li>
<li class="listitem"><p>CLIENT_SECURE_CONNECTION = 32768; new 4.1
              authentication</p></li>
</ul></div>
<p> For instance, you can specify 2080 (2048+32) to use
        both compression and SSL, or 32768 to use new authentication only.
        Initially, this option was introduced to be able to use compression
        when the <code class="filename">indexer</code> and <code class="filename">mysqld</code>
        are on different hosts. Compression on 1 Gbps links is most likely to
        hurt indexing time though it reduces network traffic, both in theory
        and in practice. However, enabling compression on 100 Mbps links may
        improve indexing time significantly (upto 20-30% of the total indexing
        time improvement was reported). Your mileage may vary.</p><h4>Example:</h4><pre class="programlisting">mysql_connect_flags = 32 # enable compression
</pre></div>
<div class="sect2" title="11.1.9.&nbsp;mysql_ssl_cert, mysql_ssl_key, mysql_ssl_ca"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mysql-ssl"></a>11.1.9.&nbsp;mysql_ssl_cert, mysql_ssl_key, mysql_ssl_ca</h3></div></div></div>
<p>SSL certificate settings to use for connecting to MySQL server.
        Optional, default values are empty strings (do not use SSL). Applies
        to <code class="option">mysql</code> source type only.</p><p>These directives let you set up secure SSL connection between
        <code class="filename">indexer</code> and MySQL. The details on creating the
        certificates and setting up MySQL server can be found in MySQL
        documentation.</p><h4>Example:</h4><pre class="programlisting">mysql_ssl_cert = /etc/ssl/client-cert.pem
mysql_ssl_key = /etc/ssl/client-key.pem
mysql_ssl_ca = /etc/ssl/cacert.pem
</pre></div>
<div class="sect2" title="11.1.10.&nbsp;odbc_dsn"><div class="titlepage"><div><div><h3 class="title"><a name="conf-odbc-dsn"></a>11.1.10.&nbsp;odbc_dsn</h3></div></div></div>
<p>ODBC DSN to connect to. Mandatory, no default value. Applies to
        <code class="option">odbc</code> source type only.</p><p>ODBC DSN (Data Source Name) specifies the credentials (host,
        user, password, etc) to use when connecting to ODBC data source. The
        format depends on specific ODBC driver used.</p><h4>Example:</h4><pre class="programlisting">odbc_dsn = Driver={Oracle ODBC Driver};Dbq=myDBName;Uid=myUsername;Pwd=myPassword
</pre></div>
<div class="sect2" title="11.1.11.&nbsp;sql_query_pre"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-pre"></a>11.1.11.&nbsp;sql_query_pre</h3></div></div></div>
<p>Pre-fetch query, or pre-query. Multi-value, optional, default is
        empty list of queries. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Multi-value means that you can specify several pre-queries. They
        are executed before <a class="link" href="#conf-sql-query" title="11.1.12.&nbsp;sql_query">the main fetch
        query</a>, and they will be exectued exactly in order of
        appeareance in the configuration file. Pre-query results are
        ignored.</p><p>Pre-queries are useful in a lot of ways. They are used to setup
        encoding, mark records that are going to be indexed, update internal
        counters, set various per-connection SQL server options and variables,
        and so on.</p><p>Perhaps the most frequent pre-query usage is to specify the
        encoding that the server will use for the rows it returnes. It
        <span class="bold"><strong>must</strong></span> match the encoding that Sphinx expects (as specified by
        <a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a> and <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> options). Two MySQL
        specific examples of setting the encoding are: </p><pre class="programlisting">sql_query_pre = SET CHARACTER_SET_RESULTS=cp1251
sql_query_pre = SET NAMES utf8
</pre><p> Also specific to MySQL sources, it is useful to disable
        query cache (for indexer connection only) in pre-query, because
        indexing queries are not going to be re-run frequently anyway, and
        there's no sense in caching their results. That could be achieved
        with: </p><pre class="programlisting">sql_query_pre = SET SESSION query_cache_type=OFF
</pre><h4>Example:</h4><pre class="programlisting">sql_query_pre = SET NAMES utf8
sql_query_pre = SET SESSION query_cache_type=OFF
</pre></div>
<div class="sect2" title="11.1.12.&nbsp;sql_query"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query"></a>11.1.12.&nbsp;sql_query</h3></div></div></div>
<p>Main document fetch query. Mandatory, no default value. Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>There can be only one main query. This is the query which is
        used to retrieve documents from SQL server. You can specify up to 32
        full-text fields (formally, upto SPH_MAX_FIELDS from sphinx.h), and an
        arbitrary amount of attributes. All of the columns that are neither
        document ID (the first one) nor attributes will be full-text
        indexed.</p><p>Document ID <span class="bold"><strong>MUST</strong></span> be the very
        first field, and it <span class="bold"><strong>MUST BE UNIQUE UNSIGNED
        POSITIVE (NON-ZERO, NON-NEGATIVE) INTEGER NUMBER</strong></span>. It can be
        either 32-bit or 64-bit, depending on how you built Sphinx; by default
        it builds with 32-bit IDs support but <code class="option">--enable-id64</code>
        option to <code class="filename">configure</code> allows to build with 64-bit
        document and word IDs support. </p><h4>Example:</h4><pre class="programlisting">sql_query = \
	SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, \
		title, content \
	FROM documents
</pre></div>
<div class="sect2" title="11.1.13.&nbsp;sql_joined_field"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-joined-field"></a>11.1.13.&nbsp;sql_joined_field</h3></div></div></div>
<p>Joined/payload field fetch query. Multi-value, optional, default
        is empty list of queries. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p><code class="option">sql_joined_field</code> lets you use two different
        features: joined fields, and payloads (payload fields). It's syntax is
        as follows: </p><pre class="programlisting">sql_joined_field = FIELD-NAME 'from'  ( 'query' | 'payload-query' ); \
    QUERY [ ; RANGE-QUERY ]
</pre><p> where </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>FIELD-NAME is a joined/payload field name;</p></li>
<li class="listitem"><p>QUERY is an SQL query that must fetch values to
              index.</p></li>
<li class="listitem"><p>RANGE-QUERY is an optional SQL query that fetches a range
              of values to index. (Added in version 2.0.1-beta.)</p></li>
</ul></div>
<p><span class="bold"><strong>Joined fields</strong></span> let you avoid JOIN and/or GROUP_CONCAT
        statements in the main document fetch query (sql_query). This can be
        useful when SQL-side JOIN is slow, or needs to be offloaded on Sphinx
        side, or simply to emulate MySQL-specific GROUP_CONCAT funcionality in
        case your database server does not support it.</p><p>The query must return exactly 2 columns: document ID, and text
        to append to a joined field. Document IDs can be duplicate, but they
        <span class="bold"><strong>must</strong></span> be in ascending order. All the text rows fetched for a
        given ID will be concatented together, and the concatenation result
        will be indexed as the entire contents of a joined field. Rows will be
        concatenated in the order returned from the query, and separating
        whitespace will be inserted between them. For instance, if joined
        field query returns the following rows: </p><pre class="programlisting">( 1, 'red' )
( 1, 'right' )
( 1, 'hand' )
( 2, 'mysql' )
( 2, 'sphinx' )
</pre><p> then the indexing results would be equivalent to that of
        adding a new text field with a value of 'red right hand' to document 1
        and 'mysql sphinx' to document 2.</p><p>Joined fields are only indexed differently. There are no other
        differences between joined fields and regular text fields.</p><p>Starting with 2.0.1-beta, <span class="bold"><strong>ranged queries</strong></span> can be used when
        a single query is not efficient enough or does not work because of the
        database driver limitations. It works similar to the ranged queries in
        the main indexing loop, see <a class="xref" href="#ranged-queries" title="3.7.&nbsp;Ranged queries">Section&nbsp;3.7, “Ranged queries”</a>. The
        range will be queried for and fetched upfront once, then multiple
        queries with different <code class="code">$start</code> and <code class="code">$end</code>
        substitutions will be run to fetch the actual data.</p><p><span class="bold"><strong>Payloads</strong></span> let you create a special field in which, instead
        of keyword positions, so-called user payloads are stored. Payloads are
        custom integer values attached to every keyword. They can then be used
        in search time to affect the ranking.</p><p>The payload query must return exactly 3 columns: document ID;
        keyword; and integer payload value. Document IDs can be duplicate, but
        they <span class="bold"><strong>must</strong></span> be in ascending order. Payloads must be unsigned
        integers within 24-bit range, ie. from 0 to 16777215. For reference,
        payloads are currently internally stored as in-field keyword
        positions, but that is not guaranteed and might change in the
        future.</p><p>Currently, the only method to account for payloads is to use
        SPH_RANK_PROXIMITY_BM25 ranker. On indexes with payload fields, it
        will automatically switch to a variant that matches keywords in those
        fields, computes a sum of matched payloads multiplied by field
        wieghts, and adds that sum to the final rank.</p><h4>Example:</h4><pre class="programlisting">sql_joined_field = \
	tagstext from query; \
	SELECT docid, CONCAT('tag',tagid) FROM tags ORDER BY docid ASC
</pre></div>
<div class="sect2" title="11.1.14.&nbsp;sql_query_range"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-range"></a>11.1.14.&nbsp;sql_query_range</h3></div></div></div>
<p>Range query setup. Optional, default is empty. Applies to SQL
        source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Setting this option enables ranged document fetch queries (see
        <a class="xref" href="#ranged-queries" title="3.7.&nbsp;Ranged queries">Section&nbsp;3.7, “Ranged queries”</a>). Ranged queries are useful to avoid
        notorious MyISAM table locks when indexing lots of data. (They also
        help with other less notorious issues, such as reduced performance
        caused by big result sets, or additional resources consumed by InnoDB
        to serialize big read transactions.)</p><p>The query specified in this option must fetch min and max
        document IDs that will be used as range boundaries. It must return
        exactly two integer fields, min ID first and max ID second; the field
        names are ignored.</p><p>When ranged queries are enabled, <a class="link" href="#conf-sql-query" title="11.1.12.&nbsp;sql_query">sql_query</a> will be required to contain
        <code class="option">$start</code> and <code class="option">$end</code> macros (because it
        obviously would be a mistake to index the whole table many times
        over). Note that the intervals specified by
        <code class="option">$start</code>..<code class="option">$end</code> will not overlap, so
        you should <span class="bold"><strong>not</strong></span> remove document IDs that are exactly equal to
        <code class="option">$start</code> or <code class="option">$end</code> from your query. The
        example in <a class="xref" href="#ranged-queries" title="3.7.&nbsp;Ranged queries">Section&nbsp;3.7, “Ranged queries”</a>) illustrates that; note
        how it uses greater-or-equal and less-or-equal comparisons.</p><h4>Example:</h4><pre class="programlisting">sql_query_range = SELECT MIN(id),MAX(id) FROM documents
</pre></div>
<div class="sect2" title="11.1.15.&nbsp;sql_range_step"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-range-step"></a>11.1.15.&nbsp;sql_range_step</h3></div></div></div>
<p>Range query step. Optional, default is 1024. Applies to SQL
        source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Only used when <a class="link" href="#ranged-queries" title="3.7.&nbsp;Ranged queries">ranged
        queries</a> are enabled. The full document IDs interval fetched by
        <a class="link" href="#conf-sql-query-range" title="11.1.14.&nbsp;sql_query_range">sql_query_range</a> will be
        walked in this big steps. For example, if min and max IDs fetched are
        12 and 3456 respectively, and the step is 1000, indexer will call
        <a class="link" href="#conf-sql-query" title="11.1.12.&nbsp;sql_query">sql_query</a> several times with the
        following substitutions: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>$start=12, $end=1011</p></li>
<li class="listitem"><p>$start=1012, $end=2011</p></li>
<li class="listitem"><p>$start=2012, $end=3011</p></li>
<li class="listitem"><p>$start=3012, $end=3456</p></li>
</ul></div>
<h4>Example:</h4><pre class="programlisting">sql_range_step = 1000
</pre></div>
<div class="sect2" title="11.1.16.&nbsp;sql_query_killlist"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-killlist"></a>11.1.16.&nbsp;sql_query_killlist</h3></div></div></div>
<p>Kill-list query. Optional, default is empty (no query). Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 0.9.9-rc1.</p><p>This query is expected to return a number of 1-column rows, each
        containing just the document ID. The returned document IDs are stored
        within an index. Kill-list for a given index suppresses results from
        <span class="emphasis"><em>other</em></span> indexes, depending on index order in the
        query. The intended use is to help implement deletions and updates on
        existing indexes without rebuilding (actually even touching them), and
        especially to fight phantom results problem.</p><p>Let us dissect an example. Assume we have two indexes, 'main'
        and 'delta'. Assume that documents 2, 3, and 5 were deleted since last
        reindex of 'main', and documents 7 and 11 were updated (ie. their text
        contents were changed). Assume that a keyword 'test' occurred in all
        these mentioned documents when we were indexing 'main'; still occurs
        in document 7 as we index 'delta'; but does not occur in document 11
        any more. We now reindex delta and then search through both these
        indexes in proper (least to most recent) order: </p><pre class="programlisting">$res = $cl-&gt;Query ( "test", "main delta" );
</pre><p>First, we need to properly handle deletions. The result set
        should not contain documents 2, 3, or 5. Second, we also need to avoid
        phantom results. Unless we do something about it, document 11
        <span class="emphasis"><em>will</em></span> appear in search results! It will be found
        in 'main' (but not 'delta'). And it will make it to the final result
        set unless something stops it.</p><p>Kill-list, or K-list for short, is that something. Kill-list
        attached to 'delta' will suppress the specified rows from <span class="bold"><strong>all</strong></span>
        the preceding indexes, in this case just 'main'. So to get the
        expected results, we should put all the updated
        <span class="emphasis"><em>and</em></span> deleted document IDs into it.</p><h4>Example:</h4><pre class="programlisting">sql_query_killlist = \
	SELECT id FROM documents WHERE updated_ts&gt;=@last_reindex UNION \
	SELECT id FROM documents_deleted WHERE deleted_ts&gt;=@last_reindex
</pre></div>
<div class="sect2" title="11.1.17.&nbsp;sql_attr_uint"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-uint"></a>11.1.17.&nbsp;sql_attr_uint</h3></div></div></div>
<p>Unsigned integer <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a>
        declaration. Multi-value (there might be multiple attributes
        declared), optional. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>The column value should fit into 32-bit unsigned integer range.
        Values outside this range will be accepted but wrapped around. For
        instance, -1 will be wrapped around to 2^32-1 or 4,294,967,295.</p><p>You can specify bit count for integer attributes by appending
        ':BITCOUNT' to attribute name (see example below). Attributes with
        less than default 32-bit size, or bitfields, perform slower. But they
        require less RAM when using <a class="link" href="#conf-docinfo" title="11.2.4.&nbsp;docinfo">extern
        storage</a>: such bitfields are packed together in 32-bit chunks in
        <code class="filename">.spa</code> attribute data file. Bit size settings are
        ignored if using <a class="link" href="#conf-docinfo" title="11.2.4.&nbsp;docinfo">inline
        storage</a>.</p><h4>Example:</h4><pre class="programlisting">sql_attr_uint = group_id
sql_attr_uint = forum_id:9 # 9 bits for forum_id
</pre></div>
<div class="sect2" title="11.1.18.&nbsp;sql_attr_bool"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-bool"></a>11.1.18.&nbsp;sql_attr_bool</h3></div></div></div>
<p>Boolean <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a> declaration.
        Multi-value (there might be multiple attributes declared), optional.
        Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only. Equivalent to
        <a class="link" href="#conf-sql-attr-uint" title="11.1.17.&nbsp;sql_attr_uint">sql_attr_uint</a> declaration
        with a bit count of 1.</p><h4>Example:</h4><pre class="programlisting">sql_attr_bool = is_deleted # will be packed to 1 bit
</pre></div>
<div class="sect2" title="11.1.19.&nbsp;sql_attr_bigint"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-bigint"></a>11.1.19.&nbsp;sql_attr_bigint</h3></div></div></div>
<p>64-bit signed integer <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a> declaration. Multi-value (there
        might be multiple attributes declared), optional. Applies to SQL
        source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Note that unlike <a class="link" href="#conf-sql-attr-uint" title="11.1.17.&nbsp;sql_attr_uint">sql_attr_uint</a>, these values are
        <span class="bold"><strong>signed</strong></span>. Introduced in version 0.9.9-rc1.</p><h4>Example:</h4><pre class="programlisting">sql_attr_bigint = my_bigint_id
</pre></div>
<div class="sect2" title="11.1.20.&nbsp;sql_attr_timestamp"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-timestamp"></a>11.1.20.&nbsp;sql_attr_timestamp</h3></div></div></div>
<p>UNIX timestamp <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a>
        declaration. Multi-value (there might be multiple attributes
        declared), optional. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Timestamps can store date and time in the range of Jan 01, 1970
        to Jan 19, 2038 with a precision of one second. The expected column
        value should be a timestamp in UNIX format, ie. 32-bit unsigned
        integer number of seconds elapsed since midnight, January 01, 1970,
        GMT. Timestamps are internally stored and handled as integers
        everywhere. But in addition to working with timestamps as integers,
        it's also legal to use them along with different date-based functions,
        such as time segments sorting mode, or day/week/month/year extraction
        for GROUP BY.</p><p>Note that DATE or DATETIME column types in MySQL can <span class="bold"><strong>not</strong></span>
        be directly used as timestamp attributes in Sphinx; you need to
        explicitly convert such columns using UNIX_TIMESTAMP function (if data
        is in range).</p><p>Note timestamps can not represent dates before January 01, 1970,
        and UNIX_TIMESTAMP() in MySQL will not return anything expected. If
        you only needs to work with dates, not times, consider TO_DAYS()
        function in MySQL instead.</p><h4>Example:</h4><pre class="programlisting">sql_attr_timestamp = UNIX_TIMESTAMP(added_datetime) AS added_ts
</pre></div>
<div class="sect2" title="11.1.21.&nbsp;sql_attr_str2ordinal"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-str2ordinal"></a>11.1.21.&nbsp;sql_attr_str2ordinal</h3></div></div></div>
<p>Ordinal string number <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a> declaration. Multi-value (there
        might be multiple attributes declared), optional. Applies to SQL
        source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>This attribute type (so-called ordinal, for brevity) is intended
        to allow sorting by string values, but without storing the strings
        themselves. When indexing ordinals, string values are fetched from
        database, temporarily stored, sorted, and then replaced by their
        respective ordinal numbers in the array of sorted strings. So, the
        ordinal number is an integer such that sorting by it produces the same
        result as if lexicographically sorting by original strings. by string
        values lexicographically.</p><p>Earlier versions could consume a lot of RAM for indexing
        ordinals. Starting with revision r1112, ordinals accumulation and
        sorting also runs in fixed memory (at the cost of using additional
        temporary disk space), and honors <a class="link" href="#conf-mem-limit" title="11.3.1.&nbsp;mem_limit">mem_limit</a> settings.</p><p>Ideally the strings should be sorted differently, depending on
        the encoding and locale. For instance, if the strings are known to be
        Russian text in KOI8R encoding, sorting the bytes 0xE0, 0xE1, and 0xE2
        should produce 0xE1, 0xE2 and 0xE0, because in KOI8R value 0xE0
        encodes a character that is (noticeably) after characters encoded by
        0xE1 and 0xE2. Unfortunately, Sphinx does not support that at the
        moment and will simply sort the strings bytewise.</p><p>Note that the ordinals are by construction local to each index,
        and it's therefore impossible to merge ordinals while retaining the
        proper order. The processed strings are replaced by their sequential
        number in the index they occurred in, but different indexes have
        different sets of strings. For instance, if 'main' index contains
        strings "aaa", "bbb", "ccc", and so on up to "zzz", they'll be
        assigned numbers 1, 2, 3, and so on up to 26, respectively. But then
        if 'delta' only contains "zzz" the assigned number will be 1. And
        after the merge, the order will be broken. Unfortunately, this is
        impossible to workaround without storing the original strings (and
        once Sphinx supports storing the original strings, ordinals will not
        be necessary any more).</p><h4>Example:</h4><pre class="programlisting">sql_attr_str2ordinal = author_name
</pre></div>
<div class="sect2" title="11.1.22.&nbsp;sql_attr_float"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-float"></a>11.1.22.&nbsp;sql_attr_float</h3></div></div></div>
<p>Floating point <a class="link" href="#attributes" title="3.2.&nbsp;Attributes">attribute</a>
        declaration. Multi-value (there might be multiple attributes
        declared), optional. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>The values will be stored in single precision, 32-bit IEEE 754
        format. Represented range is approximately from 1e-38 to 1e+38. The
        amount of decimal digits that can be stored precisely is approximately
        7. One important usage of the float attributes is storing latitude and
        longitude values (in radians), for further usage in query-time
        geosphere distance calculations.</p><h4>Example:</h4><pre class="programlisting">sql_attr_float = lat_radians
sql_attr_float = long_radians
</pre></div>
<div class="sect2" title="11.1.23.&nbsp;sql_attr_multi"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-multi"></a>11.1.23.&nbsp;sql_attr_multi</h3></div></div></div>
<p><a class="link" href="#mva" title="3.3.&nbsp;MVA (multi-valued attributes)">Multi-valued attribute</a> (MVA)
        declaration. Multi-value (ie. there may be more than one such
        attribute declared), optional. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Plain attributes only allow to attach 1 value per each document.
        However, there are cases (such as tags or categories) when it is
        desired to attach multiple values of the same attribute and be able to
        apply filtering or grouping to value lists.</p><p>The declaration format is as follows (backslashes are for
        clarity only; everything can be declared in a single line as well):
        </p><pre class="programlisting">sql_attr_multi = ATTR-TYPE ATTR-NAME 'from' SOURCE-TYPE \
	[;QUERY] \
	[;RANGE-QUERY]
</pre><p> where </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>ATTR-TYPE is 'uint' or 'timestamp'</p></li>
<li class="listitem"><p>SOURCE-TYPE is 'field', 'query', or 'ranged-query'</p></li>
<li class="listitem"><p>QUERY is SQL query used to fetch all ( docid, attrvalue )
              pairs</p></li>
<li class="listitem"><p>RANGE-QUERY is SQL query used to fetch min and max ID
              values, similar to 'sql_query_range'</p></li>
</ul></div>
<h4>Example:</h4><pre class="programlisting">sql_attr_multi = uint tag from query; SELECT id, tag FROM tags
sql_attr_multi = uint tag from ranged-query; \
	SELECT id, tag FROM tags WHERE id&gt;=$start AND id&lt;=$end; \
	SELECT MIN(id), MAX(id) FROM tags
</pre></div>
<div class="sect2" title="11.1.24.&nbsp;sql_attr_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-string"></a>11.1.24.&nbsp;sql_attr_string</h3></div></div></div>
<p>String attribute declaration. Multi-value (ie. there may be more
        than one such attribute declared), optional. Applies to SQL source
        types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 1.10-beta.</p><p>String attributes can store arbitrary strings attached to every
        document. There's a fixed size limit of 4 MB per value. Also,
        <code class="filename">searchd</code> will currently cache all the values in
        RAM, which is an additional implicit limit.</p><p>As of 1.10-beta, strings can only be used for storage and
        retrieval. They can not participate in expressions, be used for
        filtering, sorting, or grouping (ie. in WHERE, ORDER or GROUP
        clauses). Note that attributes declared using
        <code class="option">sql_attr_string</code> will <span class="bold"><strong>not</strong></span> be full-text indexed;
        you can use <a class="link" href="#conf-sql-field-string" title="11.1.27.&nbsp;sql_field_string">sql_field_string</a> directive for
        that.</p><h4>Example:</h4><pre class="programlisting">sql_attr_string = title # will be stored but will not be indexed
</pre></div>
<div class="sect2" title="11.1.25.&nbsp;sql_attr_str2wordcount"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-attr-str2wordcount"></a>11.1.25.&nbsp;sql_attr_str2wordcount</h3></div></div></div>
<p>Word-count attribute declaration. Multi-value (ie. there may be
        more than one such attribute declared), optional. Applies to SQL
        source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 1.10-beta.</p><p>Word-count attribute takes a string column, tokenizes it
        according to index settings, and stores the resulting number of tokens
        in an attribute. This number of tokens ("word count") is a normal
        integer that can be later used, for instance, in custom ranking
        expressions (boost shorter titles, help identify exact field matches,
        etc).</p><h4>Example:</h4><pre class="programlisting">sql_attr_str2wordcount = title_wc
</pre></div>
<div class="sect2" title="11.1.26.&nbsp;sql_column_buffers"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-column-buffers"></a>11.1.26.&nbsp;sql_column_buffers</h3></div></div></div>
<p>Per-column buffer sizes. Optional, default is empty (deduce the
        sizes automatically). Applies to <code class="option">odbc</code>,
        <code class="option">mssql</code> source types only. Introduced in version
        2.0.1-beta.</p><p>ODBC and MS SQL drivers sometimes can not return the maximum
        actual column size to be expected. For instance, NVARCHAR(MAX) columns
        always report their length as 2147483647 bytes to
        <code class="filename">indexer</code> even though the actually used length is
        likely considerably less. However, the receiving buffers still need to
        be allocated upfront, and their sizes have to be determined. When the
        driver does not report the column length at all, Sphinx allocates
        default 1 KB buffers for each non-char column, and 1 MB buffers for
        each char column. Driver-reported column length also gets clamped by
        an upper limie of 8 MB, so in case the driver reports (almost) a 2 GB
        column length, it will be clamped and a 8 MB buffer will be allocated
        instead for that column. These hard-coded limits can be overridden
        using the <code class="code">sql_column_buffers</code> directive, either in order
        to save memory on actually shorter columns, or overcome the 8 MB limit
        on actually longer columns. The directive values must be a
        comma-separated lists of selected column names and sizes:
        </p><pre class="programlisting">sql_column_buffers = &lt;colname&gt;=&lt;size&gt;[K|M] [, ...]
</pre><h4>Example:</h4><pre class="programlisting">sql_query = SELECT id, mytitle, mycontent FROM documents
sql_column_buffers = mytitle=64K, mycontent=10M
</pre></div>
<div class="sect2" title="11.1.27.&nbsp;sql_field_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-field-string"></a>11.1.27.&nbsp;sql_field_string</h3></div></div></div>
<p>Combined string attribute and full-text field declaration.
        Multi-value (ie. there may be more than one such attribute declared),
        optional. Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only. Introduced in
        version 1.10-beta.</p><p><a class="link" href="#conf-sql-attr-string" title="11.1.24.&nbsp;sql_attr_string">sql_attr_string</a> only
        stores the column value but does not full-text index it. In some cases
        it might be desired to both full-text index the column and store it as
        attribute. <code class="option">sql_field_string</code> lets you do exactly that.
        Both the field and the attribute will be named the same.</p><h4>Example:</h4><pre class="programlisting">sql_field_string = title # will be both indexed and stored
</pre></div>
<div class="sect2" title="11.1.28.&nbsp;sql_field_str2wordcount"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-field-str2wordcount"></a>11.1.28.&nbsp;sql_field_str2wordcount</h3></div></div></div>
<p>Combined word-count attribute and full-text field declaration.
        Multi-value (ie. there may be more than one such attribute declared),
        optional. Applies to SQL source types (<code class="option">mysql</code>,
        <code class="option">pgsql</code>, <code class="option">mssql</code>) only. Introduced in
        version 1.10-beta.</p><p><a class="link" href="#conf-sql-attr-str2wordcount" title="11.1.25.&nbsp;sql_attr_str2wordcount">sql_attr_str2wordcount</a>
        only stores the column word count but does not full-text index it. In
        some cases it might be desired to both full-text index the column and
        also have the count. <code class="option">sql_field_str2wordcount</code> lets you
        do exactly that. Both the field and the attribute will be named the
        same.</p><h4>Example:</h4><pre class="programlisting">sql_field_str2wordcount = title # will be indexed, and counted/stored
</pre></div>
<div class="sect2" title="11.1.29.&nbsp;sql_file_field"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-file-field"></a>11.1.29.&nbsp;sql_file_field</h3></div></div></div>
<p>File based field declaration. Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 1.10-beta.</p><p>This directive makes <code class="filename">indexer</code> interpret
        field contents as a file name, and load and index the referred file.
        Files larger than <a class="link" href="#conf-max-file-field-buffer" title="11.3.6.&nbsp;max_file_field_buffer">max_file_field_buffer</a> in
        size are skipped. Any errors during the file loading (IO errors,
        missed limits, etc) will be reported as indexing warnings and will
        <span class="bold"><strong>not</strong></span> early terminate the indexing. No content will be indexed
        for such files.</p><h4>Example:</h4><pre class="programlisting">sql_file_field = my_file_path # load and index files referred to by my_file_path
</pre></div>
<div class="sect2" title="11.1.30.&nbsp;sql_query_post"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-post"></a>11.1.30.&nbsp;sql_query_post</h3></div></div></div>
<p>Post-fetch query. Optional, default value is empty. Applies to
        SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>This query is executed immediately after <a class="link" href="#conf-sql-query" title="11.1.12.&nbsp;sql_query">sql_query</a> completes successfully. When
        post-fetch query produces errors, they are reported as warnings, but
        indexing is <span class="bold"><strong>not</strong></span> terminated. It's result set is ignored. Note
        that indexing is <span class="bold"><strong>not</strong></span> yet completed at the point when this query
        gets executed, and further indexing still may fail. Therefore, any
        permanent updates should not be done from here. For instance, updates
        on helper table that permanently change the last successfully indexed
        ID should not be run from post-fetch query; they should be run from
        <a class="link" href="#conf-sql-query-post-index" title="11.1.31.&nbsp;sql_query_post_index">post-index query</a>
        instead.</p><h4>Example:</h4><pre class="programlisting">sql_query_post = DROP TABLE my_tmp_table
</pre></div>
<div class="sect2" title="11.1.31.&nbsp;sql_query_post_index"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-post-index"></a>11.1.31.&nbsp;sql_query_post_index</h3></div></div></div>
<p>Post-index query. Optional, default value is empty. Applies to
        SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>This query is executed when indexing is fully and succesfully
        completed. If this query produces errors, they are reported as
        warnings, but indexing is <span class="bold"><strong>not</strong></span> terminated. It's result set is
        ignored. <code class="code">$maxid</code> macro can be used in its text; it will be
        expanded to maximum document ID which was actually fetched from the
        database during indexing. If no documents were indexed, $maxid will be
        expanded to 0.</p><h4>Example:</h4><pre class="programlisting">sql_query_post_index = REPLACE INTO counters ( id, val ) \
    VALUES ( 'max_indexed_id', $maxid )
</pre></div>
<div class="sect2" title="11.1.32.&nbsp;sql_ranged_throttle"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-ranged-throttle"></a>11.1.32.&nbsp;sql_ranged_throttle</h3></div></div></div>
<p>Ranged query throttling period, in milliseconds. Optional,
        default is 0 (no throttling). Applies to SQL source types
        (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only.</p><p>Throttling can be useful when indexer imposes too much load on
        the database server. It causes the indexer to sleep for given amount
        of milliseconds once per each ranged query step. This sleep is
        unconditional, and is performed before the fetch query.</p><h4>Example:</h4><pre class="programlisting">sql_ranged_throttle = 1000 # sleep for 1 sec before each query step
</pre></div>
<div class="sect2" title="11.1.33.&nbsp;sql_query_info"><div class="titlepage"><div><div><h3 class="title"><a name="conf-sql-query-info"></a>11.1.33.&nbsp;sql_query_info</h3></div></div></div>
<p>Document info query. Optional, default is empty. Applies to
        <code class="option">mysql</code> source type only.</p><p>Only used by CLI search to fetch and display document
        information, only works with MySQL at the moment, and only intended
        for debugging purposes. This query fetches the row that will be
        displayed by CLI search utility for each document ID. It is required
        to contain <code class="code">$id</code> macro that expands to the queried document
        ID.</p><h4>Example:</h4><pre class="programlisting">sql_query_info = SELECT * FROM documents WHERE id=$id
</pre></div>
<div class="sect2" title="11.1.34.&nbsp;xmlpipe_command"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-command"></a>11.1.34.&nbsp;xmlpipe_command</h3></div></div></div>
<p>Shell command that invokes xmlpipe stream producer. Mandatory.
        Applies to <code class="option">xmlpipe</code> and <code class="option">xmlpipe2</code>
        source types only.</p><p>Specifies a command that will be executed and which output will
        be parsed for documents. Refer to <a class="xref" href="#xmlpipe" title="3.8.&nbsp;xmlpipe data source">Section&nbsp;3.8, “xmlpipe data source”</a> or <a class="xref" href="#xmlpipe2" title="3.9.&nbsp;xmlpipe2 data source">Section&nbsp;3.9, “xmlpipe2 data source”</a> for specific format description.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_command = cat /home/sphinx/test.xml
</pre></div>
<div class="sect2" title="11.1.35.&nbsp;xmlpipe_field"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-field"></a>11.1.35.&nbsp;xmlpipe_field</h3></div></div></div>
<p>xmlpipe field declaration. Multi-value, optional. Applies to
        <code class="option">xmlpipe2</code> source type only. Refer to <a class="xref" href="#xmlpipe2" title="3.9.&nbsp;xmlpipe2 data source">Section&nbsp;3.9, “xmlpipe2 data source”</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_field = subject
xmlpipe_field = content
</pre></div>
<div class="sect2" title="11.1.36.&nbsp;xmlpipe_field_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-field-string"></a>11.1.36.&nbsp;xmlpipe_field_string</h3></div></div></div>
<p>xmlpipe field and string attribute declaration. Multi-value,
        optional. Applies to <code class="option">xmlpipe2</code> source type only. Refer
        to <a class="xref" href="#xmlpipe2" title="3.9.&nbsp;xmlpipe2 data source">Section&nbsp;3.9, “xmlpipe2 data source”</a>. Introduced in version
        1.10-beta.</p><p>Makes the specified XML element indexed as both a full-text
        field and a string attribute. Equivalent to &lt;sphinx:field
        name="field" attr="string"/&gt; declaration within the XML
        file.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_field_string = subject
</pre></div>
<div class="sect2" title="11.1.37.&nbsp;xmlpipe_field_wordcount"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-field-wordcount"></a>11.1.37.&nbsp;xmlpipe_field_wordcount</h3></div></div></div>
<p>xmlpipe field and word count attribute declaration. Multi-value,
        optional. Applies to <code class="option">xmlpipe2</code> source type only. Refer
        to <a class="xref" href="#xmlpipe2" title="3.9.&nbsp;xmlpipe2 data source">Section&nbsp;3.9, “xmlpipe2 data source”</a>. Introduced in version
        1.10-beta.</p><p>Makes the specified XML element indexed as both a full-text
        field and a word count attribute. Equivalent to &lt;sphinx:field
        name="field" attr="wordcount"/&gt; declaration within the XML
        file.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_field_wordcount = subject
</pre></div>
<div class="sect2" title="11.1.38.&nbsp;xmlpipe_attr_uint"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-uint"></a>11.1.38.&nbsp;xmlpipe_attr_uint</h3></div></div></div>
<p>xmlpipe integer attribute declaration. Multi-value, optional.
        Applies to <code class="option">xmlpipe2</code> source type only. Syntax fully
        matches that of <a class="link" href="#conf-sql-attr-uint" title="11.1.17.&nbsp;sql_attr_uint">sql_attr_uint</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_uint = author
</pre></div>
<div class="sect2" title="11.1.39.&nbsp;xmlpipe_attr_bool"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-bool"></a>11.1.39.&nbsp;xmlpipe_attr_bool</h3></div></div></div>
<p>xmlpipe boolean attribute declaration. Multi-value, optional.
        Applies to <code class="option">xmlpipe2</code> source type only. Syntax fully
        matches that of <a class="link" href="#conf-sql-attr-bool" title="11.1.18.&nbsp;sql_attr_bool">sql_attr_bool</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_bool = is_deleted # will be packed to 1 bit
</pre></div>
<div class="sect2" title="11.1.40.&nbsp;xmlpipe_attr_timestamp"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-timestamp"></a>11.1.40.&nbsp;xmlpipe_attr_timestamp</h3></div></div></div>
<p>xmlpipe UNIX timestamp attribute declaration. Multi-value,
        optional. Applies to <code class="option">xmlpipe2</code> source type only.
        Syntax fully matches that of <a class="link" href="#conf-sql-attr-timestamp" title="11.1.20.&nbsp;sql_attr_timestamp">sql_attr_timestamp</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_timestamp = published
</pre></div>
<div class="sect2" title="11.1.41.&nbsp;xmlpipe_attr_str2ordinal"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-str2ordinal"></a>11.1.41.&nbsp;xmlpipe_attr_str2ordinal</h3></div></div></div>
<p>xmlpipe string ordinal attribute declaration. Multi-value,
        optional. Applies to <code class="option">xmlpipe2</code> source type only.
        Syntax fully matches that of <a class="link" href="#conf-sql-attr-str2ordinal" title="11.1.21.&nbsp;sql_attr_str2ordinal">sql_attr_str2ordinal</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_str2ordinal = author_sort
</pre></div>
<div class="sect2" title="11.1.42.&nbsp;xmlpipe_attr_float"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-float"></a>11.1.42.&nbsp;xmlpipe_attr_float</h3></div></div></div>
<p>xmlpipe floating point attribute declaration. Multi-value,
        optional. Applies to <code class="option">xmlpipe2</code> source type only.
        Syntax fully matches that of <a class="link" href="#conf-sql-attr-float" title="11.1.22.&nbsp;sql_attr_float">sql_attr_float</a>.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_float = lat_radians
xmlpipe_attr_float = long_radians
</pre></div>
<div class="sect2" title="11.1.43.&nbsp;xmlpipe_attr_multi"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-multi"></a>11.1.43.&nbsp;xmlpipe_attr_multi</h3></div></div></div>
<p>xmlpipe MVA attribute declaration. Multi-value, optional.
        Applies to <code class="option">xmlpipe2</code> source type only.</p><p>This setting declares an MVA attribute tag in xmlpipe2 stream.
        The contents of the specified tag will be parsed and a list of
        integers that will constitute the MVA will be extracted, similar to
        how <a class="link" href="#conf-sql-attr-multi" title="11.1.23.&nbsp;sql_attr_multi">sql_attr_multi</a> parses
        SQL column contents when 'field' MVA source type is specified.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_multi = taglist
</pre></div>
<div class="sect2" title="11.1.44.&nbsp;xmlpipe_attr_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-attr-string"></a>11.1.44.&nbsp;xmlpipe_attr_string</h3></div></div></div>
<p>xmlpipe string declaration. Multi-value, optional. Applies to
        <code class="option">xmlpipe2</code> source type only. Introduced in version
        1.10-beta.</p><p>This setting declares a string attribute tag in xmlpipe2 stream.
        The contents of the specified tag will be parsed and stored as a
        string value.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_attr_string = subject
</pre></div>
<div class="sect2" title="11.1.45.&nbsp;xmlpipe_fixup_utf8"><div class="titlepage"><div><div><h3 class="title"><a name="conf-xmlpipe-fixup-utf8"></a>11.1.45.&nbsp;xmlpipe_fixup_utf8</h3></div></div></div>
<p>Perform Sphinx-side UTF-8 validation and filtering to prevent
        XML parser from choking on non-UTF-8 documents. Optional, default is
        0. Applies to <code class="option">xmlpipe2</code> source type only.</p><p>Under certain occasions it might be hard or even impossible to
        guarantee that the incoming XMLpipe2 document bodies are in perfectly
        valid and conforming UTF-8 encoding. For instance, documents with
        national single-byte encodings could sneak into the stream. libexpat
        XML parser is fragile, meaning that it will stop processing in such
        cases. UTF8 fixup feature lets you avoid that. When fixup is enabled,
        Sphinx will preprocess the incoming stream before passing it to the
        XML parser and replace invalid UTF-8 sequences with spaces.</p><h4>Example:</h4><pre class="programlisting">xmlpipe_fixup_utf8 = 1
</pre></div>
<div class="sect2" title="11.1.46.&nbsp;mssql_winauth"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mssql-winauth"></a>11.1.46.&nbsp;mssql_winauth</h3></div></div></div>
<p>MS SQL Windows authentication flag. Boolean, optional, default
        value is 0 (false). Applies to <code class="option">mssql</code> source type
        only. Introduced in version 0.9.9-rc1.</p><p>Whether to use currently logged in Windows account credentials
        for authentication when connecting to MS SQL Server. Note that when
        running <code class="filename">searchd</code> as a service, account user can
        differ from the account you used to install the service.</p><h4>Example:</h4><pre class="programlisting">mssql_winauth = 1
</pre></div>
<div class="sect2" title="11.1.47.&nbsp;mssql_unicode"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mssql-unicode"></a>11.1.47.&nbsp;mssql_unicode</h3></div></div></div>
<p>MS SQL encoding type flag. Boolean, optional, default value is 0
        (false). Applies to <code class="option">mssql</code> source type only.
        Introduced in version 0.9.9-rc1.</p><p>Whether to ask for Unicode or single-byte data when querying MS
        SQL Server. This flag <span class="bold"><strong>must</strong></span> be in sync with <a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a> directive; that is, to
        index Unicode data, you must set both <code class="option">charset_type</code> in
        the index (to 'utf-8') and <code class="option">mssql_unicode</code> in the
        source (to 1). For reference, MS SQL will actually return data in
        UCS-2 encoding instead of UTF-8, but Sphinx will automatically handle
        that.</p><h4>Example:</h4><pre class="programlisting">mssql_unicode = 1
</pre></div>
<div class="sect2" title="11.1.48.&nbsp;unpack_zlib"><div class="titlepage"><div><div><h3 class="title"><a name="conf-unpack-zlib"></a>11.1.48.&nbsp;unpack_zlib</h3></div></div></div>
<p>Columns to unpack using zlib (aka deflate, aka gunzip).
        Multi-value, optional, default value is empty list of columns. Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 0.9.9-rc1.</p><p>Columns specified using this directive will be unpacked by
        <code class="filename">indexer</code> using standard zlib algorithm (called
        deflate and also implemented by <code class="filename">gunzip</code>). When
        indexing on a different box than the database, this lets you offload
        the database, and save on network traffic. The feature is only
        available if zlib and zlib-devel were both available during build
        time.</p><h4>Example:</h4><pre class="programlisting">unpack_zlib = col1
unpack_zlib = col2
</pre></div>
<div class="sect2" title="11.1.49.&nbsp;unpack_mysqlcompress"><div class="titlepage"><div><div><h3 class="title"><a name="conf-unpack-mysqlcompress"></a>11.1.49.&nbsp;unpack_mysqlcompress</h3></div></div></div>
<p>Columns to unpack using MySQL UNCOMPRESS() algorithm.
        Multi-value, optional, default value is empty list of columns. Applies
        to SQL source types (<code class="option">mysql</code>, <code class="option">pgsql</code>,
        <code class="option">mssql</code>) only. Introduced in version 0.9.9-rc1.</p><p>Columns specified using this directive will be unpacked by
        <code class="filename">indexer</code> using modified zlib algorithm used by
        MySQL COMPRESS() and UNCOMPRESS() functions. When indexing on a
        different box than the database, this lets you offload the database,
        and save on network traffic. The feature is only available if zlib and
        zlib-devel were both available during build time.</p><h4>Example:</h4><pre class="programlisting">unpack_mysqlcompress = body_compressed
unpack_mysqlcompress = description_compressed
</pre></div>
<div class="sect2" title="11.1.50.&nbsp;unpack_mysqlcompress_maxsize"><div class="titlepage"><div><div><h3 class="title"><a name="conf-unpack-mysqlcompress-maxsize"></a>11.1.50.&nbsp;unpack_mysqlcompress_maxsize</h3></div></div></div>
<p>Buffer size for UNCOMPRESS()ed data. Optional, default value is
        16M. Introduced in version 0.9.9-rc1.</p><p>When using <a class="link" href="#conf-unpack-mysqlcompress" title="11.1.49.&nbsp;unpack_mysqlcompress">unpack_mysqlcompress</a>, due
        to implementation intrincacies it is not possible to deduce the
        required buffer size from the compressed data. So the buffer must be
        preallocated in advance, and unpacked data can not go over the buffer
        size. This option lets you control the buffer size, both to limit
        <code class="filename">indexer</code> memory use, and to enable unpacking of
        really long data fields if necessary.</p><h4>Example:</h4><pre class="programlisting">unpack_mysqlcompress_maxsize = 1M
</pre></div></div>
<div class="sect1" title="11.2.&nbsp;Index configuration options"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="confgroup-index"></a>11.2.&nbsp;Index configuration options</h2></div></div></div>
<div class="sect2" title="11.2.1.&nbsp;type"><div class="titlepage"><div><div><h3 class="title"><a name="conf-index-type"></a>11.2.1.&nbsp;type</h3></div></div></div>
<p>Index type. Known values are 'plain', 'distributed', and 'rt'.
        Optional, default is 'plain' (plain local index).</p><p>Sphinx supports several different types of indexes. Versions
        0.9.x supported two index types: plain local indexes that are stored
        and processed on the local machine; and distributed indexes, that
        involve not only local searching but querying remote
        <code class="filename">searchd</code> instances over the network as well (see
        <a class="xref" href="#distributed" title="5.8.&nbsp;Distributed searching">Section&nbsp;5.8, “Distributed searching”</a>). Version 1.10-beta also adds support
        for so-called real-time indexes (or RT indexes for short) that are
        also stored and processed locally, but additionally allow for
        on-the-fly updates of the full-text index (see <a class="xref" href="#rt-indexes" title="Chapter&nbsp;4.&nbsp;Real-time indexes">Chapter&nbsp;4, <i>Real-time indexes</i></a>). Note that <span class="emphasis"><em>attributes</em></span>
        can be updated on-the-fly using either plain local indexes or RT
        ones.</p><p>Index type setting lets you choose the needed type. By default,
        plain local index type will be assumed.</p><h4>Example:</h4><pre class="programlisting">type = distributed
</pre></div>
<div class="sect2" title="11.2.2.&nbsp;source"><div class="titlepage"><div><div><h3 class="title"><a name="conf-source"></a>11.2.2.&nbsp;source</h3></div></div></div>
<p>Adds document source to local index. Multi-value,
        mandatory.</p><p>Specifies document source to get documents from when the current
        index is indexed. There must be at least one source. There may be
        multiple sources, without any restrictions on the source types: ie.
        you can pull part of the data from MySQL server, part from PostgreSQL,
        part from the filesystem using xmlpipe2 wrapper.</p><p>However, there are some restrictions on the source data. First,
        document IDs must be globally unique across all sources. If that
        condition is not met, you might get unexpected search results. Second,
        source schemas must be the same in order to be stored within the same
        index.</p><p>No source ID is stored automatically. Therefore, in order to be
        able to tell what source the matched document came from, you will need
        to store some additional information yourself. Two typical approaches
        include: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>mangling document ID and encoding source ID in it:
              </p><pre class="programlisting">source src1
{
	sql_query = SELECT id*10+1, ... FROM table1
	...
}

source src2
{
	sql_query = SELECT id*10+2, ... FROM table2
	...
}
</pre></li>
<li class="listitem"><p>storing source ID simply as an attribute: </p><pre class="programlisting">source src1
{
	sql_query = SELECT id, 1 AS source_id FROM table1
	sql_attr_uint = source_id
	...
}

source src2
{
	sql_query = SELECT id, 2 AS source_id FROM table2
	sql_attr_uint = source_id
	...
}
</pre></li>
</ol></div>
<h4>Example:</h4><pre class="programlisting">source = srcpart1
source = srcpart2
source = srcpart3
</pre></div>
<div class="sect2" title="11.2.3.&nbsp;path"><div class="titlepage"><div><div><h3 class="title"><a name="conf-path"></a>11.2.3.&nbsp;path</h3></div></div></div>
<p>Index files path and file name (without extension).
        Mandatory.</p><p>Path specifies both directory and file name, but without
        extension. <code class="filename">indexer</code> will append different
        extensions to this path when generating final names for both permanent
        and temporary index files. Permanent data files have several different
        extensions starting with '.sp'; temporary files' extensions start with
        '.tmp'. It's safe to remove <code class="filename">.tmp*</code> files is if
        indexer fails to remove them automatically.</p><p>For reference, different index files store the following data:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="filename">.spa</code> stores document attributes (used
              in <a class="link" href="#conf-docinfo" title="11.2.4.&nbsp;docinfo">extern docinfo</a> storage
              mode only);</p></li>
<li class="listitem"><p><code class="filename">.spd</code> stores matching document ID
              lists for each word ID;</p></li>
<li class="listitem"><p><code class="filename">.sph</code> stores index header
              information;</p></li>
<li class="listitem"><p><code class="filename">.spi</code> stores word lists (word IDs and
              pointers to <code class="filename">.spd</code> file);</p></li>
<li class="listitem"><p><code class="filename">.spk</code> stores kill-lists;</p></li>
<li class="listitem"><p><code class="filename">.spm</code> stores MVA data;</p></li>
<li class="listitem"><p><code class="filename">.spp</code> stores hit (aka posting, aka
              word occurence) lists for each word ID;</p></li>
<li class="listitem"><p><code class="filename">.sps</code> stores string attribute
              data.</p></li>
</ul></div>
<h4>Example:</h4><pre class="programlisting">path = /var/data/test1
</pre></div>
<div class="sect2" title="11.2.4.&nbsp;docinfo"><div class="titlepage"><div><div><h3 class="title"><a name="conf-docinfo"></a>11.2.4.&nbsp;docinfo</h3></div></div></div>
<p>Document attribute values (docinfo) storage mode. Optional,
        default is 'extern'. Known values are 'none', 'extern' and
        'inline'.</p><p>Docinfo storage mode defines how exactly docinfo will be
        physically stored on disk and RAM. "none" means that there will be no
        docinfo at all (ie. no attributes). Normally you need not to set
        "none" explicitly because Sphinx will automatically select "none" when
        there are no attributes configured. "inline" means that the docinfo
        will be stored in the <code class="filename">.spd</code> file, along with the
        document ID lists. "extern" means that the docinfo will be stored
        separately (externally) from document ID lists, in a special
        <code class="filename">.spa</code> file.</p><p>Basically, externally stored docinfo must be kept in RAM when
        querying. for performance reasons. So in some cases "inline" might be
        the only option. However, such cases are infrequent, and docinfo
        defaults to "extern". Refer to <a class="xref" href="#attributes" title="3.2.&nbsp;Attributes">Section&nbsp;3.2, “Attributes”</a> for
        in-depth discussion and RAM usage estimates.</p><h4>Example:</h4><pre class="programlisting">docinfo = inline
</pre></div>
<div class="sect2" title="11.2.5.&nbsp;mlock"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mlock"></a>11.2.5.&nbsp;mlock</h3></div></div></div>
<p>Memory locking for cached data. Optional, default is 0 (do not
        call mlock()).</p><p>For search performance, <code class="filename">searchd</code> preloads a
        copy of <code class="filename">.spa</code> and <code class="filename">.spi</code> files
        in RAM, and keeps that copy in RAM at all times. But if there are no
        searches on the index for some time, there are no accesses to that
        cached copy, and OS might decide to swap it out to disk. First queries
        to such "cooled down" index will cause swap-in and their latency will
        suffer.</p><p>Setting mlock option to 1 makes Sphinx lock physical RAM used
        for that cached data using mlock(2) system call, and that prevents
        swapping (see man 2 mlock for details). mlock(2) is a privileged call,
        so it will require <code class="filename">searchd</code> to be either run from
        root account, or be granted enough privileges otherwise. If mlock()
        fails, a warning is emitted, but index continues working.</p><h4>Example:</h4><pre class="programlisting">mlock = 1
</pre></div>
<div class="sect2" title="11.2.6.&nbsp;morphology"><div class="titlepage"><div><div><h3 class="title"><a name="conf-morphology"></a>11.2.6.&nbsp;morphology</h3></div></div></div>
<p>A list of morphology preprocessors to apply. Optional, default
        is empty (do not apply any preprocessor).</p><p>Morphology preprocessors can be applied to the words being
        indexed to replace different forms of the same word with the base,
        normalized form. For instance, English stemmer will normalize both
        "dogs" and "dog" to "dog", making search results for both searches the
        same.</p><p>Built-in preprocessors include English stemmer, Russian stemmer
        (that supports UTF-8 and Windows-1251 encodings), Soundex, and
        Metaphone. The latter two replace the words with special phonetic
        codes that are equal is words are phonetically close. Additional
        stemmers provided by <a class="ulink" href="http://snowball.tartarus.org/" target="_top">Snowball</a> project <a class="ulink" href="http://snowball.tartarus.org/dist/libstemmer_c.tgz" target="_top">libstemmer</a>
        library can be enabled at compile time using
        <code class="option">--with-libstemmer</code> <code class="filename">configure</code>
        option. Built-in English and Russian stemmers should be faster than
        their libstemmer counterparts, but can produce slightly different
        results, because they are based on an older version. Metaphone
        implementation is based on Double Metaphone algorithm and indexes the
        primary code.</p><p>Built-in values that are available for use in
        <code class="option">morphology</code> option are as follows: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>none - do not perform any morphology processing;</p></li>
<li class="listitem"><p>stem_en - apply Porter's English stemmer;</p></li>
<li class="listitem"><p>stem_ru - apply Porter's Russian stemmer;</p></li>
<li class="listitem"><p>stem_enru - apply Porter's English and Russian
              stemmers;</p></li>
<li class="listitem"><p>stem_cz - apply Czech stemmer;</p></li>
<li class="listitem"><p>soundex - replace keywords with their SOUNDEX code;</p></li>
<li class="listitem"><p>metaphone - replace keywords with their METAPHONE
              code.</p></li>
</ul></div>
<p> Additional values provided by libstemmer are in
        'libstemmer_XXX' format, where XXX is libstemmer algorithm codename
        (refer to <code class="filename">libstemmer_c/libstemmer/modules.txt</code> for
        a complete list).</p><p>Several stemmers can be specified (comma-separated). They will
        be applied to incoming words in the order they are listed, and the
        processing will stop once one of the stemmers actually modifies the
        word. Also when <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a>
        feature is enabled the word will be looked up in word forms dictionary
        first, and if there is a matching entry in the dictionary, stemmers
        will not be applied at all. Or in other words, <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a> can be used to implement
        stemming exceptions.</p><h4>Example:</h4><pre class="programlisting">morphology = stem_en, libstemmer_sv
</pre></div>
<div class="sect2" title="11.2.7.&nbsp;dict"><div class="titlepage"><div><div><h3 class="title"><a name="conf-dict"></a>11.2.7.&nbsp;dict</h3></div></div></div>
<p>The keywords dictionary type. Known values are 'crc' and
        'keywords'. Optional, default is 'crc'. Introduced in version
        2.0.1-beta.</p><p>The default dictionary type in Sphinx, and the only one
        available until version 2.0.1-beta, is a so-called CRC dictionary
        which never stores the original keyword text in the index. Instead,
        keywords are replaced with their control sum value (either CRC32 or
        FNV64, depending whether Sphinx was built with
        <code class="option">--enable-id64</code>) both when searching and indexing, and
        that value is used internally in the index.</p><p>That approach has two drawbacks. First, in CRC32 case there is a
        chance of control sum collision between several pairs of different
        keywords, growing quadratically with the number of unique keywords in
        the index. (FNV64 case is unaffected in practice, as a chance of a
        single FNV64 collision in a dictionary of 1 billion entries is
        approximately 1:16, or 6.25 percent. And most dictionaries will be
        much more compact that a billion keywords, as a typical spoken human
        language has in the region of 1 to 10 million word forms.) Second, and
        more importantly, substring searches are not directly possible with
        control sums. Sphinx alleviated that by pre-indexing all the possible
        substrings as separate keywords (see <a class="xref" href="#conf-min-prefix-len" title="11.2.18.&nbsp;min_prefix_len">Section&nbsp;11.2.18, “min_prefix_len”</a>, <a class="xref" href="#conf-min-infix-len" title="11.2.19.&nbsp;min_infix_len">Section&nbsp;11.2.19, “min_infix_len”</a> directives). That actually has an
        added benefit of matching substrings in the quickest way possible. But
        at the same time pre-indexing all substrings grows the index size a
        lot (factors of 3-10x and even more would not be unusual) and impacts
        the indexing time respectively, rendering substring searches on big
        indexes rather impractical.</p><p>Keywords dictionary, introduced in 2.0.1-beta, fixes both these
        drawbacks. It stores the keywords in the index and performs
        search-time wildcard expansion. For example, a search for a 'test*'
        prefix could internally expand to 'test|tests|testing' query based on
        the dictionary contents. That expansion is fully transparent to the
        application, except that the separate per-keyword statistics for all
        the actually matched keywords would now also be reported.</p><p>Indexing with keywords dictionary should be 1.1x to 1.3x slower
        compared to regular, non-substring indexing - but times faster
        compared to substring indexing (either prefix or infix). Index size
        should only be slightly bigger that than of the regular non-substring
        index, with a 1..10% percent total difference Regular keyword
        searching time must be very close or identical across all three
        discussed index kinds (CRC non-substring, CRC substring, keywords).
        Substring searching time can vary greatly depending on how many actual
        keywords match the given substring (in other words, into how many
        keywords does the search term expand). The maximum number of keywords
        matched is restricted by the <a class="link" href="#conf-expansion-limit" title="11.4.39.&nbsp;expansion_limit">expansion_limit</a>
        directive.</p><p>Essentially, keywords and CRC dictionaries represent the two
        different trade-off substring searching decisions. You can choose to
        either sacrifice indexing time and index size in favor of top-speed
        worst-case searches (CRC dictionary), or only slightly impact indexing
        time but sacrifice worst-case searching time when the prefix expands
        into very many keywords (keywords dictionary).</p><h4>Example:</h4><pre class="programlisting">dict = keywords
</pre></div>
<div class="sect2" title="11.2.8.&nbsp;index_sp"><div class="titlepage"><div><div><h3 class="title"><a name="conf-index-sp"></a>11.2.8.&nbsp;index_sp</h3></div></div></div>
<p>Whether to detect and index sentence and paragraph boundaries.
        Optional, default is 0 (do not detect and index). Introduced in
        version 2.0.1-beta.</p><p>This directive enables sentence and paragraph boundary indexing.
        It's required for the SENTENCE and PARAGRAPH operators to work.
        Sentence boundary detection is based on plain text analysis, so you
        only need to set <code class="code">index_sp = 1</code> to enable it. Paragraph
        detection is however based on HTML markup, and happens in the <a class="link" href="#conf-html-strip" title="11.2.27.&nbsp;html_strip">HTML stripper</a>. So to index paragraph
        locations you also need to enable the stripper by specifying
        <code class="code">html_strip = 1</code>. Both types of boundaries are detected
        based on a few built-in rules enumerated just below.</p><p>Sentence boundary detection rules are as follows. </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Question and excalamation signs (? and !) are always a
              sentence boundary.</p></li>
<li class="listitem"><p>Trailing dot (.) is a sentence boundary, except:
              </p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p>When followed by a letter. That's considered a part
                    of an abbreviation (as in "S.T.A.L.K.E.R" or "Goldman
                    Sachs S.p.A.").</p></li>
<li class="listitem"><p>When followed by a comma. That's considered an
                    abbreviation followed by a comma (as in "Telecom Italia
                    S.p.A., founded in 1994").</p></li>
<li class="listitem"><p>When followed by a space and a small letter. That's
                    considered an abbreviation within a sentence (as in "News
                    Corp. announced in Februrary").</p></li>
<li class="listitem"><p>When preceded by a space and a capital letter, and
                    followed by a space. That's considered a middle initial
                    (as in "John D. Doe").</p></li>
</ul></div></li>
</ul></div>
<p>Paragraph boundaries are inserted at every block-level HTML tag.
        Namely, those are (as taken from HTML 4 standard) ADDRESS, BLOCKQUOTE,
        CAPTION, CENTER, DD, DIV, DL, DT, H1, H2, H3, H4, H5, LI, MENU, OL, P,
        PRE, TABLE, TBODY, TD, TFOOT, TH, THEAD, TR, and UL.</p><p>Both sentences and paragraphs increment the keyword position
        counter by 1.</p><h4>Example:</h4><pre class="programlisting">index_sp = 1
</pre></div>
<div class="sect2" title="11.2.9.&nbsp;index_zones"><div class="titlepage"><div><div><h3 class="title"><a name="conf-index-zones"></a>11.2.9.&nbsp;index_zones</h3></div></div></div>
<p>A list of in-field HTML/XML zones to index. Optional, default is
        empty (do not index zones). Introduced in version 2.0.1-beta.</p><p>Zones can be formally defined as follows. Everything between an
        opening and a matching closing tag is called a span, and the aggregate
        of all spans corresponding sharing the same tag name is called a zone.
        For instance, everything between the occurrences of &lt;H1&gt; and
        &lt;/H1&gt; in the document field belongs to H1 zone.</p><p>Zone indexing, enabled by <code class="code">index_zones</code> directive, is
        an optional extension of the HTML stripper. So it will also require
        that the <a class="link" href="#conf-html-strip" title="11.2.27.&nbsp;html_strip">stripper</a> is enabled
        (with <code class="code">html_strip = 1</code>). The value of the
        <code class="code">index_zones</code> should be a comma-separated list of those tag
        names and wildcards (ending with a star) that should be indexed as
        zones.</p><p>Zones can nest and overlap arbitrarily. The only requirement is
        that every opening tag has a matching tag. You can also have an
        arbitrary number of both zones (as in unique zone names, such as H1)
        and spans (all the occurrences of those H1 tags) in a document. Once
        indexed, zones can then be used for matching with the ZONE operator,
        see <a class="xref" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">Section&nbsp;5.3, “Extended query syntax”</a>.</p><h4>Example:</h4><pre class="programlisting">index_zones = h*, th, title
</pre></div>
<div class="sect2" title="11.2.10.&nbsp;min_stemming_len"><div class="titlepage"><div><div><h3 class="title"><a name="conf-min-stemming-len"></a>11.2.10.&nbsp;min_stemming_len</h3></div></div></div>
<p>Minimum word length at which to enable stemming. Optional,
        default is 1 (stem everything). Introduced in version
        0.9.9-rc1.</p><p>Stemmers are not perfect, and might sometimes produce undesired
        results. For instance, running "gps" keyword through Porter stemmer
        for English results in "gp", which is not really the intent.
        <code class="option">min_stemming_len</code> feature lets you suppress stemming
        based on the source word length, ie. to avoid stemming too short
        words. Keywords that are shorter than the given threshold will not be
        stemmed. Note that keywords that are exactly as long as specified
        <span class="bold"><strong>will</strong></span> be stemmed. So in order to avoid stemming 3-character
        keywords, you should specify 4 for the value. For more finely grained
        control, refer to <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a>
        feature.</p><h4>Example:</h4><pre class="programlisting">min_stemming_len = 4
</pre></div>
<div class="sect2" title="11.2.11.&nbsp;stopwords"><div class="titlepage"><div><div><h3 class="title"><a name="conf-stopwords"></a>11.2.11.&nbsp;stopwords</h3></div></div></div>
<p>Stopword files list (space separated). Optional, default is
        empty.</p><p>Stopwords are the words that will not be indexed. Typically
        you'd put most frequent words in the stopwords list because they do
        not add much value to search results but consume a lot of resources to
        process.</p><p>You can specify several file names, separated by spaces. All the
        files will be loaded. Stopwords file format is simple plain text. The
        encoding must match index encoding specified in <a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a>. File data will be
        tokenized with respect to <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> settings, so you can
        use the same separators as in the indexed data. The <a class="link" href="#conf-morphology" title="11.2.6.&nbsp;morphology">stemmers</a> will also be applied when
        parsing stopwords file.</p><p>While stopwords are not indexed, they still do affect the
        keyword positions. For instance, assume that "the" is a stopword, that
        document 1 contains the line "in office", and that document 2 contains
        "in the office". Searching for "in office" as for exact phrase will
        only return the first document, as expected, even though "the" in the
        second one is stopped.</p><h4>Example:</h4><pre class="programlisting">stopwords = /usr/local/sphinx/data/stopwords.txt
stopwords = stopwords-ru.txt stopwords-en.txt
</pre></div>
<div class="sect2" title="11.2.12.&nbsp;wordforms"><div class="titlepage"><div><div><h3 class="title"><a name="conf-wordforms"></a>11.2.12.&nbsp;wordforms</h3></div></div></div>
<p>Word forms dictionary. Optional, default is empty.</p><p>Word forms are applied after tokenizing the incoming text by
        <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> rules. They
        essentialy let you replace one word with another. Normally, that would
        be used to bring different word forms to a single normal form (eg. to
        normalize all the variants such as "walks", "walked", "walking" to the
        normal form "walk"). It can also be used to implement stemming
        exceptions, because stemming is not applied to words found in the
        forms list.</p><p>Dictionaries are used to normalize incoming words both during
        indexing and searching. Therefore, to pick up changes in wordforms
        file it's required to reindex and restart
        <code class="filename">searchd</code>.</p><p>Word forms support in Sphinx is designed to support big
        dictionaries well. They moderately affect indexing speed: for
        instance, a dictionary with 1 million entries slows down indexing
        about 1.5 times. Searching speed is not affected at all. Additional
        RAM impact is roughly equal to the dictionary file size, and
        dictionaries are shared across indexes: ie. if the very same 50 MB
        wordforms file is specified for 10 different indexes, additional
        <code class="filename">searchd</code> RAM usage will be about 50 MB.</p><p>Dictionary file should be in a simple plain text format. Each
        line should contain source and destination word forms, in exactly the
        same encoding as specified in <a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a>, separated by
        "greater" sign. Rules from the <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> will be applied when
        the file is loaded. So basically it's as case sensitive as your other
        full-text indexed data, ie. typically case insensitive. Here's the
        file contents sample: </p><pre class="programlisting">walks &gt; walk
walked &gt; walk
walking &gt; walk
</pre><p>There is a bundled <code class="filename">spelldump</code> utility that
        helps you create a dictionary file in the format Sphinx can read from
        source <code class="filename">.dict</code> and <code class="filename">.aff</code>
        dictionary files in <code class="filename">ispell</code> or
        <code class="filename">MySpell</code> format (as bundled with
        OpenOffice).</p><p>Starting with version 0.9.9-rc1, you can map several source
        words to a single destination word. Because the work happens on
        tokens, not the source text, differences in whitespace and markup are
        ignored. </p><pre class="programlisting">core 2 duo &gt; c2d
e6600 &gt; c2d
core 2duo &gt; c2d
</pre><p>Notice however that the <span class="emphasis"><em>destination</em></span>
        wordforms are still always interpreted as a
        <span class="emphasis"><em>single</em></span> keyword! Having a mapping like "St John
        &gt; Saint John" will result in <span class="bold"><strong>not</strong></span> matching "St John" when
        searching for "Saint" or "John", because the destination keyword will
        be "Saint John" with a space character in it (and it's barely possible
        to input a destination keyword with a space).</p><h4>Example:</h4><pre class="programlisting">wordforms = /usr/local/sphinx/data/wordforms.txt
</pre></div>
<div class="sect2" title="11.2.13.&nbsp;exceptions"><div class="titlepage"><div><div><h3 class="title"><a name="conf-exceptions"></a>11.2.13.&nbsp;exceptions</h3></div></div></div>
<p>Tokenizing exceptions file. Optional, default is empty.</p><p>Exceptions allow to map one or more tokens (including tokens
        with characters that would normally be excluded) to a single keyword.
        They are similar to <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a> in
        that they also perform mapping, but have a number of important
        differences.</p><p>Short summary of the differences is as follows: </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>exceptions are case sensitive, wordforms are not;</p></li>
<li class="listitem"><p>exceptions allow to detect sequences of tokens, wordforms
              work with single words only;</p></li>
<li class="listitem"><p>exceptions can use special characters that are <span class="bold"><strong>not</strong></span>
              in charset_table, wordforms fully obey charset_table;</p></li>
<li class="listitem"><p>exceptions can underperform on huge dictionaries,
              wordforms handle millions of entries well.</p></li>
</ul></div>
<p>The expected file format is also plain text, with one line per
        exception, and the line format is as follows: </p><pre class="programlisting">map-from-tokens =&gt; map-to-token
</pre><p> Example file: </p><pre class="programlisting">AT &amp; T =&gt; AT&amp;T
AT&amp;T =&gt; AT&amp;T
Standarten   Fuehrer =&gt; standartenfuhrer
Standarten Fuhrer =&gt; standartenfuhrer
MS Windows =&gt; ms windows
Microsoft Windows =&gt; ms windows
C++ =&gt; cplusplus
c++ =&gt; cplusplus
C plus plus =&gt; cplusplus
</pre><p> All tokens here are case sensitive: they will <span class="bold"><strong>not</strong></span> be
        processed by <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a>
        rules. Thus, with the example exceptions file above, "At&amp;t" text
        will be tokenized as two keywords "at" and "t", because of lowercase
        letters. On the other hand, "AT&amp;T" will match exactly and produce
        single "AT&amp;T" keyword.</p><p>Note that this map-to keyword is a) always interpereted as a
        <span class="emphasis"><em>single</em></span> word, and b) is both case and space
        sensitive! In our sample, "ms windows" query will
        <span class="emphasis"><em>not</em></span> match the document with "MS Windows" text.
        The query will be interpreted as a query for two keywords, "ms" and
        "windows". And what "MS Windows" gets mapped to is a
        <span class="emphasis"><em>single</em></span> keyword "ms windows", with a space in the
        middle. On the other hand, "standartenfuhrer" will retrieve documents
        with "Standarten Fuhrer" or "Standarten Fuehrer" contents (capitalized
        exactly like this), or any capitalization variant of the keyword
        itself, eg. "staNdarTenfUhreR". (It won't catch "standarten fuhrer",
        however: this text does not match any of the listed exceptions because
        of case sensitivity, and gets indexed as two separate
        keywords.)</p><p>Whitespace in the map-from tokens list matters, but its amount
        does not. Any amount of the whitespace in the map-form list will match
        any other amount of whitespace in the indexed document or query. For
        instance, "AT&nbsp;&amp;&nbsp;T" map-from token will match "AT&nbsp;&nbsp;&nbsp;&nbsp;&amp;&nbsp;&nbsp;T"
        text, whatever the amount of space in both map-from part and the
        indexed text. Such text will therefore be indexed as a special
        "AT&amp;T" keyword, thanks to the very first entry from the
        sample.</p><p>Exceptions also allow to capture special characters (that are
        exceptions from general <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> rules; hence the
        name). Assume that you generally do not want to treat '+' as a valid
        character, but still want to be able search for some exceptions from
        this rule such as 'C++'. The sample above will do just that, totally
        independent of what characters are in the table and what are
        not.</p><p>Exceptions are applied to raw incoming document and query data
        during indexing and searching respectively. Therefore, to pick up
        changes in the file it's required to reindex and restart
        <code class="filename">searchd</code>.</p><h4>Example:</h4><pre class="programlisting">exceptions = /usr/local/sphinx/data/exceptions.txt
</pre></div>
<div class="sect2" title="11.2.14.&nbsp;min_word_len"><div class="titlepage"><div><div><h3 class="title"><a name="conf-min-word-len"></a>11.2.14.&nbsp;min_word_len</h3></div></div></div>
<p>Minimum indexed word length. Optional, default is 1 (index
        everything).</p><p>Only those words that are not shorter than this minimum will be
        indexed. For instance, if min_word_len is 4, then 'the' won't be
        indexed, but 'they' will be.</p><h4>Example:</h4><pre class="programlisting">min_word_len = 4
</pre></div>
<div class="sect2" title="11.2.15.&nbsp;charset_type"><div class="titlepage"><div><div><h3 class="title"><a name="conf-charset-type"></a>11.2.15.&nbsp;charset_type</h3></div></div></div>
<p>Character set encoding type. Optional, default is 'sbcs'. Known
        values are 'sbcs' and 'utf-8'.</p><p>Different encodings have different methods for mapping their
        internal characters codes into specific byte sequences. Two most
        common methods in use today are single-byte encoding and UTF-8. Their
        corresponding charset_type values are 'sbcs' (stands for Single Byte
        Character Set) and 'utf-8'. The selected encoding type will be used
        everywhere where the index is used: when indexing the data, when
        parsing the query against this index, when generating snippets,
        etc.</p><p>Note that while 'utf-8' implies that the decoded values must be
        treated as Unicode codepoint numbers, there's a family of 'sbcs'
        encodings that may in turn treat different byte values differently,
        and that should be properly reflected in your <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a> settings. For
        example, the same byte value of 224 (0xE0 hex) maps to different
        Russian letters depending on whether koi-8r or windows-1251 encoding
        is used.</p><h4>Example:</h4><pre class="programlisting">charset_type = utf-8
</pre></div>
<div class="sect2" title="11.2.16.&nbsp;charset_table"><div class="titlepage"><div><div><h3 class="title"><a name="conf-charset-table"></a>11.2.16.&nbsp;charset_table</h3></div></div></div>
<p>Accepted characters table, with case folding rules. Optional,
        default value depends on <a class="link" href="#conf-charset-type" title="11.2.15.&nbsp;charset_type">charset_type</a> value.</p><p>charset_table is the main workhorse of Sphinx tokenizing
        process, ie. the process of extracting keywords from document text or
        query txet. It controls what characters are accepted as valid and what
        are not, and how the accepted characters should be transformed (eg.
        should the case be removed or not).</p><p>You can think of charset_table as of a big table that has a
        mapping for each and every of 100K+ characters in Unicode (or as of a
        small 256-character table if you're using SBCS). By default, every
        character maps to 0, which means that it does not occur within
        keywords and should be treated as a separator. Once mentioned in the
        table, character is mapped to some other character (most frequently,
        either to itself or to a lowercase letter), and is treated as a valid
        keyword part.</p><p>The expected value format is a commas-separated list of
        mappings. Two simplest mappings simply declare a character as valid,
        and map a single character to another single character, respectively.
        But specifying the whole table in such form would result in bloated
        and barely manageable specifications. So there are several syntax
        shortcuts that let you map ranges of characters at once. The complete
        list is as follows: </p><div class="variablelist"><dl><dt><span class="term">A-&gt;a</span></dt>
<dd><p>Single char mapping, declares source char 'A' as allowed
                to occur within keywords and maps it to destination char 'a'
                (but does <span class="emphasis"><em>not</em></span> declare 'a' as
                allowed).</p></dd><dt><span class="term">A..Z-&gt;a..z</span></dt>
<dd><p>Range mapping, declares all chars in source range as
                allowed and maps them to the destination range. Does
                <span class="emphasis"><em>not</em></span> declare destination range as allowed.
                Also checks ranges' lengths (the lengths must be
                equal).</p></dd><dt><span class="term">a</span></dt>
<dd><p>Stray char mapping, declares a character as allowed and
                maps it to itself. Equivalent to a-&gt;a single char
                mapping.</p></dd><dt><span class="term">a..z</span></dt>
<dd><p>Stray range mapping, declares all characters in range as
                allowed and maps them to themselves. Equivalent to
                a..z-&gt;a..z range mapping.</p></dd><dt><span class="term">A..Z/2</span></dt>
<dd><p>Checkerboard range map. Maps every pair of chars to the
                second char. More formally, declares odd characters in range
                as allowed and maps them to the even ones; also declares even
                characters as allowed and maps them to themselves. For
                instance, A..Z/2 is equivalent to A-&gt;B, B-&gt;B, C-&gt;D,
                D-&gt;D, ..., Y-&gt;Z, Z-&gt;Z. This mapping shortcut is
                helpful for a number of Unicode blocks where uppercase and
                lowercase letters go in such interleaved order instead of
                contiguous chunks.</p></dd></dl></div>
<p>Control characters with codes from 0 to 31 are always treated as
        separators. Characters with codes 32 to 127, ie. 7-bit ASCII
        characters, can be used in the mappings as is. To avoid configuration
        file encoding issues, 8-bit ASCII characters and Unicode characters
        must be specified in U+xxx form, where 'xxx' is hexadecimal codepoint
        number. This form can also be used for 7-bit ASCII characters to
        encode special ones: eg. use U+20 to encode space, U+2E to encode dot,
        U+2C to encode comma.</p><h4>Example:</h4><pre class="programlisting"># 'sbcs' defaults for English and Russian
charset_table = 0..9, A..Z-&gt;a..z, _, a..z, \
	U+A8-&gt;U+B8, U+B8, U+C0..U+DF-&gt;U+E0..U+FF, U+E0..U+FF

# 'utf-8' defaults for English and Russian
charset_table = 0..9, A..Z-&gt;a..z, _, a..z, \
	U+410..U+42F-&gt;U+430..U+44F, U+430..U+44F
</pre></div>
<div class="sect2" title="11.2.17.&nbsp;ignore_chars"><div class="titlepage"><div><div><h3 class="title"><a name="conf-ignore-chars"></a>11.2.17.&nbsp;ignore_chars</h3></div></div></div>
<p>Ignored characters list. Optional, default is empty.</p><p>Useful in the cases when some characters, such as soft
        hyphenation mark (U+00AD), should be not just treated as separators
        but rather fully ignored. For example, if '-' is simply not in the
        charset_table, "abc-def" text will be indexed as "abc" and "def"
        keywords. On the contrary, if '-' is added to ignore_chars list, the
        same text will be indexed as a single "abcdef" keyword.</p><p>The syntax is the same as for <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a>, but it's only
        allowed to declare characters, and not allowed to map them. Also, the
        ignored characters must not be present in charset_table.</p><h4>Example:</h4><pre class="programlisting">ignore_chars = U+AD
</pre></div>
<div class="sect2" title="11.2.18.&nbsp;min_prefix_len"><div class="titlepage"><div><div><h3 class="title"><a name="conf-min-prefix-len"></a>11.2.18.&nbsp;min_prefix_len</h3></div></div></div>
<p>Minimum word prefix length to index. Optional, default is 0 (do
        not index prefixes).</p><p>Prefix indexing allows to implement wildcard searching by
        'wordstart*' wildcards (refer to <a class="link" href="#conf-enable-star" title="11.2.22.&nbsp;enable_star">enable_star</a> option for details on
        wildcard syntax). When mininum prefix length is set to a positive
        number, indexer will index all the possible keyword prefixes (ie. word
        beginnings) in addition to the keywords themselves. Too short prefixes
        (below the minimum allowed length) will not be indexed.</p><p>For instance, indexing a keyword "example" with min_prefix_len=3
        will result in indexing "exa", "exam", "examp", "exampl" prefixes
        along with the word itself. Searches against such index for "exam"
        will match documents that contain "example" word, even if they do not
        contain "exam" on itself. However, indexing prefixes will make the
        index grow significantly (because of many more indexed keywords), and
        will degrade both indexing and searching times.</p><p>There's no automatic way to rank perfect word matches higher in
        a prefix index, but there's a number of tricks to achieve that. First,
        you can setup two indexes, one with prefix indexing and one without
        it, search through both, and use <a class="link" href="#api-func-setindexweights" title="8.3.6.&nbsp;SetIndexWeights">SetIndexWeights()</a> call to
        combine weights. Second, you can enable star-syntax and rewrite your
        extended-mode queries: </p><pre class="programlisting"># in sphinx.conf
enable_star = 1

// in query
$cl-&gt;Query ( "( keyword | keyword* ) other keywords" );
</pre><h4>Example:</h4><pre class="programlisting">min_prefix_len = 3
</pre></div>
<div class="sect2" title="11.2.19.&nbsp;min_infix_len"><div class="titlepage"><div><div><h3 class="title"><a name="conf-min-infix-len"></a>11.2.19.&nbsp;min_infix_len</h3></div></div></div>
<p>Minimum infix prefix length to index. Optional, default is 0 (do
        not index infixes).</p><p>Infix indexing allows to implement wildcard searching by
        'start*', '*end', and '*middle*' wildcards (refer to <a class="link" href="#conf-enable-star" title="11.2.22.&nbsp;enable_star">enable_star</a> option for details on
        wildcard syntax). When mininum infix length is set to a positive
        number, indexer will index all the possible keyword infixes (ie.
        substrings) in addition to the keywords themselves. Too short infixes
        (below the minimum allowed length) will not be indexed. For instance,
        indexing a keyword "test" with min_infix_len=2 will result in indexing
        "te", "es", "st", "tes", "est" infixes along with the word itself.
        Searches against such index for "es" will match documents that contain
        "test" word, even if they do not contain "es" on itself. However,
        indexing infixes will make the index grow significantly (because of
        many more indexed keywords), and will degrade both indexing and
        searching times.</p><p>There's no automatic way to rank perfect word matches higher in
        an infix index, but the same tricks as with <a class="link" href="#conf-min-prefix-len" title="11.2.18.&nbsp;min_prefix_len">prefix indexes</a> can be
        applied.</p><h4>Example:</h4><pre class="programlisting">min_infix_len = 3
</pre></div>
<div class="sect2" title="11.2.20.&nbsp;prefix_fields"><div class="titlepage"><div><div><h3 class="title"><a name="conf-prefix-fields"></a>11.2.20.&nbsp;prefix_fields</h3></div></div></div>
<p>The list of full-text fields to limit prefix indexing to.
        Optional, default is empty (index all fields in prefix mode).</p><p>Because prefix indexing impacts both indexing and searching
        performance, it might be desired to limit it to specific full-text
        fields only: for instance, to provide prefix searching through URLs,
        but not through page contents. prefix_fields specifies what fields
        will be prefix-indexed; all other fields will be indexed in normal
        mode. The value format is a comma-separated list of field
        names.</p><h4>Example:</h4><pre class="programlisting">prefix_fields = url, domain
</pre></div>
<div class="sect2" title="11.2.21.&nbsp;infix_fields"><div class="titlepage"><div><div><h3 class="title"><a name="conf-infix-fields"></a>11.2.21.&nbsp;infix_fields</h3></div></div></div>
<p>The list of full-text fields to limit infix indexing to.
        Optional, default is empty (index all fields in infix mode).</p><p>Similar to <a class="link" href="#conf-prefix-fields" title="11.2.20.&nbsp;prefix_fields">prefix_fields</a>, but lets you limit
        infix-indexing to given fields.</p><h4>Example:</h4><pre class="programlisting">infix_fields = url, domain
</pre></div>
<div class="sect2" title="11.2.22.&nbsp;enable_star"><div class="titlepage"><div><div><h3 class="title"><a name="conf-enable-star"></a>11.2.22.&nbsp;enable_star</h3></div></div></div>
<p>Enables star-syntax (or wildcard syntax) when searching through
        prefix/infix indexes. Optional, default is is 0 (do not use wildcard
        syntax), for compatibility with 0.9.7. Known values are 0 and
        1.</p><p>This feature enables "star-syntax", or wildcard syntax, when
        searching through indexes which were created with prefix or infix
        indexing enabled. It only affects searching; so it can be changed
        without reindexing by simply restarting
        <code class="filename">searchd</code>.</p><p>The default value is 0, that means to disable star-syntax and
        treat all keywords as prefixes or infixes respectively, depending on
        indexing-time <a class="link" href="#conf-min-prefix-len" title="11.2.18.&nbsp;min_prefix_len">min_prefix_len</a> and <a class="link" href="#conf-min-infix-len" title="11.2.19.&nbsp;min_infix_len">min_infix_len settings</a>. The value
        of 1 means that star ('*') can be used at the start and/or the end of
        the keyword. The star will match zero or more characters.</p><p>For example, assume that the index was built with infixes and
        that enable_star is 1. Searching should work as follows: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>"abcdef" query will match only those documents that
              contain the exact "abcdef" word in them.</p></li>
<li class="listitem"><p>"abc*" query will match those documents that contain any
              words starting with "abc" (including the documents which contain
              the exact "abc" word only);</p></li>
<li class="listitem"><p>"*cde*" query will match those documents that contain any
              words which have "cde" characters in any part of the word
              (including the documents which contain the exact "cde" word
              only).</p></li>
<li class="listitem"><p>"*def" query will match those documents that contain any
              words ending with "def" (including the documents that contain
              the exact "def" word only).</p></li>
</ol></div>
<h4>Example:</h4><pre class="programlisting">enable_star = 1
</pre></div>
<div class="sect2" title="11.2.23.&nbsp;ngram_len"><div class="titlepage"><div><div><h3 class="title"><a name="conf-ngram-len"></a>11.2.23.&nbsp;ngram_len</h3></div></div></div>
<p>N-gram lengths for N-gram indexing. Optional, default is 0
        (disable n-gram indexing). Known values are 0 and 1 (other lengths to
        be implemented).</p><p>N-grams provide basic CJK (Chinese, Japanese, Korean) support
        for unsegmented texts. The issue with CJK searching is that there
        could be no clear separators between the words. Ideally, the texts
        would be filtered through a special program called segmenter that
        would insert separators in proper locations. However, segmenters are
        slow and error prone, and it's common to index contiguous groups of N
        characters, or n-grams, instead.</p><p>When this feature is enabled, streams of CJK characters are
        indexed as N-grams. For example, if incoming text is "ABCDEF" (where A
        to F represent some CJK characters) and length is 1, in will be
        indexed as if it was "A B C D E F". (With length equal to 2, it would
        produce "AB BC CD DE EF"; but only 1 is supported at the moment.) Only
        those characters that are listed in <a class="link" href="#conf-ngram-chars" title="11.2.24.&nbsp;ngram_chars">ngram_chars</a> table will be split this
        way; other ones will not be affected.</p><p>Note that if search query is segmented, ie. there are separators
        between individual words, then wrapping the words in quotes and using
        extended mode will resut in proper matches being found even if the
        text was <span class="bold"><strong>not</strong></span> segmented. For instance, assume that the original
        query is BC&nbsp;DEF. After wrapping in quotes on the application side, it
        should look like "BC"&nbsp;"DEF" (<span class="emphasis"><em>with</em></span> quotes). This
        query will be passed to Sphinx and internally split into 1-grams too,
        resulting in "B&nbsp;C"&nbsp;"D&nbsp;E&nbsp;F" query, still with quotes that are the
        phrase matching operator. And it will match the text even though there
        were no separators in the text.</p><p>Even if the search query is not segmented, Sphinx should still
        produce good results, thanks to phrase based ranking: it will pull
        closer phrase matches (which in case of N-gram CJK words can mean
        closer multi-character word matches) to the top.</p><h4>Example:</h4><pre class="programlisting">ngram_len = 1
</pre></div>
<div class="sect2" title="11.2.24.&nbsp;ngram_chars"><div class="titlepage"><div><div><h3 class="title"><a name="conf-ngram-chars"></a>11.2.24.&nbsp;ngram_chars</h3></div></div></div>
<p>N-gram characters list. Optional, default is empty.</p><p>To be used in conjunction with in <a class="link" href="#conf-ngram-len" title="11.2.23.&nbsp;ngram_len">ngram_len</a>, this list defines
        characters, sequences of which are subject to N-gram extraction. Words
        comprised of other characters will not be affected by N-gram indexing
        feature. The value format is identical to <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a>.</p><h4>Example:</h4><pre class="programlisting">ngram_chars = U+3000..U+2FA1F
</pre></div>
<div class="sect2" title="11.2.25.&nbsp;phrase_boundary"><div class="titlepage"><div><div><h3 class="title"><a name="conf-phrase-boundary"></a>11.2.25.&nbsp;phrase_boundary</h3></div></div></div>
<p>Phrase boundary characters list. Optional, default is
        empty.</p><p>This list controls what characters will be treated as phrase
        boundaries, in order to adjust word positions and enable phrase-level
        search emulation through proximity search. The syntax is similar to
        <a class="link" href="#conf-charset-table" title="11.2.16.&nbsp;charset_table">charset_table</a>. Mappings are
        not allowed and the boundary characters must not overlap with anything
        else.</p><p>On phrase boundary, additional word position increment
        (specified by <a class="link" href="#conf-phrase-boundary-step" title="11.2.26.&nbsp;phrase_boundary_step">phrase_boundary_step</a>) will
        be added to current word position. This enables phrase-level searching
        through proximity queries: words in different phrases will be
        guaranteed to be more than phrase_boundary_step distance away from
        each other; so proximity search within that distance will be
        equivalent to phrase-level search.</p><p>Phrase boundary condition will be raised if and only if such
        character is followed by a separator; this is to avoid abbreviations
        such as S.T.A.L.K.E.R or URLs being treated as several phrases.</p><h4>Example:</h4><pre class="programlisting">phrase_boundary = ., ?, !, U+2026 # horizontal ellipsis
</pre></div>
<div class="sect2" title="11.2.26.&nbsp;phrase_boundary_step"><div class="titlepage"><div><div><h3 class="title"><a name="conf-phrase-boundary-step"></a>11.2.26.&nbsp;phrase_boundary_step</h3></div></div></div>
<p>Phrase boundary word position increment. Optional, default is
        0.</p><p>On phrase boundary, current word position will be additionally
        incremented by this number. See <a class="link" href="#conf-phrase-boundary" title="11.2.25.&nbsp;phrase_boundary">phrase_boundary</a> for
        details.</p><h4>Example:</h4><pre class="programlisting">phrase_boundary_step = 100
</pre></div>
<div class="sect2" title="11.2.27.&nbsp;html_strip"><div class="titlepage"><div><div><h3 class="title"><a name="conf-html-strip"></a>11.2.27.&nbsp;html_strip</h3></div></div></div>
<p>Whether to strip HTML markup from incoming full-text data.
        Optional, default is 0. Known values are 0 (disable stripping) and 1
        (enable stripping).</p><p>Both HTML tags and entities and considered markup and get
        processed.</p><p>HTML tags are removed, their contents (i.e., everything between
        &lt;P&gt; and &lt;/P&gt;) are left intact by default. You can choose
        to keep and index attributes of the tags (e.g., HREF attribute in an A
        tag, or ALT in an IMG one). Several well-known inline tags are
        completely removed, all other tags are treated as block level and
        replaced with whitespace. For example, 'te&lt;B&gt;st&lt;/B&gt;' text
        will be indexed as a single keyword 'test', however,
        'te&lt;P&gt;st&lt;/P&gt;' will be indexed as two keywords 'te' and
        'st'. Known inline tags are as follows: A, B, I, S, U, BASEFONT, BIG,
        EM, FONT, IMG, LABEL, SMALL, SPAN, STRIKE, STRONG, SUB, SUP,
        TT.</p><p>HTML entities get decoded and replaced with corresponding UTF-8
        characters. Stripper supports both numeric forms (such as &amp;#239;)
        and text forms (such as &amp;oacute; or &amp;nbsp;). All entities as
        specified by HTML4 standard are supported.</p><p>Stripping does not work with <code class="option">xmlpipe</code> source
        type (it's suggested to upgrade to xmlpipe2 anyway). It should work
        with properly formed HTML and XHTML, but, just as most browsers, may
        produce unexpected results on malformed input (such as HTML with stray
        &lt;'s or unclosed &gt;'s).</p><p>Only the tags themselves, and also HTML comments, are stripped.
        To strip the contents of the tags too (eg. to strip embedded scripts),
        see <a class="link" href="#conf-html-remove-elements" title="11.2.29.&nbsp;html_remove_elements">html_remove_elements</a>
        option. There are no restrictions on tag names; ie. everything that
        looks like a valid tag start, or end, or a comment will be
        stripped.</p><h4>Example:</h4><pre class="programlisting">html_strip = 1
</pre></div>
<div class="sect2" title="11.2.28.&nbsp;html_index_attrs"><div class="titlepage"><div><div><h3 class="title"><a name="conf-html-index-attrs"></a>11.2.28.&nbsp;html_index_attrs</h3></div></div></div>
<p>A list of markup attributes to index when stripping HTML.
        Optional, default is empty (do not index markup attributes).</p><p>Specifies HTML markup attributes whose contents should be
        retained and indexed even though other HTML markup is stripped. The
        format is per-tag enumeration of indexable attributes, as shown in the
        example below.</p><h4>Example:</h4><pre class="programlisting">html_index_attrs = img=alt,title; a=title;
</pre></div>
<div class="sect2" title="11.2.29.&nbsp;html_remove_elements"><div class="titlepage"><div><div><h3 class="title"><a name="conf-html-remove-elements"></a>11.2.29.&nbsp;html_remove_elements</h3></div></div></div>
<p>A list of HTML elements for which to strip contents along with
        the elements themselves. Optional, default is empty string (do not
        strip contents of any elements).</p><p>This feature allows to strip element contents, ie. everything
        that is between the opening and the closing tags. It is useful to
        remove embedded scripts, CSS, etc. Short tag form for empty elements
        (ie. &lt;br /&gt;) is properly supported; ie. the text that follows
        such tag will <span class="bold"><strong>not</strong></span> be removed.</p><p>The value is a comma-separated list of element (tag) names whose
        contents should be removed. Tag names are case insensitive.</p><h4>Example:</h4><pre class="programlisting">html_remove_elements = style, script
</pre></div>
<div class="sect2" title="11.2.30.&nbsp;local"><div class="titlepage"><div><div><h3 class="title"><a name="conf-local"></a>11.2.30.&nbsp;local</h3></div></div></div>
<p>Local index declaration in the <a class="link" href="#distributed" title="5.8.&nbsp;Distributed searching">distributed index</a>. Multi-value, optional,
        default is empty.</p><p>This setting is used to declare local indexes that will be
        searched when given distributed index is searched. All local indexes
        will be searched <span class="bold"><strong>sequentially</strong></span>, utilizing only 1 CPU or core; to
        parallelize processing, you can configure <code class="filename">searchd</code>
        to query itself (refer to <a class="xref" href="#conf-agent" title="11.2.31.&nbsp;agent">Section&nbsp;11.2.31, “agent”</a> for the
        details). There might be several local indexes declared per each
        distributed index. Any local index can be mentioned several times in
        other distributed indexes.</p><h4>Example:</h4><pre class="programlisting">local = chunk1
local = chunk2
</pre></div>
<div class="sect2" title="11.2.31.&nbsp;agent"><div class="titlepage"><div><div><h3 class="title"><a name="conf-agent"></a>11.2.31.&nbsp;agent</h3></div></div></div>
<p>Remote agent declaration in the <a class="link" href="#distributed" title="5.8.&nbsp;Distributed searching">distributed index</a>. Multi-value, optional,
        default is empty.</p><p>This setting is used to declare remote agents that will be
        searched when given distributed index is searched. The agents can be
        thought of as network pointers that specify host, port, and index
        names. In the basic case agents would correspond to remote physical
        machines. More formally, that is not always correct: you can point
        several agents to the same remote machine; or you can even point
        agents to the very same single instance of
        <code class="filename">searchd</code> (in order to utilize many CPUs or
        cores).</p><p>The value format is as follows: </p><pre class="programlisting">agent = specification:remote-indexes-list
specification = hostname ":" port | path
</pre><p> Where 'hostname' is remote host name; 'port' is remote TCP
        port; 'path' is Unix-domain socket path and 'remote-indexes-list' is a
        comma-separated list of remote index names.</p><p>All agents will be searched in parallel. However, all indexes
        specified for a given agent will be searched sequentially in this
        agent. This lets you fine-tune the configuration to the hardware. For
        instance, if two remote indexes are stored on the same physical HDD,
        it's better to configure one agent with several sequentially searched
        indexes to avoid HDD steping. If they are stored on different HDDs,
        having two agents will be advantageous, because the work will be fully
        parallelized. The same applies to CPUs; though CPU performance impact
        caused by two processes stepping on each other is somewhat smaller and
        frequently can be ignored at all.</p><p>On machines with many CPUs and/or HDDs, agents can be pointed to
        the same machine to utilize all of the hardware in parallel and reduce
        query latency. There is no need to setup several
        <code class="filename">searchd</code> instances for that; it's legal to
        configure the instance to contact itself. Here's an example setup,
        intended for a 4-CPU machine, that will use up to 4 CPUs in parallel
        to process each query: </p><pre class="programlisting">index dist
{
	type = distributed
	local = chunk1
	agent = localhost:9312:chunk2
	agent = localhost:9312:chunk3
	agent = localhost:9312:chunk4
}
</pre><p> Note how one of the chunks is searched locally and the same
        instance of searchd queries itself to launch searches through three
        other ones in parallel.</p><h4>Example:</h4><pre class="programlisting">agent = localhost:9312:chunk2 # contact itself
agent = /var/run/searchd.s:chunk2
agent = searchbox2:9312:chunk3,chunk4 # search remote indexes
</pre></div>
<div class="sect2" title="11.2.32.&nbsp;agent_blackhole"><div class="titlepage"><div><div><h3 class="title"><a name="conf-agent-blackhole"></a>11.2.32.&nbsp;agent_blackhole</h3></div></div></div>
<p>Remote blackhole agent declaration in the <a class="link" href="#distributed" title="5.8.&nbsp;Distributed searching">distributed index</a>. Multi-value, optional,
        default is empty. Introduced in version 0.9.9-rc1.</p><p><code class="option">agent_blackhole</code> lets you fire-and-forget
        queries to remote agents. That is useful for debugging (or just
        testing) production clusters: you can setup a separate
        debugging/testing searchd instance, and forward the requests to this
        instance from your production master (aggregator) instance without
        interfering with production work. Master searchd will attempt to
        connect and query blackhole agent normally, but it will neither wait
        nor process any responses. Also, all network errors on blackhole
        agents will be ignored. The value format is completely identical to
        regular <a class="link" href="#conf-agent" title="11.2.31.&nbsp;agent">agent</a> directive.</p><h4>Example:</h4><pre class="programlisting">agent_blackhole = testbox:9312:testindex1,testindex2
</pre></div>
<div class="sect2" title="11.2.33.&nbsp;agent_connect_timeout"><div class="titlepage"><div><div><h3 class="title"><a name="conf-agent-connect-timeout"></a>11.2.33.&nbsp;agent_connect_timeout</h3></div></div></div>
<p>Remote agent connection timeout, in milliseconds. Optional,
        default is 1000 (ie. 1 second).</p><p>When connecting to remote agents, <code class="filename">searchd</code>
        will wait at most this much time for connect() call to complete
        succesfully. If the timeout is reached but connect() does not
        complete, and <a class="link" href="#api-func-setretries" title="8.1.4.&nbsp;SetRetries">retries</a> are
        enabled, retry will be initiated.</p><h4>Example:</h4><pre class="programlisting">agent_connect_timeout = 300
</pre></div>
<div class="sect2" title="11.2.34.&nbsp;agent_query_timeout"><div class="titlepage"><div><div><h3 class="title"><a name="conf-agent-query-timeout"></a>11.2.34.&nbsp;agent_query_timeout</h3></div></div></div>
<p>Remote agent query timeout, in milliseconds. Optional, default
        is 3000 (ie. 3 seconds).</p><p>After connection, <code class="filename">searchd</code> will wait at most
        this much time for remote queries to complete. This timeout is fully
        separate from connection timeout; so the maximum possible delay caused
        by a remote agent equals to the sum of
        <code class="code">agent_connection_timeout</code> and
        <code class="code">agent_query_timeout</code>. Queries will <span class="bold"><strong>not</strong></span> be retried
        if this timeout is reached; a warning will be produced instead.</p><h4>Example:</h4><pre class="programlisting">agent_query_timeout = 10000 # our query can be long, allow up to 10 sec
</pre></div>
<div class="sect2" title="11.2.35.&nbsp;preopen"><div class="titlepage"><div><div><h3 class="title"><a name="conf-preopen"></a>11.2.35.&nbsp;preopen</h3></div></div></div>
<p>Whether to pre-open all index files, or open them per each
        query. Optional, default is 0 (do not preopen).</p><p>This option tells <code class="filename">searchd</code> that it should
        pre-open all index files on startup (or rotation) and keep them open
        while it runs. Currently, the default mode is <span class="bold"><strong>not</strong></span> to pre-open
        the files (this may change in the future). Preopened indexes take a
        few (currently 2) file descriptors per index. However, they save on
        per-query <code class="code">open()</code> calls; and also they are invulnerable to
        subtle race conditions that may happen during index rotation under
        high load. On the other hand, when serving many indexes (100s to
        1000s), it still might be desired to open the on per-query basis in
        order to save file descriptors.</p><p>This directive does not affect <code class="filename">indexer</code> in
        any way, it only affects <code class="filename">searchd</code>.</p><h4>Example:</h4><pre class="programlisting">preopen = 1
</pre></div>
<div class="sect2" title="11.2.36.&nbsp;ondisk_dict"><div class="titlepage"><div><div><h3 class="title"><a name="conf-ondisk-dict"></a>11.2.36.&nbsp;ondisk_dict</h3></div></div></div>
<p>Whether to keep the dictionary file (.spi) for this index on
        disk, or precache it in RAM. Optional, default is 0 (precache in RAM).
        Introduced in version 0.9.9-rc1.</p><p>The dictionary (.spi) can be either kept on RAM or on disk. The
        default is to fully cache it in RAM. That improves performance, but
        might cause too much RAM pressure, especially if prefixes or infixes
        were used. Enabling <code class="option">ondisk_dict</code> results in 1
        additional disk IO per keyword per query, but reduces memory
        footprint.</p><p>This directive does not affect <code class="filename">indexer</code> in
        any way, it only affects <code class="filename">searchd</code>.</p><h4>Example:</h4><pre class="programlisting">ondisk_dict = 1
</pre></div>
<div class="sect2" title="11.2.37.&nbsp;inplace_enable"><div class="titlepage"><div><div><h3 class="title"><a name="conf-inplace-enable"></a>11.2.37.&nbsp;inplace_enable</h3></div></div></div>
<p>Whether to enable in-place index inversion. Optional, default is
        0 (use separate temporary files). Introduced in version
        0.9.9-rc1.</p><p><code class="option">inplace_enable</code> greatly reduces indexing disk
        footprint, at a cost of slightly slower indexing (it uses around 2x
        less disk, but yields around 90-95% the original performance).</p><p>Indexing involves two major phases. The first phase collects,
        processes, and partially sorts documents by keyword, and writes the
        intermediate result to temporary files (.tmp*). The second phase fully
        sorts the documents, and creates the final index files. Thus,
        rebuilding a production index on the fly involves around 3x peak disk
        footprint: 1st copy for the intermediate temporary files, 2nd copy for
        newly constructed copy, and 3rd copy for the old index that will be
        serving production queries in the meantime. (Intermediate data is
        comparable in size to the final index.) That might be too much disk
        footprint for big data collections, and
        <code class="option">inplace_enable</code> allows to reduce it. When enabled, it
        reuses the temporary files, outputs the final data back to them, and
        renames them on completion. However, this might require additional
        temporary data chunk relocation, which is where the performance impact
        comes from.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">inplace_enable = 1
</pre></div>
<div class="sect2" title="11.2.38.&nbsp;inplace_hit_gap"><div class="titlepage"><div><div><h3 class="title"><a name="conf-inplace-hit-gap"></a>11.2.38.&nbsp;inplace_hit_gap</h3></div></div></div>
<p><a class="link" href="#conf-inplace-enable" title="11.2.37.&nbsp;inplace_enable">In-place inversion</a>
        fine-tuning option. Controls preallocated hitlist gap size. Optional,
        default is 0. Introduced in version 0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">inplace_hit_gap = 1M
</pre></div>
<div class="sect2" title="11.2.39.&nbsp;inplace_docinfo_gap"><div class="titlepage"><div><div><h3 class="title"><a name="conf-inplace-docinfo-gap"></a>11.2.39.&nbsp;inplace_docinfo_gap</h3></div></div></div>
<p><a class="link" href="#conf-inplace-enable" title="11.2.37.&nbsp;inplace_enable">In-place inversion</a>
        fine-tuning option. Controls preallocated docinfo gap size. Optional,
        default is 0. Introduced in version 0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">inplace_docinfo_gap = 1M
</pre></div>
<div class="sect2" title="11.2.40.&nbsp;inplace_reloc_factor"><div class="titlepage"><div><div><h3 class="title"><a name="conf-inplace-reloc-factor"></a>11.2.40.&nbsp;inplace_reloc_factor</h3></div></div></div>
<p><a class="link" href="#conf-inplace-reloc-factor" title="11.2.40.&nbsp;inplace_reloc_factor">In-place
        inversion</a> fine-tuning option. Controls relocation buffer size
        within indexing memory arena. Optional, default is 0.1. Introduced in
        version 0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">inplace_reloc_factor = 0.1
</pre></div>
<div class="sect2" title="11.2.41.&nbsp;inplace_write_factor"><div class="titlepage"><div><div><h3 class="title"><a name="conf-inplace-write-factor"></a>11.2.41.&nbsp;inplace_write_factor</h3></div></div></div>
<p><a class="link" href="#conf-inplace-write-factor" title="11.2.41.&nbsp;inplace_write_factor">In-place
        inversion</a> fine-tuning option. Controls in-place write buffer
        size within indexing memory arena. Optional, default is 0.1.
        Introduced in version 0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">inplace_write_factor = 0.1
</pre></div>
<div class="sect2" title="11.2.42.&nbsp;index_exact_words"><div class="titlepage"><div><div><h3 class="title"><a name="conf-index-exact-words"></a>11.2.42.&nbsp;index_exact_words</h3></div></div></div>
<p>Whether to index the original keywords along with the
        stemmed/remapped versions. Optional, default is 0 (do not index).
        Introduced in version 0.9.9-rc1.</p><p>When enabled, <code class="option">index_exact_words</code> forces
        <code class="filename">indexer</code> to put the raw keywords in the index
        along with the stemmed versions. That, in turn, enables <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">exact form operator</a> in the query
        language to work. This impacts the index size and the indexing time.
        However, searching performance is not impacted at all.</p><h4>Example:</h4><pre class="programlisting">index_exact_words = 1
</pre></div>
<div class="sect2" title="11.2.43.&nbsp;overshort_step"><div class="titlepage"><div><div><h3 class="title"><a name="conf-overshort-step"></a>11.2.43.&nbsp;overshort_step</h3></div></div></div>
<p>Position increment on overshort (less that <a class="link" href="#conf-min-word-len" title="11.2.14.&nbsp;min_word_len">min_word_len</a>) keywords. Optional,
        allowed values are 0 and 1, default is 1. Introduced in version
        0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">overshort_step = 1
</pre></div>
<div class="sect2" title="11.2.44.&nbsp;stopword_step"><div class="titlepage"><div><div><h3 class="title"><a name="conf-stopword-step"></a>11.2.44.&nbsp;stopword_step</h3></div></div></div>
<p>Position increment on <a class="link" href="#conf-stopwords" title="11.2.11.&nbsp;stopwords">stopwords</a>. Optional, allowed values
        are 0 and 1, default is 1. Introduced in version 0.9.9-rc1.</p><p>This directive does not affect <code class="filename">searchd</code> in
        any way, it only affects <code class="filename">indexer</code>.</p><h4>Example:</h4><pre class="programlisting">stopword_step = 1
</pre></div>
<div class="sect2" title="11.2.45.&nbsp;hitless_words"><div class="titlepage"><div><div><h3 class="title"><a name="conf-hitless-words"></a>11.2.45.&nbsp;hitless_words</h3></div></div></div>
<p>Hitless words list. Optional, allowed values are 'all', or a
        list file name. Introduced in version 1.10-beta.</p><p>By default, Sphinx full-text index stores not only a list of
        matching documents for every given keyword, but also a list of its
        in-document positions (aka hitlist). Hitlists enables phrase,
        proximity, strict order and other advanced types of searching, as well
        as phrase proximity ranking. However, hitlists for specific frequent
        keywords (that can not be stopped for some reason despite being
        frequent) can get huge and thus slow to process while querying. Also,
        in some cases we might only care about boolean keyword matching, and
        never need position-based searching operators (such as phrase
        matching) nor phrase ranking.</p><p><code class="option">hitless_words</code> lets you create indexes that
        either do not have positional information (hitlists) at all, or skip
        it for specific keywords.</p><p>Hitless index will generally use less space than the respective
        regular index (about 1.5x can be expected). Both indexing and
        searching should be faster, at a cost of missing positional query and
        ranking support. When searching, positional queries (eg. phrase
        queries) will be automatically converted to respective non-positional
        (document-level) or combined queries. For instance, if keywords
        "hello" and "world" are hitless, "hello world" phrase query will be
        converted to (hello &amp; world) bag-of-words query, matching all
        documents that mention either of the keywords but not necessarily the
        exact phrase. And if, in addition, keywords "simon" and "says" are not
        hitless, "simon says hello world" will be converted to ("simon says"
        &amp; hello &amp; world) query, matching all documents that contain
        "hello" and "world" anywhere in the document, and also "simon says" as
        an exact phrase.</p><h4>Example:</h4><pre class="programlisting">hitless_words = all
</pre></div>
<div class="sect2" title="11.2.46.&nbsp;expand_keywords"><div class="titlepage"><div><div><h3 class="title"><a name="conf-expand-keywords"></a>11.2.46.&nbsp;expand_keywords</h3></div></div></div>
<p>Expand keywords with exact forms and/or stars when possible.
        Optional, default is 0 (do not expand keywords). Introduced in version
        1.10-beta.</p><p>Queries against indexes with <code class="option">expand_keywords</code>
        feature enabled are internally expanded as follows. If the index was
        built with prefix or infix indexing enabled, every keyword gets
        internally replaced with a disjunction of keyword itself and a
        respective prefix or infix (keyword with stars). If the index was
        built with both stemming and <a class="link" href="#conf-index-exact-words" title="11.2.42.&nbsp;index_exact_words">index_exact_words</a> enabled,
        exact form is also added. Here's an example that shows how internal
        expansion works when all of the above (infixes, stemming, and exact
        words) are combined: </p><pre class="programlisting">running -&gt; ( running | *running* | =running )
</pre><p>Expanded queries take naturally longer to complete, but can
        possibly improve the search quality, as the documents with exact form
        matches should be ranked generally higher than documents with stemmed
        or infix matches.</p><p>Note that the existing query syntax does not allowe to emulate
        this kind of expansion, because internal expansion works on keyword
        level and expands keywords within phrase or quorum operators too
        (which is not possible through the query syntax).</p><p>This directive does not affect <code class="filename">indexer</code> in
        any way, it only affects <code class="filename">searchd</code>.</p><h4>Example:</h4><pre class="programlisting">expand_keywords = 1
</pre></div>
<div class="sect2" title="11.2.47.&nbsp;blend_chars"><div class="titlepage"><div><div><h3 class="title"><a name="conf-blend-chars"></a>11.2.47.&nbsp;blend_chars</h3></div></div></div>
<p>Blended characters list. Optional, default is empty. Introduced
        in version 1.10-beta.</p><p>Blended characters are indexed both as separators and valid
        characters. For instance, assume that &amp; is configured as blended
        and AT&amp;T occurs in an indexed document. Three different keywords
        will get indexed, namely "at&amp;t", treating blended characters as
        valid, plus "at" and "t", treating them as separators.</p><p>Positions for tokens obtained by replacing blended characters
        with whitespace are assigned as usual, so regular keywords will be
        indexed just as if there was no <code class="option">blend_chars</code> specified
        at all. An additional token that mixes blended and non-blended
        characters will be put at the starting position. For instance, if the
        field contents are "AT&amp;T company" occurs in the very beginning of
        the text field, "at" will be given position 1, "t" position 2,
        "company" positin 3, and "AT&amp;T" will also be given position 1
        ("blending" with the opening regular keyword). Thus, querying for
        either AT&amp;T or just AT will match that document, and querying for
        "AT T" as a phrase also match it. Last but not least, phrase query for
        "AT&amp;T company" will <span class="emphasis"><em>also</em></span> match it, despite
        the position</p><p>Blended characters can overlap with special characters used in
        query syntax (think of T-Mobile or @twitter). Where possible, query
        parser will automatically handle blended character as blended. For
        instance, "hello @twitter" within quotes (a phrase operator) would
        handle @-sign as blended, because @-syntax for field operator is not
        allowed within phrases. Otherwise, the character would be handled as
        an operator. So you might want to escape the keywords.</p><p>Starting with version 2.0.1-beta, blended characters can be
        remapped, so that multiple different blended characters could be
        normalized into just one base form. This is useful when indexing
        multiple alternative Unicode codepoints with equivalent glyphs.</p><h4>Example:</h4><pre class="programlisting">blend_chars = +, &amp;, U+23
blend_chars = +, &amp;-&gt;+ # 2.0.1 and above
</pre></div>
<div class="sect2" title="11.2.48.&nbsp;blend_mode"><div class="titlepage"><div><div><h3 class="title"><a name="conf-blend-mode"></a>11.2.48.&nbsp;blend_mode</h3></div></div></div>
<p>Blended tokens indexing mode. Optional, default is
        <code class="option">trim_none</code>. Introduced in version 2.0.1-beta.</p><p>By default, tokens that mix blended and non-blended characters
        get indexed in there entirety. For instance, when both at-sign and an
        exclamation are in <code class="option">blend_chars</code>, "@dude!" will get
        result in two tokens indexed: "@dude!" (with all the blended
        characters) and "dude" (without any). Therefore "@dude" query will
        <span class="emphasis"><em>not</em></span> match it.</p><p><code class="option">blend_mode</code> directive adds flexibility to this
        indexing behavior. It takes a comma-separated list of options.
        </p><pre class="programlisting">blend_mode = option [, option [, ...]]
option = trim_none | trim_head | trim_tail | trim_both | skip_pure
</pre><p>Options specify token indexing variants. If multiple options are
        specified, multiple variants of the same token will be indexed.
        Regular keywords (resulting from that token by replacing blended with
        whitespace) are always be indexed. </p><div class="variablelist"><dl><dt><span class="term">trim_none</span></dt>
<dd><p>Index the entire token.</p></dd><dt><span class="term">trim_head</span></dt>
<dd><p>Trim heading blended characters, and index the resulting
                token.</p></dd><dt><span class="term">trim_tail</span></dt>
<dd><p>Trim trailing blended characters, and index the
                resulting token.</p></dd><dt><span class="term">trim_both</span></dt>
<dd><p>Trim both heading and trailing blended characters, and
                index the resulting token.</p></dd><dt><span class="term">skip_pure</span></dt>
<dd><p>Do not index the token if it's purely blended, that is,
                consists of blended characters only.</p></dd></dl></div>
<p> Returning to the "@dude!" example above, setting
        <code class="option">blend_mode = trim_head, trim_tail</code> will result in two
        tokens being indexed, "@dude" and "dude!". In this particular example,
        <code class="option">trim_both</code> would have no effect, because trimming both
        blended characters results in "dude" which is already indexed as a
        regular keyword. Indexing "@U.S.A." with <code class="option">trim_both</code>
        (and assuming that dot is blended two) would result in "U.S.A" being
        indexed. Last but not least, <code class="option">skip_pure</code> enables you to
        fully ignore sequences of blended characters only. For example, "one
        @@@ two" would be indexed exactly as "one two", and match that as a
        phrase. That is not the case by default because a fully blended token
        gets indexed and offsets the second keyword position.</p><p>Default behavior is to index the entire token, equivalent to
        <code class="option">blend_mode = trim_none</code>.</p><h4>Example:</h4><pre class="programlisting">blend_mode = trim_tail, skip_pure
</pre></div>
<div class="sect2" title="11.2.49.&nbsp;rt_mem_limit"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-mem-limit"></a>11.2.49.&nbsp;rt_mem_limit</h3></div></div></div>
<p>RAM chunk size limit. Optional, default is empty. Introduced in
        version 1.10-beta.</p><p>RT index keeps some data in memory (so-called RAM chunk) and
        also maintains a number of on-disk indexes (so-called disk chunks).
        This directive lets you control the RAM chunk size. Once there's too
        much data to keep in RAM, RT index will flush it to disk, activate a
        newly created disk chunk, and reset the RAM chunk.</p><p>The limit is pretty strict; RT index should never allocate more
        memory than it's limited to. The memory is not preallocated either,
        hence, specifying 512 MB limit and only inserting 3 MB of data should
        result in allocating 3 MB, not 512 MB.</p><p></p><h4>Example:</h4><pre class="programlisting">rt_mem_limit = 512M
</pre></div>
<div class="sect2" title="11.2.50.&nbsp;rt_field"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-field"></a>11.2.50.&nbsp;rt_field</h3></div></div></div>
<p>Full-text field declaration. Multi-value, mandatory Introduced
        in version 1.10-beta.</p><p>Full-text fields to be indexed are declared using
        <code class="option">rt_field</code> directive. The names must be unique. The
        order is preserved; and so field values in INSERT statements without
        an explicit list of inserted columns will have to be in the same order
        as configured.</p><p></p><h4>Example:</h4><pre class="programlisting">rt_field = author
rt_field = title
rt_field = content
</pre></div>
<div class="sect2" title="11.2.51.&nbsp;rt_attr_uint"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-attr-uint"></a>11.2.51.&nbsp;rt_attr_uint</h3></div></div></div>
<p>Unsigned integer attribute declaration. Multi-value (an
        arbitrary number of attributes is allowed), optional. Declares an
        unsigned 32-bit attribute. Introduced in version 1.10-beta.</p><h4>Example:</h4><pre class="programlisting">rt_attr_uint = gid
</pre></div>
<div class="sect2" title="11.2.52.&nbsp;rt_attr_bigint"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-attr-bigint"></a>11.2.52.&nbsp;rt_attr_bigint</h3></div></div></div>
<p>BIGINT attribute declaration. Multi-value (an arbitrary number
        of attributes is allowed), optional. Declares a signed 64-bit
        attribute. Introduced in version 1.10-beta.</p><h4>Example:</h4><pre class="programlisting">rt_attr_bigint = guid
</pre></div>
<div class="sect2" title="11.2.53.&nbsp;rt_attr_float"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-attr-float"></a>11.2.53.&nbsp;rt_attr_float</h3></div></div></div>
<p>Floating point attribute declaration. Multi-value (an arbitrary
        number of attributes is allowed), optional. Declares a single
        precision, 32-bit IEEE 754 format float attribute. Introduced in
        version 1.10-beta.</p><h4>Example:</h4><pre class="programlisting">rt_attr_float = gpa
</pre></div>
<div class="sect2" title="11.2.54.&nbsp;rt_attr_timestamp"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-attr-timestamp"></a>11.2.54.&nbsp;rt_attr_timestamp</h3></div></div></div>
<p>Timestamp attribute declaration. Multi-value (an arbitrary
        number of attributes is allowed), optional. Introduced in version
        1.10-beta.</p><h4>Example:</h4><pre class="programlisting">rt_attr_timestamp = date_added
</pre></div>
<div class="sect2" title="11.2.55.&nbsp;rt_attr_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-attr-string"></a>11.2.55.&nbsp;rt_attr_string</h3></div></div></div>
<p>String attribute declaration. Multi-value (an arbitrary number
        of attributes is allowed), optional. Introduced in version
        1.10-beta.</p><h4>Example:</h4><pre class="programlisting">rt_attr_string = author
</pre></div></div>
<div class="sect1" title="11.3.&nbsp;indexer program configuration options"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="confgroup-indexer"></a>11.3.&nbsp;<code class="filename">indexer</code> program configuration
      options</h2></div></div></div>
<div class="sect2" title="11.3.1.&nbsp;mem_limit"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mem-limit"></a>11.3.1.&nbsp;mem_limit</h3></div></div></div>
<p>Indexing RAM usage limit. Optional, default is 32M.</p><p>Enforced memory usage limit that the
        <code class="filename">indexer</code> will not go above. Can be specified in
        bytes, or kilobytes (using K postfix), or megabytes (using M postfix);
        see the example. This limit will be automatically raised if set to
        extremely low value causing I/O buffers to be less than 8 KB; the
        exact lower bound for that depends on the indexed data size. If the
        buffers are less than 256 KB, a warning will be produced.</p><p>Maximum possible limit is 2047M. Too low values can hurt
        indexing speed, but 256M to 1024M should be enough for most if not all
        datasets. Setting this value too high can cause SQL server timeouts.
        During the document collection phase, there will be periods when the
        memory buffer is partially sorted and no communication with the
        database is performed; and the database server can timeout. You can
        resolve that either by raising timeouts on SQL server side or by
        lowering <code class="code">mem_limit</code>.</p><h4>Example:</h4><pre class="programlisting">mem_limit = 256M
# mem_limit = 262144K # same, but in KB
# mem_limit = 268435456 # same, but in bytes
</pre></div>
<div class="sect2" title="11.3.2.&nbsp;max_iops"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-iops"></a>11.3.2.&nbsp;max_iops</h3></div></div></div>
<p>Maximum I/O operations per second, for I/O throttling. Optional,
        default is 0 (unlimited).</p><p>I/O throttling related option. It limits maximum count of I/O
        operations (reads or writes) per any given second. A value of 0 means
        that no limit is imposed.</p><p><code class="filename">indexer</code> can cause bursts of intensive disk
        I/O during indexing, and it might desired to limit its disk activity
        (and keep something for other programs running on the same machine,
        such as <code class="filename">searchd</code>). I/O throttling helps to do
        that. It works by enforcing a minimum guaranteed delay between
        subsequent disk I/O operations performed by
        <code class="filename">indexer</code>. Modern SATA HDDs are able to perform up
        to 70-100+ I/O operations per second (that's mostly limited by disk
        heads seek time). Limiting indexing I/O to a fraction of that can help
        reduce search performance dedgradation caused by indexing.</p><h4>Example:</h4><pre class="programlisting">max_iops = 40
</pre></div>
<div class="sect2" title="11.3.3.&nbsp;max_iosize"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-iosize"></a>11.3.3.&nbsp;max_iosize</h3></div></div></div>
<p>Maximum allowed I/O operation size, in bytes, for I/O
        throttling. Optional, default is 0 (unlimited).</p><p>I/O throttling related option. It limits maximum file I/O
        operation (read or write) size for all operations performed by
        <code class="filename">indexer</code>. A value of 0 means that no limit is
        imposed. Reads or writes that are bigger than the limit will be split
        in several smaller operations, and counted as several operation by
        <a class="link" href="#conf-max-iops" title="11.3.2.&nbsp;max_iops">max_iops</a> setting. At the time of
        this writing, all I/O calls should be under 256 KB (default internal
        buffer size) anyway, so <code class="code">max_iosize</code> values higher than 256
        KB must not affect anything.</p><h4>Example:</h4><pre class="programlisting">max_iosize = 1048576
</pre></div>
<div class="sect2" title="11.3.4.&nbsp;max_xmlpipe2_field"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-xmlpipe2-field"></a>11.3.4.&nbsp;max_xmlpipe2_field</h3></div></div></div>
<p>Maximum allowed field size for XMLpipe2 source type, bytes.
        Optional, default is 2 MB.</p><h4>Example:</h4><pre class="programlisting">max_xmlpipe2_field = 8M
</pre></div>
<div class="sect2" title="11.3.5.&nbsp;write_buffer"><div class="titlepage"><div><div><h3 class="title"><a name="conf-write-buffer"></a>11.3.5.&nbsp;write_buffer</h3></div></div></div>
<p>Write buffer size, bytes. Optional, default is 1 MB.</p><p>Write buffers are used to write both temporary and final index
        files when indexing. Larger buffers reduce the number of required disk
        writes. Memory for the buffers is allocated in addition to <a class="link" href="#conf-mem-limit" title="11.3.1.&nbsp;mem_limit">mem_limit</a>. Note that several
        (currently up to 4) buffers for different files will be allocated,
        proportionally increasing the RAM usage.</p><h4>Example:</h4><pre class="programlisting">write_buffer = 4M
</pre></div>
<div class="sect2" title="11.3.6.&nbsp;max_file_field_buffer"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-file-field-buffer"></a>11.3.6.&nbsp;max_file_field_buffer</h3></div></div></div>
<p>Maximum file field adaptive buffer size, bytes. Optional,
        default is 8 MB, minimum is 1 MB.</p><p>File field buffer is used to load files referred to from <a class="link" href="#conf-sql-file-field" title="11.1.29.&nbsp;sql_file_field">sql_file_field</a> columns. This
        buffer is adaptive, starting at 1 MB at first allocation, and growing
        in 2x steps until either file contents can be loaded, or maximum
        buffer size, specified by <code class="option">max_file_field_buffer</code>
        directive, is reached.</p><p>Thus, if there are no file fields are specified, no buffer is
        allocated at all. If all files loaded during indexing are under (for
        example) 2 MB in size, but <code class="option">max_file_field_buffer</code>
        value is 128 MB, peak buffer usage would still be only 2 MB. However,
        files over 128 MB would be entirely skipped.</p><h4>Example:</h4><pre class="programlisting">max_file_field_buffer = 128M
</pre></div></div>
<div class="sect1" title="11.4.&nbsp;searchd program configuration options"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="confgroup-searchd"></a>11.4.&nbsp;<code class="filename">searchd</code> program configuration
      options</h2></div></div></div>
<div class="sect2" title="11.4.1.&nbsp;listen"><div class="titlepage"><div><div><h3 class="title"><a name="conf-listen"></a>11.4.1.&nbsp;listen</h3></div></div></div>
<p>This setting lets you specify IP address and port, or
        Unix-domain socket path, that <code class="code">searchd</code> will listen on.
        Introduced in version 0.9.9-rc1.</p><p>The informal grammar for <code class="code">listen</code> setting is:
        </p><pre class="programlisting">listen = ( address ":" port | port | path ) [ ":" protocol ]
</pre><p> I.e. you can specify either an IP address (or hostname) and
        port number, or just a port number, or Unix socket path. If you
        specify port number but not the address, <code class="code">searchd</code> will
        listen on all network interfaces. Unix path is identified by a leading
        slash.</p><p>Starting with version 0.9.9-rc2, you can also specify a protocol
        handler (listener) to be used for connections on this socket.
        Supported protocol values are 'sphinx' (Sphinx 0.9.x API protocol) and
        'mysql41' (MySQL protocol used since 4.1 upto at least 5.1). More
        details on MySQL protocol support can be found in <a class="xref" href="#sphinxql" title="5.10.&nbsp;MySQL protocol support and SphinxQL">Section&nbsp;5.10, “MySQL protocol support and SphinxQL”</a> section.</p><h4>Examples:</h4><pre class="programlisting">listen = localhost
listen = localhost:5000
listen = 192.168.0.1:5000
listen = /var/run/sphinx.s
listen = 9312
listen = localhost:9306:mysql41
</pre><p>There can be multiple listen directives, <code class="code">searchd</code>
        will listen for client connections on all specified ports and sockets.
        If no <code class="code">listen</code> directives are found then the server will
        listen on all available interfaces using the default SphinxAPI port
        9312. Starting with 1.10-beta, it will also listen on default SphinxQL
        port 9306. Both port numbers are assigned by IANA (see <a class="ulink" href="http://www.iana.org/assignments/port-numbers" target="_top">http://www.iana.org/assignments/port-numbers</a>
        for details) and should therefore be available.</p><p>Unix-domain sockets are not supported on Windows.</p></div>
<div class="sect2" title="11.4.2.&nbsp;address"><div class="titlepage"><div><div><h3 class="title"><a name="conf-address"></a>11.4.2.&nbsp;address</h3></div></div></div>
<p>Interface IP address to bind on. Optional, default is 0.0.0.0
        (ie. listen on all interfaces). <span class="bold"><strong>DEPRECATED</strong></span>, use <a class="link" href="#conf-listen" title="11.4.1.&nbsp;listen">listen</a> instead.</p><p><code class="code">address</code> setting lets you specify which network
        interface <code class="filename">searchd</code> will bind to, listen on, and
        accept incoming network connections on. The default value is 0.0.0.0
        which means to listen on all interfaces. At the time, you can
        <span class="bold"><strong>not</strong></span> specify multiple interfaces.</p><h4>Example:</h4><pre class="programlisting">address = 192.168.0.1
</pre></div>
<div class="sect2" title="11.4.3.&nbsp;port"><div class="titlepage"><div><div><h3 class="title"><a name="conf-port"></a>11.4.3.&nbsp;port</h3></div></div></div>
<p><code class="filename">searchd</code> TCP port number. <span class="bold"><strong>DEPRECATED</strong></span>,
        use <a class="link" href="#conf-listen" title="11.4.1.&nbsp;listen">listen</a> instead. Used to be
        mandatory. Default port number is 9312.</p><h4>Example:</h4><pre class="programlisting">port = 9312
</pre></div>
<div class="sect2" title="11.4.4.&nbsp;log"><div class="titlepage"><div><div><h3 class="title"><a name="conf-log"></a>11.4.4.&nbsp;log</h3></div></div></div>
<p>Log file name. Optional, default is 'searchd.log'. All
        <code class="filename">searchd</code> run time events will be logged in this
        file.</p><p>Also you can use the 'syslog' as the file name. In this case the
        events will be sent to syslog daemon. To use the syslog option the
        sphinx must be configured '--with-syslog' on building.</p><h4>Example:</h4><pre class="programlisting">log = /var/log/searchd.log
</pre></div>
<div class="sect2" title="11.4.5.&nbsp;query_log"><div class="titlepage"><div><div><h3 class="title"><a name="conf-query-log"></a>11.4.5.&nbsp;query_log</h3></div></div></div>
<p>Query log file name. Optional, default is empty (do not log
        queries). All search queries will be logged in this file. The format
        is described in <a class="xref" href="#query-log-format" title="5.9.&nbsp;searchd query log formats">Section&nbsp;5.9, “<code class="filename">searchd</code> query log formats”</a>.</p><p>In case of 'plain' format, you can use the 'syslog' as the path
        to the log file. In this case all search queries will be sent to
        syslog daemon with LOG_INFO priority, prefixed with '[query]' instead
        of timestamp. To use the syslog option the sphinx must be configured
        '--with-syslog' on building.</p><h4>Example:</h4><pre class="programlisting">query_log = /var/log/query.log
</pre></div>
<div class="sect2" title="11.4.6.&nbsp;query_log_format"><div class="titlepage"><div><div><h3 class="title"><a name="conf-query-log-format"></a>11.4.6.&nbsp;query_log_format</h3></div></div></div>
<p>Query log format. Optional, allowed values are 'plain' and
        'sphinxql', default is 'plain'. Introduced in version
        2.0.1-beta.</p><p>Starting with version 2.0.1-beta, two different log formats are
        supported. The default one logs queries in a custom text format. The
        new one logs valid SphinxQL statements. This directive allows to
        switch between the two formats on search daemon startup. The log
        format can also be altered on the fly, using <code class="code">SET GLOBAL
        query_log_format=sphinxql</code> syntax. Refer to <a class="xref" href="#query-log-format" title="5.9.&nbsp;searchd query log formats">Section&nbsp;5.9, “<code class="filename">searchd</code> query log formats”</a> for more discussion and format
        details.</p><h4>Example:</h4><pre class="programlisting">query_log_format = sphinxql
</pre></div>
<div class="sect2" title="11.4.7.&nbsp;read_timeout"><div class="titlepage"><div><div><h3 class="title"><a name="conf-read-timeout"></a>11.4.7.&nbsp;read_timeout</h3></div></div></div>
<p>Network client request read timeout, in seconds. Optional,
        default is 5 seconds. <code class="filename">searchd</code> will forcibly close
        the client connections which fail to send a query within this
        timeout.</p><h4>Example:</h4><pre class="programlisting">read_timeout = 1
</pre></div>
<div class="sect2" title="11.4.8.&nbsp;client_timeout"><div class="titlepage"><div><div><h3 class="title"><a name="conf-client-timeout"></a>11.4.8.&nbsp;client_timeout</h3></div></div></div>
<p>Maximum time to wait between requests (in seconds) when using
        persistent connections. Optional, default is five minutes.</p><h4>Example:</h4><pre class="programlisting">client_timeout = 3600
</pre></div>
<div class="sect2" title="11.4.9.&nbsp;max_children"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-children"></a>11.4.9.&nbsp;max_children</h3></div></div></div>
<p>Maximum amount of children to fork (or in other words,
        concurrent searches to run in parallel). Optional, default is 0
        (unlimited).</p><p>Useful to control server load. There will be no more than this
        much concurrent searches running, at all times. When the limit is
        reached, additional incoming clients are dismissed with temporarily
        failure (SEARCHD_RETRY) status code and a message stating that the
        server is maxed out.</p><h4>Example:</h4><pre class="programlisting">max_children = 10
</pre></div>
<div class="sect2" title="11.4.10.&nbsp;pid_file"><div class="titlepage"><div><div><h3 class="title"><a name="conf-pid-file"></a>11.4.10.&nbsp;pid_file</h3></div></div></div>
<p><code class="filename">searchd</code> process ID file name.
        Mandatory.</p><p>PID file will be re-created (and locked) on startup. It will
        contain head daemon process ID while the daemon is running, and it
        will be unlinked on daemon shutdown. It's mandatory because Sphinx
        uses it internally for a number of things: to check whether there
        already is a running instance of <code class="filename">searchd</code>; to stop
        <code class="filename">searchd</code>; to notify it that it should rotate the
        indexes. Can also be used for different external automation
        scripts.</p><h4>Example:</h4><pre class="programlisting">pid_file = /var/run/searchd.pid
</pre></div>
<div class="sect2" title="11.4.11.&nbsp;max_matches"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-matches"></a>11.4.11.&nbsp;max_matches</h3></div></div></div>
<p>Maximum amount of matches that the daemon keeps in RAM for each
        index and can return to the client. Optional, default is 1000.</p><p>Introduced in order to control and limit RAM usage,
        <code class="code">max_matches</code> setting defines how much matches will be kept
        in RAM while searching each index. Every match found will still be
        <span class="emphasis"><em>processed</em></span>; but only best N of them will be kept
        in memory and return to the client in the end. Assume that the index
        contains 2,000,000 matches for the query. You rarely (if ever) need to
        retrieve <span class="emphasis"><em>all</em></span> of them. Rather, you need to scan
        all of them, but only choose "best" at most, say, 500 by some criteria
        (ie. sorted by relevance, or price, or anything else), and display
        those 500 matches to the end user in pages of 20 to 100 matches. And
        tracking only the best 500 matches is much more RAM and CPU efficient
        than keeping all 2,000,000 matches, sorting them, and then discarding
        everything but the first 20 needed to display the search results page.
        <code class="code">max_matches</code> controls N in that "best N" amount.</p><p>This parameter noticeably affects per-query RAM and CPU usage.
        Values of 1,000 to 10,000 are generally fine, but higher limits must
        be used with care. Recklessly raising <code class="code">max_matches</code> to
        1,000,000 means that <code class="filename">searchd</code> will have to
        allocate and initialize 1-million-entry matches buffer for
        <span class="emphasis"><em>every</em></span> query. That will obviously increase
        per-query RAM usage, and in some cases can also noticeably impact
        performance.</p><p><span class="bold"><strong>CAVEAT EMPTOR!</strong></span> Note that there also is <span class="bold"><strong>another</strong></span>
        place where this limit is enforced. <code class="code">max_matches</code> can be
        decreased on the fly through the <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">corresponding API call</a>, and the
        default value in the API is <span class="bold"><strong>also</strong></span> set to 1,000. So in order to
        retrieve more than 1,000 matches to your application, you will have to
        change the configuration file, restart searchd, and set proper limit
        in <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a> call. Also
        note that you can not set the value in the API higher than the value
        in the .conf file. This is prohibited in order to have some protection
        against malicious and/or malformed requests.</p><h4>Example:</h4><pre class="programlisting">max_matches = 10000
</pre></div>
<div class="sect2" title="11.4.12.&nbsp;seamless_rotate"><div class="titlepage"><div><div><h3 class="title"><a name="conf-seamless-rotate"></a>11.4.12.&nbsp;seamless_rotate</h3></div></div></div>
<p>Prevents <code class="filename">searchd</code> stalls while rotating
        indexes with huge amounts of data to precache. Optional, default is 1
        (enable seamless rotation).</p><p>Indexes may contain some data that needs to be precached in RAM.
        At the moment, <code class="filename">.spa</code>, <code class="filename">.spi</code>
        and <code class="filename">.spm</code> files are fully precached (they contain
        attribute data, MVA data, and keyword index, respectively.) Without
        seamless rotate, rotating an index tries to use as little RAM as
        possible and works as follows: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>new queries are temporarly rejected (with "retry" error
              code);</p></li>
<li class="listitem"><p><code class="filename">searchd</code> waits for all currently
              running queries to finish;</p></li>
<li class="listitem"><p>old index is deallocated and its files are renamed;</p></li>
<li class="listitem"><p>new index files are renamed and required RAM is
              allocated;</p></li>
<li class="listitem"><p>new index attribute and dictionary data is preloaded to
              RAM;</p></li>
<li class="listitem"><p><code class="filename">searchd</code> resumes serving queries from
              new index.</p></li>
</ol></div>
<p>However, if there's a lot of attribute or dictionary data, then
        preloading step could take noticeble time - up to several minutes in
        case of preloading 1-5+ GB files.</p><p>With seamless rotate enabled, rotation works as follows:
        </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>new index RAM storage is allocated;</p></li>
<li class="listitem"><p>new index attribute and dictionary data is asynchronously
              preloaded to RAM;</p></li>
<li class="listitem"><p>on success, old index is deallocated and both indexes'
              files are renamed;</p></li>
<li class="listitem"><p>on failure, new index is deallocated;</p></li>
<li class="listitem"><p>at any given moment, queries are served either from old or
              new index copy.</p></li>
</ol></div>
<p>Seamless rotate comes at the cost of higher <span class="bold"><strong>peak</strong></span> memory usage during the rotation (because
        both old and new copies of <code class="filename">.spa/.spi/.spm</code> data
        need to be in RAM while preloading new copy). Average usage stays the
        same.</p><h4>Example:</h4><pre class="programlisting">seamless_rotate = 1
</pre></div>
<div class="sect2" title="11.4.13.&nbsp;preopen_indexes"><div class="titlepage"><div><div><h3 class="title"><a name="conf-preopen-indexes"></a>11.4.13.&nbsp;preopen_indexes</h3></div></div></div>
<p>Whether to forcibly preopen all indexes on startup. Optional,
        default is 1 (preopen everything).</p><p>Starting with 2.0.1-beta, the default value for this option is
        now 1 (foribly preopen all indexes). In prior versions, it used to be
        0 (use per-index settings).</p><p>When set to 1, this directive overrides and enforces <a class="link" href="#conf-preopen" title="11.2.35.&nbsp;preopen">preopen</a> on all indexes. They will be
        preopened, no matter what is the per-index <code class="code">preopen</code>
        setting. When set to 0, per-index settings can take effect. (And they
        default to 0.)</p><p>Pre-opened indexes avoid races between search queries and
        rotations that can cause queries to fail occasionally. They also make
        <code class="filename">searchd</code> use more file handles. In most scenarios
        it's therefore preferred and recommended to preopen indexes.</p><h4>Example:</h4><pre class="programlisting">preopen_indexes = 1
</pre></div>
<div class="sect2" title="11.4.14.&nbsp;unlink_old"><div class="titlepage"><div><div><h3 class="title"><a name="conf-unlink-old"></a>11.4.14.&nbsp;unlink_old</h3></div></div></div>
<p>Whether to unlink .old index copies on succesful rotation.
        Optional, default is 1 (do unlink).</p><h4>Example:</h4><pre class="programlisting">unlink_old = 0
</pre></div>
<div class="sect2" title="11.4.15.&nbsp;attr_flush_period"><div class="titlepage"><div><div><h3 class="title"><a name="conf-attr-flush-period"></a>11.4.15.&nbsp;attr_flush_period</h3></div></div></div>
<p>When calling <code class="code">UpdateAttributes()</code> to update document
        attributes in real-time, changes are first written to the in-memory
        copy of attributes (<code class="option">docinfo</code> must be set to
        <code class="option">extern</code>). Then, once <code class="filename">searchd</code>
        shuts down normally (via <code class="code">SIGTERM</code> being sent), the changes
        are written to disk. Introduced in version 0.9.9-rc1.</p><p>Starting with 0.9.9-rc1, it is possible to tell
        <code class="filename">searchd</code> to periodically write these changes back
        to disk, to avoid them being lost. The time between those intervals is
        set with <code class="option">attr_flush_period</code>, in seconds.</p><p>It defaults to 0, which disables the periodic flushing, but
        flushing will still occur at normal shut-down.</p><h4>Example:</h4><pre class="programlisting">attr_flush_period = 900 # persist updates to disk every 15 minutes
</pre></div>
<div class="sect2" title="11.4.16.&nbsp;ondisk_dict_default"><div class="titlepage"><div><div><h3 class="title"><a name="conf-ondisk-dict-default"></a>11.4.16.&nbsp;ondisk_dict_default</h3></div></div></div>
<p>Instance-wide defaults for <a class="link" href="#conf-ondisk-dict" title="11.2.36.&nbsp;ondisk_dict">ondisk_dict</a> directive. Optional,
        default it 0 (precache dictionaries in RAM). Introduced in version
        0.9.9-rc1.</p><p>This directive lets you specify the default value of <a class="link" href="#conf-ondisk-dict" title="11.2.36.&nbsp;ondisk_dict">ondisk_dict</a> for all the indexes
        served by this copy of <code class="filename">searchd</code>. Per-index
        directive take precedence, and will overwrite this instance-wide
        default value, allowing for fine-grain control.</p><h4>Example:</h4><pre class="programlisting">ondisk_dict_default = 1 # keep all dictionaries on disk
</pre></div>
<div class="sect2" title="11.4.17.&nbsp;max_packet_size"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-packet-size"></a>11.4.17.&nbsp;max_packet_size</h3></div></div></div>
<p>Maximum allowed network packet size. Limits both query packets
        from clients, and response packets from remote agents in distributed
        environment. Only used for internal sanity checks, does not directly
        affect RAM use or performance. Optional, default is 8M. Introduced in
        version 0.9.9-rc1.</p><h4>Example:</h4><pre class="programlisting">max_packet_size = 32M
</pre></div>
<div class="sect2" title="11.4.18.&nbsp;mva_updates_pool"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mva-updates-pool"></a>11.4.18.&nbsp;mva_updates_pool</h3></div></div></div>
<p>Shared pool size for in-memory MVA updates storage. Optional,
        default size is 1M. Introduced in version 0.9.9-rc1.</p><p>This setting controls the size of the shared storage pool for
        updated MVA values. Specifying 0 for the size disable MVA updates at
        all. Once the pool size limit is hit, MVA update attempts will result
        in an error. However, updates on regular (scalar) attributes will
        still work. Due to internal technical difficulties, currently it is
        <span class="bold"><strong>not</strong></span> possible to store (flush) <span class="bold"><strong>any</strong></span> updates on indexes
        where MVA were updated; though this might be implemented in the
        future. In the meantime, MVA updates are intended to be used as a
        measure to quickly catchup with latest changes in the database until
        the next index rebuild; not as a persistent storage mechanism.</p><h4>Example:</h4><pre class="programlisting">mva_updates_pool = 16M
</pre></div>
<div class="sect2" title="11.4.19.&nbsp;crash_log_path"><div class="titlepage"><div><div><h3 class="title"><a name="conf-crash-log-path"></a>11.4.19.&nbsp;crash_log_path</h3></div></div></div>
<p>Deprecated debugging setting, path (formally prefix) for crash
        log files. Introduced in version 0.9.9-rc1. Deprecated in version
        2.0.1-beta, as crash debugging information now gets logged into
        searchd.log in text form, and separate binary crash logs are no longer
        needed.</p></div>
<div class="sect2" title="11.4.20.&nbsp;max_filters"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-filters"></a>11.4.20.&nbsp;max_filters</h3></div></div></div>
<p>Maximum allowed per-query filter count. Only used for internal
        sanity checks, does not directly affect RAM use or performance.
        Optional, default is 256. Introduced in version 0.9.9-rc1.</p><h4>Example:</h4><pre class="programlisting">max_filters = 1024
</pre></div>
<div class="sect2" title="11.4.21.&nbsp;max_filter_values"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-filter-values"></a>11.4.21.&nbsp;max_filter_values</h3></div></div></div>
<p>Maximum allowed per-filter values count. Only used for internal
        sanity checks, does not directly affect RAM use or performance.
        Optional, default is 4096. Introduced in version 0.9.9-rc1.</p><h4>Example:</h4><pre class="programlisting">max_filter_values = 16384
</pre></div>
<div class="sect2" title="11.4.22.&nbsp;listen_backlog"><div class="titlepage"><div><div><h3 class="title"><a name="conf-listen-backlog"></a>11.4.22.&nbsp;listen_backlog</h3></div></div></div>
<p>TCP listen backlog. Optional, default is 5.</p><p>Windows builds currently (as of 0.9.9) can only process the
        requests one by one. Concurrent requests will be enqueued by the TCP
        stack on OS level, and requests that can not be enqueued will
        immediately fail with "connection refused" message. listen_backlog
        directive controls the length of the connection queue. Non-Windows
        builds should work fine with the default value.</p><h4>Example:</h4><pre class="programlisting">listen_backlog = 20
</pre></div>
<div class="sect2" title="11.4.23.&nbsp;read_buffer"><div class="titlepage"><div><div><h3 class="title"><a name="conf-read-buffer"></a>11.4.23.&nbsp;read_buffer</h3></div></div></div>
<p>Per-keyword read buffer size. Optional, default is 256K.</p><p>For every keyword occurrence in every search query, there are
        two associated read buffers (one for document list and one for hit
        list). This setting lets you control their sizes, increasing per-query
        RAM use, but possibly decreasing IO time.</p><h4>Example:</h4><pre class="programlisting">read_buffer = 1M
</pre></div>
<div class="sect2" title="11.4.24.&nbsp;read_unhinted"><div class="titlepage"><div><div><h3 class="title"><a name="conf-read-unhinted"></a>11.4.24.&nbsp;read_unhinted</h3></div></div></div>
<p>Unhinted read size. Optional, default is 32K.</p><p>When querying, some reads know in advance exactly how much data
        is there to be read, but some currently do not. Most prominently, hit
        list size in not currently known in advance. This setting lest you
        control how much data to read in such cases. It will impact hit list
        IO time, reducing it for lists larger than unhinted read size, but
        raising it for smaller lists. It will <span class="bold"><strong>not</strong></span> affect RAM use
        because read buffer will be already allocated. So it should be not
        greater than read_buffer.</p><h4>Example:</h4><pre class="programlisting">read_unhinted = 32K
</pre></div>
<div class="sect2" title="11.4.25.&nbsp;max_batch_queries"><div class="titlepage"><div><div><h3 class="title"><a name="conf-max-batch-queries"></a>11.4.25.&nbsp;max_batch_queries</h3></div></div></div>
<p>Limits the amount of queries per batch. Optional, default is
        32.</p><p>Makes searchd perform a sanity check of the amount of the
        queries submitted in a single batch when using <a class="link" href="#multi-queries" title="5.11.&nbsp;Multi-queries">multi-queries</a>. Set it to 0 to skip the
        check.</p><h4>Example:</h4><pre class="programlisting">max_batch_queries = 256
</pre></div>
<div class="sect2" title="11.4.26.&nbsp;subtree_docs_cache"><div class="titlepage"><div><div><h3 class="title"><a name="conf-subtree-docs-cache"></a>11.4.26.&nbsp;subtree_docs_cache</h3></div></div></div>
<p>Max common subtree document cache size, per-query. Optional,
        default is 0 (disabled).</p><p>Limits RAM usage of a common subtree optimizer (see <a class="xref" href="#multi-queries" title="5.11.&nbsp;Multi-queries">Section&nbsp;5.11, “Multi-queries”</a>). At most this much RAM will be spent to
        cache document entries per each query. Setting the limit to 0 disables
        the optimizer.</p><h4>Example:</h4><pre class="programlisting">subtree_docs_cache = 8M
</pre></div>
<div class="sect2" title="11.4.27.&nbsp;subtree_hits_cache"><div class="titlepage"><div><div><h3 class="title"><a name="conf-subtree-hits-cache"></a>11.4.27.&nbsp;subtree_hits_cache</h3></div></div></div>
<p>Max common subtree hit cache size, per-query. Optional, default
        is 0 (disabled).</p><p>Limits RAM usage of a common subtree optimizer (see <a class="xref" href="#multi-queries" title="5.11.&nbsp;Multi-queries">Section&nbsp;5.11, “Multi-queries”</a>). At most this much RAM will be spent to
        cache keyword occurrences (hits) per each query. Setting the limit to
        0 disables the optimizer.</p><h4>Example:</h4><pre class="programlisting">subtree_hits_cache = 16M
</pre></div>
<div class="sect2" title="11.4.28.&nbsp;workers"><div class="titlepage"><div><div><h3 class="title"><a name="conf-workers"></a>11.4.28.&nbsp;workers</h3></div></div></div>
<p>Multi-processing mode (MPM). Optional; allowed values are none,
        fork, prefork, and threads. Default is fork on Unix based systems, and
        threads on Windows. Introduced in version 1.10-beta.</p><p>Lets you choose how <code class="filename">searchd</code> processes
        multiple concurrent requests. The possible values are: </p><div class="variablelist"><dl><dt><span class="term">none</span></dt>
<dd><p>All requests will be handled serially, one-by-one. Prior
                to 1.x, this was the only mode available on Windows.</p></dd><dt><span class="term">fork</span></dt>
<dd><p>A new child process will be forked to handle every
                incoming request. Historically, this is the default
                mode.</p></dd><dt><span class="term">prefork</span></dt>
<dd><p>On startup, <code class="filename">searchd</code> will pre-fork a
                number of worker processes, and pass the incoming requests to
                one of those children.</p></dd><dt><span class="term">threads</span></dt>
<dd><p>A new thread will be created to handle every incoming
                request. This is the only mode compatible with RT indexing
                backend.</p></dd></dl></div>
<p>Historically, <code class="filename">searchd</code> used fork-based
        model, which generally performs OK but spends a noticeable amount of
        CPU in fork() system call when there's a high amount of (tiny)
        requests per second. Prefork mode was implemented to alleviate that;
        with prefork, worker processes are basically only created on startup
        and re-created on index rotation, somewhat reducing fork() call
        pressure.</p><p>Threads mode was implemented along with RT backend and is
        required to use RT indexes. (Regular disk-based indexes work in all
        the available modes.)</p><h4>Example:</h4><pre class="programlisting">workers = threads
</pre></div>
<div class="sect2" title="11.4.29.&nbsp;dist_threads"><div class="titlepage"><div><div><h3 class="title"><a name="conf-dist-threads"></a>11.4.29.&nbsp;dist_threads</h3></div></div></div>
<p>Max local worker threads to use for parallelizable requests
        (searching a distributed index; building a batch of snippets).
        Optional, default is 0, which means to disable in-request parallelism.
        Introduced in version 1.10-beta.</p><p>Distributed index can include several local indexes.
        <code class="option">dist_threads</code> lets you easily utilize multiple
        CPUs/cores for that (previously existing alternative was to specify
        the indexes as remote agents, pointing searchd to itself and paying
        some network overheads).</p><p>When set to a value N greater than 1, this directive will create
        up to N threads for every query, and schedule the specific searches
        within these threads. For example, if there are 7 local indexes to
        search and dist_threads is set to 2, then 2 parallel threads would be
        created: one that sequentially searches 4 indexes, and another one
        that searches the other 3 indexes.</p><p>In case of CPU bound workload, setting
        <code class="option">dist_threads</code> to 1x the number of cores is advised
        (creating more threads than cores will not improve query time). In
        case of mixed CPU/disk bound workload it might sometimes make sense to
        use more (so that all cores could be utilizes even when there are
        threads that wait for I/O completion).</p><p>Note that <code class="option">dist_threads</code> does <span class="bold"><strong>not</strong></span> require
        threads MPM. You can perfectly use it with fork or prefork MPMs
        too.</p><p>Starting with version 2.0.1-beta, building a batch of snippets
        with <code class="option">load_files</code> flag enabled can also be
        parallelized. Up to <code class="option">dist_threads</code> threads are be
        created to process those files. That speeds up snippet extraction when
        the total amount of document data to process is significant (hundreds
        of megabytes).</p><h4>Example:</h4><pre class="programlisting">index dist_test
{
	type = distributed
	local = chunk1
	local = chunk2
	local = chunk3
	local = chunk4
}

# ...

dist_threads = 4
</pre></div>
<div class="sect2" title="11.4.30.&nbsp;binlog_path"><div class="titlepage"><div><div><h3 class="title"><a name="conf-binlog-path"></a>11.4.30.&nbsp;binlog_path</h3></div></div></div>
<p>Binary log (aka transaction log) files path. Optional, default
        is build-time configured data directory. Introduced in version
        1.10-beta.</p><p>Binary logs are used for crash recovery of RT index data that
        would otherwise only be stored in RAM. When logging is enabled, every
        transaction COMMIT-ted into RT index gets written into a log file.
        Logs are then automatically replayed on startup after an unclean
        shutdown, recovering the logged changes.</p><p><code class="option">binlog_path</code> directive specifies the binary log
        files location. It should contain just the path;
        <code class="option">searchd</code> will create and unlink multiple binlog.*
        files in that path as necessary (binlog data, metadata, and lock
        files, etc).</p><p>Empty value disables binary logging. That improves performance,
        but puts RT index data at risk.</p><h4>Example:</h4><pre class="programlisting">binlog_path = # disable logging
binlog_path = /var/data # /var/data/binlog.001 etc will be created
</pre></div>
<div class="sect2" title="11.4.31.&nbsp;binlog_flush"><div class="titlepage"><div><div><h3 class="title"><a name="conf-binlog-flush"></a>11.4.31.&nbsp;binlog_flush</h3></div></div></div>
<p>Binary log transaction flush/sync mode. Optional, default is 2
        (flush every transaction, sync every second). Introduced in version
        1.10-beta.</p><p>This directive controls how frequently will binary log be
        flushed to OS and synced to disk. Three modes are supported:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>0, flush and sync every second. Best performance, but up
              to 1 second worth of committed transactions can be lost both on
              daemon crash, or OS/hardware crash.</p></li>
<li class="listitem"><p>1, flush and sync every transaction. Worst performance,
              but every committed transaction data is guaranteed to be
              saved.</p></li>
<li class="listitem"><p>2, flush every transaction, sync every second. Good
              performance, and every committed transaction is guaranteed to be
              saved in case of daemon crash. However, in case of OS/hardware
              crash up to 1 second worth of committed transactions can be
              lost.</p></li>
</ul></div>
<p>For those familiar with MySQL and InnoDB, this directive is
        entirely similar to <code class="option">innodb_flush_log_at_trx_commit</code>.
        In most cases, the default hybrid mode 2 provides a nice balance of
        speed and safety, with full RT index data protection against daemon
        crashes, and some protection against hardware ones.</p><h4>Example:</h4><pre class="programlisting">binlog_flush = 1 # ultimate safety, low speed
</pre></div>
<div class="sect2" title="11.4.32.&nbsp;binlog_max_log_size"><div class="titlepage"><div><div><h3 class="title"><a name="conf-binlog-max-log-size"></a>11.4.32.&nbsp;binlog_max_log_size</h3></div></div></div>
<p>Maximum binary log file size. Optional, default is 0 (do not
        reopen binlog file based on size). Introduced in version
        1.10-beta.</p><p>A new binlog file will be forcibly opened once the current
        binlog file reaches this limit. This achieves a finer granularity of
        logs and can yield more efficient binlog disk usage under certain
        borderline workloads.</p><h4>Example:</h4><pre class="programlisting">binlog_max_log_size = 16M
</pre></div>
<div class="sect2" title="11.4.33.&nbsp;collation_server"><div class="titlepage"><div><div><h3 class="title"><a name="conf-collation-server"></a>11.4.33.&nbsp;collation_server</h3></div></div></div>
<p>Default server collation. Optional, default is libc_ci.
        Introduced in version 2.0.1-beta.</p><p>Specifies the default collation used for incoming requests. The
        collation can be overridden on a per-query basis. Refer to <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a> section for the list of available collations
        and other details.</p><h4>Example:</h4><pre class="programlisting">collation_server = utf8_ci
</pre></div>
<div class="sect2" title="11.4.34.&nbsp;collation_libc_locale"><div class="titlepage"><div><div><h3 class="title"><a name="conf-collation-libc-locale"></a>11.4.34.&nbsp;collation_libc_locale</h3></div></div></div>
<p>Server libc locale. Optional, default is C. Introduced in
        version 2.0.1-beta.</p><p>Specifies the libc locale, affecting the libc-based collations.
        Refer to <a class="xref" href="#collations" title="5.12.&nbsp;Collations">Section&nbsp;5.12, “Collations”</a> section for the details.</p><h4>Example:</h4><pre class="programlisting">collation_libc_locale = fr_FR
</pre></div>
<div class="sect2" title="11.4.35.&nbsp;plugin_dir"><div class="titlepage"><div><div><h3 class="title"><a name="conf-plugin-dir"></a>11.4.35.&nbsp;plugin_dir</h3></div></div></div>
<p>Trusted location for the dynamic libraries (UDFs). Optional,
        default is empty (no location). Introduced in version
        2.0.1-beta.</p><p>Specifies the trusted directory from which the <a class="link" href="#udf" title="5.13.&nbsp;User-defined functions (UDF)">UDF libraries</a> can be loaded. Requires <a class="link" href="#conf-workers" title="11.4.28.&nbsp;workers">workers = thread</a> to take effect.</p><h4>Example:</h4><pre class="programlisting">workers = threads
plugin_dir = /usr/local/sphinx/lib
</pre></div>
<div class="sect2" title="11.4.36.&nbsp;mysql_version_string"><div class="titlepage"><div><div><h3 class="title"><a name="conf-mysql-version-string"></a>11.4.36.&nbsp;mysql_version_string</h3></div></div></div>
<p>A server version string to return via MySQL protocol. Optional,
        default is empty (return Sphinx version). Introduced in version
        2.0.1-beta.</p><p>Several picky MySQL client libraries depend on a particular
        version number format used by MySQL, and moreover, sometimes choose a
        different execution path based on the reported version number (rather
        than the indicated capabilities flags). For instance, Python MySQLdb
        1.2.2 throws an exception when the version number is not in X.Y.ZZ
        format; MySQL .NET connector 6.3.x fails internally on version numbers
        1.x along with a certain combination of flags, etc. To workaround
        that, you can use <code class="option">mysql_version_string</code> directive and
        have <code class="filename">searchd</code> report a different version to
        clients connecting over MySQL protocol. (By default, it reports its
        own version.)</p><h4>Example:</h4><pre class="programlisting">mysql_version_string = 5.0.37
</pre></div>
<div class="sect2" title="11.4.37.&nbsp;rt_flush_period"><div class="titlepage"><div><div><h3 class="title"><a name="conf-rt-flush-period"></a>11.4.37.&nbsp;rt_flush_period</h3></div></div></div>
<p>RT indexes RAM chunk flush check period, in seconds. Optional,
        default is 0 (do not flush). Introduced in version 2.0.1-beta.</p><p>Actively updated RT indexes that however fully fit in RAM chunks
        can result in ever-growing binlogs, impacting disk use and crash
        recovery time. With this directive the search daemon performs periodic
        flush checks, and eligible RAM chunks can get saved, enabling
        consequential binlog cleanup. See <a class="xref" href="#rt-binlog" title="4.4.&nbsp;Binary logging">Section&nbsp;4.4, “Binary logging”</a> for
        more details.</p><h4>Example:</h4><pre class="programlisting">rt_flush_period = 3600
</pre></div>
<div class="sect2" title="11.4.38.&nbsp;thread_stack"><div class="titlepage"><div><div><h3 class="title"><a name="conf-thread-stack"></a>11.4.38.&nbsp;thread_stack</h3></div></div></div>
<p>Per-thread stack size. Optional, default is 64K. Introduced in
        version 2.0.1-beta.</p><p>In the <code class="code">workers = threads</code> mode, every request is
        processed with a separate thread that needs its own stack space. By
        default, 64K per thread are allocated for stack. However, extremely
        complex search requests might eventually exhaust the default stack and
        require more. For instance, a query that matches a few thousand
        keywords (either directly or through term expansion) can eventually
        run out of stack. Previously, that resulted in crashes. Starting with
        2.0.1-beta, <code class="filename">searchd</code> attempts to estimate the
        expected stack use, and blocks the potentially dangerous queries. To
        process such queries, you can either the thread stack size by using
        the <code class="code">thread_stack</code> directive (or switch to a different
        <code class="code">workers</code> setting if that is possible).</p><p>A query with N levels of nesting is estimated to require
        approximately 30+0.12*N KB of stack, meaning that the default 64K is
        enough for queries with upto 300 levels, 150K for upto 1000 levels,
        etc. If the stack size limit is not met, <code class="filename">searchd</code>
        fails the query and reports the required stack size in the error
        message.</p><h4>Example:</h4><pre class="programlisting">thread_stack = 256K
</pre></div>
<div class="sect2" title="11.4.39.&nbsp;expansion_limit"><div class="titlepage"><div><div><h3 class="title"><a name="conf-expansion-limit"></a>11.4.39.&nbsp;expansion_limit</h3></div></div></div>
<p>The maximum number of expanded keywords for a single wildcard.
        Optional, default is 0 (no limit). Introduced in version
        2.0.1-beta.</p><p>When doing substring searches against indexes built with
        <code class="code">dict = keywords</code> enabled, a single wildcard may
        potentially result in thousands and even millions of matched keywords
        (think of matching 'a*' against the entire Oxford dictionary). This
        directive lets you limit the impact of such expansions. Setting
        <code class="code">expansion_limit = N</code> restricts expansions to no more than
        N of the most frequent matching keywords (per each wildcard in the
        query).</p><h4>Example:</h4><pre class="programlisting">expansion_limit = 16
</pre></div>
<div class="sect2" title="11.4.40.&nbsp;compat_sphinxql_magics"><div class="titlepage"><div><div><h3 class="title"><a name="conf-compat-sphinxql-magics"></a>11.4.40.&nbsp;compat_sphinxql_magics</h3></div></div></div>
<p>Legacy SphinxQL quirks compatiblity mode. Optional, default is 1
        (keep compatibility). Introduced in version 2.0.1-beta.</p><p>Starting with version 2.0.1-beta, we're bringing SphinxQL in
        closer compliance with standard SQL. However, existing applications
        must not get broken, and <code class="code">compat_sphinxql_magics</code> lets you
        upgrade safely. It defauls to 1, which enables the compatibility mode.
        However, <span class="bold"><strong>SphinxQL compatibility mode is now deprecated and will be
        removed</strong></span> once we complete bringing SphinxQL in line with standard
        SQL syntax. So it's advised to update the applications utilising
        SphinxQL and then switch the daemon to the new, more SQL compliant
        mode by setting <code class="code">compat_sphinxql_magics = 0</code>. Please refer
        to <a class="xref" href="#sphinxql-upgrading-magics" title="7.21.&nbsp;SphinxQL upgrade notes, version 2.0.1-beta">Section&nbsp;7.21, “SphinxQL upgrade notes, version 2.0.1-beta”</a> for the details and
        update instruction.</p><h4>Example:</h4><pre class="programlisting">compat_sphinxql_magics = 0 # the future is now
</pre></div>
<div class="sect2" title="11.4.41.&nbsp;watchdog"><div class="titlepage"><div><div><h3 class="title"><a name="conf-watchdog"></a>11.4.41.&nbsp;watchdog</h3></div></div></div>
<p>Threaded server watchdog. Optional, default is 1 (watchdog
        enabled). Introduced in version 2.0.1-beta.</p><p>A crashed query in <code class="code">threads</code> multi-processing mode
        (<code class="code"><a class="link" href="#conf-workers" title="11.4.28.&nbsp;workers">workers</a> = threads</code>)
        can take down the entire server. With watchdog feature enabled,
        <code class="filename">searchd</code> additionally keeps a separate lightweight
        process that monitors the main server process, and automatically
        restarts the latter in case of abnormal termination. Watchdog is
        enabled by default.</p><h4>Example:</h4><pre class="programlisting">watchdog = 0 # disable watchdog
</pre></div></div></div>
<div class="appendix" title="Appendix&nbsp;A.&nbsp;Sphinx revision history"><div class="titlepage"><div><div><h2 class="title"><a name="changelog"></a>Appendix&nbsp;A.&nbsp;Sphinx revision history</h2></div></div></div>
<div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#rel111">A.1. Version 2.0.1-beta, 22 apr 2011</a></span></dt>
<dt><span class="sect1"><a href="#rel110">A.2. Version 1.10-beta, 19 jul 2010</a></span></dt>
<dt><span class="sect1"><a href="#rel099">A.3. Version 0.9.9-release, 02 dec 2009</a></span></dt>
<dt><span class="sect1"><a href="#rel099rc2">A.4. Version 0.9.9-rc2, 08 apr 2009</a></span></dt>
<dt><span class="sect1"><a href="#rel099rc1">A.5. Version 0.9.9-rc1, 17 nov 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel0981">A.6. Version 0.9.8.1, 30 oct 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel098">A.7. Version 0.9.8, 14 jul 2008</a></span></dt>
<dt><span class="sect1"><a href="#rel097">A.8. Version 0.9.7, 02 apr 2007</a></span></dt>
<dt><span class="sect1"><a href="#rel097rc2">A.9. Version 0.9.7-rc2, 15 dec 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel097rc">A.10. Version 0.9.7-rc1, 26 oct 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel096">A.11. Version 0.9.6, 24 jul 2006</a></span></dt>
<dt><span class="sect1"><a href="#rel096rc1">A.12. Version 0.9.6-rc1, 26 jun 2006</a></span></dt>
</dl></div>
<div class="sect1" title="A.1.&nbsp;Version 2.0.1-beta, 22 apr 2011"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel111"></a>A.1.&nbsp;Version 2.0.1-beta, 22 apr 2011</h2></div></div></div>
<h3>New general features</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added remapping support to <a class="link" href="#conf-blend-chars" title="11.2.47.&nbsp;blend_chars">blend_chars</a> directive</p></li>
<li class="listitem"><p>added multi-threaded snippet batches support (requires a batch
          sent via API, <a class="link" href="#conf-dist-threads" title="11.4.29.&nbsp;dist_threads">dist_threads</a>,
          and <code class="code">load_files</code>)</p></li>
<li class="listitem"><p>added collations (<a class="link" href="#conf-collation-server" title="11.4.33.&nbsp;collation_server">collation_server</a>, <a class="link" href="#conf-collation-libc-locale" title="11.4.34.&nbsp;collation_libc_locale">collation_libc_locale
          directives</a>)</p></li>
<li class="listitem"><p>added support for sorting and grouping on string attributes
          (<code class="code">ORDER BY</code>, <code class="code">GROUP BY</code>, <code class="code">WITHING GROUP
          ORDER BY</code>)</p></li>
<li class="listitem"><p>added UDF support (<a class="link" href="#conf-plugin-dir" title="11.4.35.&nbsp;plugin_dir">plugin_dir</a> directive; <a class="link" href="#sphinxql-create-function" title="7.13.&nbsp;CREATE FUNCTION syntax">CREATE FUNCTION</a>, <a class="link" href="#sphinxql-drop-function" title="7.14.&nbsp;DROP FUNCTION syntax">DROP FUNCTION</a>
          statements)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-query-log-format" title="11.4.6.&nbsp;query_log_format">query_log_format</a> directive,
          <a class="link" href="#sphinxql-set" title="7.7.&nbsp;SET syntax">SET GLOBAL query_log_format | log_level
          = ...</a> statements; and connection id tracking</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-sql-column-buffers" title="11.1.26.&nbsp;sql_column_buffers">sql_column_buffers</a>
          directive, fixed out-of-buffer column handling in ODBC/MS SQL
          sources</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-blend-mode" title="11.2.48.&nbsp;blend_mode">blend_mode</a>
          directive that enables indexing multiple variants of a blended
          sequence</p></li>
<li class="listitem"><p>added UNIX socket support to C, Ruby APIs</p></li>
<li class="listitem"><p>added ranged query support to <a class="link" href="#conf-sql-joined-field" title="11.1.13.&nbsp;sql_joined_field">sql_joined_field</a></p></li>
<li class="listitem"><p>added <a class="link" href="#conf-rt-flush-period" title="11.4.37.&nbsp;rt_flush_period">rt_flush_period</a>
          directive</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-thread-stack" title="11.4.38.&nbsp;thread_stack">thread_stack</a>
          directive</p></li>
<li class="listitem"><p>added SENTENCE, PARAGRAPH, ZONE operators (and <a class="link" href="#conf-index-sp" title="11.2.8.&nbsp;index_sp">index_sp</a>, <a class="link" href="#conf-index-zones" title="11.2.9.&nbsp;index_zones">index_zones</a> directives)</p></li>
<li class="listitem"><p>added keywords dictionary support (and <a class="link" href="#conf-dict" title="11.2.7.&nbsp;dict">dict</a>, <a class="link" href="#conf-expansion-limit" title="11.4.39.&nbsp;expansion_limit">expansion_limit</a>
          directives)</p></li>
<li class="listitem"><p>added <code class="code">passage_boundary</code>, <code class="code">emit_zones</code>
          options to snippets</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-watchdog" title="11.4.41.&nbsp;watchdog">a watchdog process</a>
          in threaded mode</p></li>
<li class="listitem"><p>added persistent MVA updates</p></li>
<li class="listitem"><p>added crash dumps to <code class="filename">searchd.log</code>,
          deprecated <code class="code">crash_log_path</code> directive</p></li>
<li class="listitem"><p>added id32 index support in id64 binaries
          (EXPERIMENTAL)</p></li>
<li class="listitem"><p>added SphinxSE support for DELETE and REPLACE on SphinxQL
          tables</p></li>
</ul></div>
<h3>New SphinxQL features</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added new, more SQL compliant SphinxQL syntax; and a <a class="link" href="#conf-compat-sphinxql-magics" title="11.4.40.&nbsp;compat_sphinxql_magics">compat_sphinxql_magics</a>
          directive</p></li>
<li class="listitem"><p>added <a class="link" href="#expr-func-crc32">CRC32()</a>, <a class="link" href="#expr-func-day">DAY()</a>, <a class="link" href="#expr-func-month">MONTH()</a>, <a class="link" href="#expr-func-year">YEAR()</a>, <a class="link" href="#expr-func-yearmonth">YEARMONTH()</a>, <a class="link" href="#expr-func-yearmonthday">YEARMONTHDAY()</a>
          functions</p></li>
<li class="listitem"><p>added <a class="link" href="#expr-ari-ops">DIV, MOD, and %
          operators</a></p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-select" title="7.1.&nbsp;SELECT syntax">reverse_scan=(0|1)</a> option to
          SELECT</p></li>
<li class="listitem"><p>added support for MySQL packets over 16M</p></li>
<li class="listitem"><p>added dummy SHOW VARIABLES, SHOW COLLATION, and SET
          character_set_results support (to support handshake with certain
          client libraries and frameworks)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-mysql-version-string" title="11.4.36.&nbsp;mysql_version_string">mysql_version_string</a>
          directive (to workaround picky MySQL client libraries)</p></li>
<li class="listitem"><p>added support for global filter variables, <a class="link" href="#sphinxql-set" title="7.7.&nbsp;SET syntax">SET GLOBAL @uservar=(int_list)</a></p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-delete" title="7.6.&nbsp;DELETE syntax">DELETE ... IN
          (id_list)</a> syntax support</p></li>
<li class="listitem"><p>added C-style comments syntax (for example, <code class="code">SELECT
          /*!40000 some comment*/ id FROM test</code>)</p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-update" title="7.17.&nbsp;UPDATE syntax">UPDATE ... WHERE
          id=X</a> syntax support</p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-multi-queries" title="7.18.&nbsp;Multi-statement queries">SphinxQL
          multi-query support</a></p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-describe" title="7.12.&nbsp;DESCRIBE syntax">DESCRIBE</a>, <a class="link" href="#sphinxql-show-tables" title="7.11.&nbsp;SHOW TABLES syntax">SHOW TABLES</a> statements</p></li>
</ul></div>
<h3>New command-line switches</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added <code class="code">--print-queries</code> switch to
          <code class="filename">indexer</code> that dumps SQL queries it runs</p></li>
<li class="listitem"><p>added <code class="code">--sighup-each </code> switch to
          <code class="filename">indexer</code> that rotates indexes one by one</p></li>
<li class="listitem"><p>added <code class="code">--strip-path</code> switch to
          <code class="filename">searchd</code> that skips file paths embedded in the
          index(-es)</p></li>
<li class="listitem"><p>added <code class="code">--dumpconfig</code> switch to
          <code class="filename">indextool</code> that dumps an index header in
          <code class="filename">sphinx.conf</code> format</p></li>
</ul></div>
<h3>Major changes and optimizations</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>changed default preopen_indexes value to 1</p></li>
<li class="listitem"><p>optimized English stemmer (results in 1.3x faster snippets and
          indexing with morphology=stem_en)</p></li>
<li class="listitem"><p>optimized snippets, 1.6x general speedup</p></li>
<li class="listitem"><p>optimized const-list parsing in SphinxQL</p></li>
<li class="listitem"><p>optimized full-document highlighting CPU/RAM use</p></li>
<li class="listitem"><p>optimized binlog replay (improved performance on K-list
          update)</p></li>
</ul></div>
<h3>Bug fixes</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=767" target="_top">#767</a>, joined fields vs ODBC sources</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=757" target="_top">#757</a>, wordforms shared by indexes with different
          settings</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=733" target="_top">#733</a>, loading of indexes in formats prior to v.14</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=763" target="_top">#763</a>, occasional snippets failures</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=648" target="_top">#648</a>, occasionally missed rotations on multiple
          SIGHUPs</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=750" target="_top">#750</a>, an RT segment merge leading to false positives
          and/or crashes in some cases</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=755" target="_top">#755</a>, zones in snippets output</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=754" target="_top">#754</a>, stopwords counting at snippet passage
          generation</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=723" target="_top">#723</a>, fork/prefork index rotation in children
          processes</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=696" target="_top">#696</a>, freeze on zero threshold in quorum operator</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=732" target="_top">#732</a>, query escaping in SphinxSE</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=739" target="_top">#739</a>, occasional crashes in MT mode on result set
          send</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=746" target="_top">#746</a>, crash with a named list in SphinxQL option</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=674" target="_top">#674</a>, AVG vs group order</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=734" target="_top">#734</a>, occasional crashes attempting to report NULL
          errors</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=829" target="_top">#829</a>, tail hits within field position modifier</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=712" target="_top">#712</a>, missing query_mode, force_all_words snippet option
          defaults in Java API</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=721" target="_top">#721</a>, added dupe removal on RT batch
          INSERT/REPLACE</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=720" target="_top">#720</a>, potential extraneous highlighting after a blended
          keyword</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=702" target="_top">#702</a>, exceptions vs star search</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=666" target="_top">#666</a>, ext2 query grouping vs exceptions</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=688" target="_top">#688</a>, WITHIN GROUP ORDER BY related crash</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=660" target="_top">#660</a>, multi-queue batches vs dist_threads</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=678" target="_top">#678</a>, crash on dict=keywords vs xmlpipe vs
          min_prefix_len</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=596" target="_top">#596</a>, ECHILD vs scripted configs</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=653" target="_top">#653</a>, dependency in expression, sorting, grouping</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=661" target="_top">#661</a>, concurrent distributed searches vs
          workers=threads</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=646" target="_top">#646</a>, crash on status query via UNIX socket</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=589" target="_top">#589</a>, libexpat.dll missing from some Win32 build
          types</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=574" target="_top">#574</a>, quorum match order</p></li>
<li class="listitem"><p>fixed multiple documentation issues (#372, #483, #495, #601,
          #623, #632, #654)</p></li>
<li class="listitem"><p>fixed that ondisk_dict did not affect RT indexes</p></li>
<li class="listitem"><p>fixed that string attributes check in indextool --check was
          erroneously sensitive to string data order</p></li>
<li class="listitem"><p>fixed a rare crash when using BEFORE operator</p></li>
<li class="listitem"><p>fixed an issue with multiforms vs BuildKeywords()</p></li>
<li class="listitem"><p>fixed an edge case in OR operator (emitted wrong hits order
          sometimes)</p></li>
<li class="listitem"><p>fixed aliasing in docinfo accessors that lead to very rare
          crashes and/or missing results</p></li>
<li class="listitem"><p>fixed a syntax error on a short token at the end of a
          query</p></li>
<li class="listitem"><p>fixed id64 filtering and performance degradation with range
          filters</p></li>
<li class="listitem"><p>fixed missing rankers in libsphinxclient</p></li>
<li class="listitem"><p>fixed missing SPH04 ranker in SphinxSE</p></li>
<li class="listitem"><p>fixed column names in sql_attr_multi sample (works with
          example.sql now)</p></li>
<li class="listitem"><p>fixed an issue with distributed local+remote setup vs
          aggregate functions</p></li>
<li class="listitem"><p>fixed case sensitive columns names in RT indexes</p></li>
<li class="listitem"><p>fixed a crash vs strings from multiple indexes in result
          set</p></li>
<li class="listitem"><p>fixed blended keywords vs snippets</p></li>
<li class="listitem"><p>fixed secure_connection vs MySQL protocol vs MySQL.NET
          connector</p></li>
<li class="listitem"><p>fixed that Python API did not works with Python 2.3</p></li>
<li class="listitem"><p>fixed overshort_step vs snippets</p></li>
<li class="listitem"><p>fixed keyword staistics vs dist_threads searching</p></li>
<li class="listitem"><p>fixed multiforms vs query parsing (vs quorum)</p></li>
<li class="listitem"><p>fixed missed quorum words vs RT segments</p></li>
<li class="listitem"><p>fixed blended keywords occasionally skipping extra character
          when querying (eg "abc[]")</p></li>
<li class="listitem"><p>fixed Python API to handle int32 values</p></li>
<li class="listitem"><p>fixed prefix and infix indexing of joined fields</p></li>
<li class="listitem"><p>fixed MVA ranged query</p></li>
<li class="listitem"><p>fixed missing blended state reset on document boundary</p></li>
<li class="listitem"><p>fixed a crash on missing index while replaying binlog</p></li>
<li class="listitem"><p>fixed an error message on filter values overrun</p></li>
<li class="listitem"><p>fixed passage duplication in snippets in weight_order
          mode</p></li>
<li class="listitem"><p>fixed select clauses over 1K vs remote agents</p></li>
<li class="listitem"><p>fixed overshort accounting vs soft-whitespace tokens</p></li>
<li class="listitem"><p>fixed rotation vs workers=threads</p></li>
<li class="listitem"><p>fixed schema issues vs distributed indexes</p></li>
<li class="listitem"><p>fixed blended-escaped sequence parsing issue</p></li>
<li class="listitem"><p>fixed MySQL IN clause (values order etc)</p></li>
<li class="listitem"><p>fixed that post_index did not execute when 0 documents were
          succesfully indexed</p></li>
<li class="listitem"><p>fixed field position limit vs many hits</p></li>
<li class="listitem"><p>fixed that joined fields missed an end marker at field
          end</p></li>
<li class="listitem"><p>fixed that xxx_step settings were missing from .sph index
          header</p></li>
<li class="listitem"><p>fixed libsphinxclient missing request cleanup in
          sphinx_query() (eg after network errors)</p></li>
<li class="listitem"><p>fixed that index_weights were ignored when grouping</p></li>
<li class="listitem"><p>fixed multi wordforms vs blend_chars</p></li>
<li class="listitem"><p>fixed broken MVA output in SphinxQL</p></li>
<li class="listitem"><p>fixed a few RT leaks</p></li>
<li class="listitem"><p>fixed an issue with RT string storage going missing</p></li>
<li class="listitem"><p>fixed an issue with repeated queries vs dist_threads</p></li>
<li class="listitem"><p>fixed an issue with string attributes vs buffer overrun in
          SphinxQL</p></li>
<li class="listitem"><p>fixed unexpected character data warnings within ignored
          xmlpipe tags</p></li>
<li class="listitem"><p>fixed a crash in snippets with NEAR syntax query</p></li>
<li class="listitem"><p>fixed passage duplication in snippets</p></li>
<li class="listitem"><p>fixed libsphinxclient SIGPIPE handling</p></li>
<li class="listitem"><p>fixed libsphinxclient vs VS2003 compiler bug</p></li>
</ul></div></div>
<div class="sect1" title="A.2.&nbsp;Version 1.10-beta, 19 jul 2010"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel110"></a>A.2.&nbsp;Version 1.10-beta, 19 jul 2010</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added RT indexes support (<a class="xref" href="#rt-indexes" title="Chapter&nbsp;4.&nbsp;Real-time indexes">Chapter&nbsp;4, <i>Real-time indexes</i></a>)</p></li>
<li class="listitem"><p>added prefork and threads support (<a class="link" href="#conf-workers" title="11.4.28.&nbsp;workers">workers</a> directives)</p></li>
<li class="listitem"><p>added multi-threaded local searches in distributed indexes
          (<a class="link" href="#conf-dist-threads" title="11.4.29.&nbsp;dist_threads">dist_threads</a>
          directive)</p></li>
<li class="listitem"><p>added common subquery cache (<a class="link" href="#conf-subtree-docs-cache" title="11.4.26.&nbsp;subtree_docs_cache">subtree_docs_cache</a>, <a class="link" href="#conf-subtree-hits-cache" title="11.4.27.&nbsp;subtree_hits_cache">subtree_hits_cache</a>
          directives)</p></li>
<li class="listitem"><p>added string attributes support (<a class="link" href="#conf-sql-attr-string" title="11.1.24.&nbsp;sql_attr_string">sql_attr_string</a>, <a class="link" href="#conf-sql-field-string" title="11.1.27.&nbsp;sql_field_string">sql_field_string</a>, <a class="link" href="#conf-xmlpipe-attr-string" title="11.1.44.&nbsp;xmlpipe_attr_string">xml_attr_string</a>, <a class="link" href="#conf-xmlpipe-field-string" title="11.1.36.&nbsp;xmlpipe_field_string">xml_field_string</a>
          directives)</p></li>
<li class="listitem"><p>added indexing-time word counter (<a class="link" href="#conf-sql-attr-str2wordcount" title="11.1.25.&nbsp;sql_attr_str2wordcount">sql_attr_str2wordcount</a>,
          <a class="link" href="#conf-sql-field-str2wordcount" title="11.1.28.&nbsp;sql_field_str2wordcount">sql_field_str2wordcount</a>
          directives)</p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql-call-snippets" title="7.9.&nbsp;CALL SNIPPETS syntax">CALL
          SNIPPETS()</a>, <a class="link" href="#sphinxql-call-keywords" title="7.10.&nbsp;CALL KEYWORDS syntax">CALL
          KEYWORDS()</a> SphinxQL statements</p></li>
<li class="listitem"><p>added <code class="option">field_weights</code>,
          <code class="option">index_weights</code> options to SphinxQL <a class="link" href="#sphinxql-select" title="7.1.&nbsp;SELECT syntax">SELECT</a> statement</p></li>
<li class="listitem"><p>added insert-only SphinxQL-talking tables to SphinxSE
          (connection='sphinxql://host[:port]/index')</p></li>
<li class="listitem"><p>added <code class="option">select</code> option to SphinxSE
          queries</p></li>
<li class="listitem"><p>added backtrace on crash to
          <code class="filename">searchd</code></p></li>
<li class="listitem"><p>added SQL+FS indexing, aka loading files by names fetched from
          SQL (<a class="link" href="#conf-sql-file-field" title="11.1.29.&nbsp;sql_file_field">sql_file_field</a>
          directive)</p></li>
<li class="listitem"><p>added a watchdog in threads mode to
          <code class="filename">searchd</code></p></li>
<li class="listitem"><p>added automatic row phantoms elimination to index merge</p></li>
<li class="listitem"><p>added hitless indexing support (hitless_words
          directive)</p></li>
<li class="listitem"><p>added --check, --strip-path, --htmlstrip, --dumphitlist ...
          --wordid switches to <a class="link" href="#ref-indextool" title="6.5.&nbsp;indextool command reference">indextool</a></p></li>
<li class="listitem"><p>added --stopwait, --logdebug switches to <a class="link" href="#ref-searchd" title="6.2.&nbsp;searchd command reference">searchd</a></p></li>
<li class="listitem"><p>added --dump-rows, --verbose switches to <a class="link" href="#ref-indexer" title="6.1.&nbsp;indexer command reference">indexer</a></p></li>
<li class="listitem"><p>added "blended" characters indexing support (<a class="link" href="#conf-blend-chars" title="11.2.47.&nbsp;blend_chars">blend_chars</a> directive)</p></li>
<li class="listitem"><p>added joined/payload field indexing (<a class="link" href="#conf-sql-joined-field" title="11.1.13.&nbsp;sql_joined_field">sql_joined_field</a>
          directive)</p></li>
<li class="listitem"><p>added <a class="link" href="#api-func-flushattributes" title="8.7.6.&nbsp;FlushAttributes">FlushAttributes() API
          call</a></p></li>
<li class="listitem"><p>added query_mode, force_all_words, limit_passages,
          limit_words, start_passage_id, load_files, html_strip_mode,
          allow_empty options, and %PASSAGE_ID% macro in before_match,
          after_match options to <a class="link" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">BuildExcerpts()</a> API
          call</p></li>
<li class="listitem"><p>added @groupby/@count/@distinct columns support to SELECT (but
          not to expressions)</p></li>
<li class="listitem"><p>added query-time keyword expansion support (<a class="link" href="#conf-expand-keywords" title="11.2.46.&nbsp;expand_keywords">expand_keywords</a> directive,
          <a class="link" href="#api-func-setrankingmode" title="8.3.2.&nbsp;SetRankingMode">SPH_RANK_SPH04</a>
          ranker)</p></li>
<li class="listitem"><p>added query batch size limit option (<a class="link" href="#conf-max-batch-queries" title="11.4.25.&nbsp;max_batch_queries">max_batch_queries</a> directive;
          was hardcoded)</p></li>
<li class="listitem"><p>added SINT() function to expressions</p></li>
<li class="listitem"><p>improved SphinxQL syntax error reporting</p></li>
<li class="listitem"><p>improved expression optimizer (better constant
          handling)</p></li>
<li class="listitem"><p>improved dash handling within keywords (no longer treated as
          an operator)</p></li>
<li class="listitem"><p>improved snippets (better passage selection/trimming, around
          option now a hard limit)</p></li>
<li class="listitem"><p>optimized index format that yields ~20-30% smaller
          indexes</p></li>
<li class="listitem"><p>optimized sorting code (indexing time 1-5% faster on average;
          100x faster in worst case)</p></li>
<li class="listitem"><p>optimized searchd startup time (moved .spa preindexing to
          indexer), added a progress bar</p></li>
<li class="listitem"><p>optimized queries against indexes with many attributes
          (eliminated redundant copying)</p></li>
<li class="listitem"><p>optimized 1-keyword queries (performace regression introduced
          in 0.9.9)</p></li>
<li class="listitem"><p>optimized SphinxQL protocol overheads, and performance on
          bigger result sets</p></li>
<li class="listitem"><p>optimized unbuffered attributes writes on index merge</p></li>
<li class="listitem"><p>changed attribute handling, duplicate names are strictly
          forbidden now</p></li>
<li class="listitem"><p>fixed that SphinxQL sessions could stall shutdown</p></li>
<li class="listitem"><p>fixed consts with leading minus in SphinxQL</p></li>
<li class="listitem"><p>fixed AND/OR precedence in expressions</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=334" target="_top">#334</a>, AVG() on integers was not computed in
          floats</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=371" target="_top">#371</a>, attribute flush vs 2+ GB files</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=373" target="_top">#373</a>, segfault on distributed queries vs certain libc
          versions</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=398" target="_top">#398</a>, stopwords not stopped in prefix/infix
          indexes</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=404" target="_top">#404</a>, erroneous MVA failures in indextool --check</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=408" target="_top">#408</a>, segfault on certain query batches (regular scan,
          plus a scan with MVA groupby)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=431" target="_top">#431</a>, occasional shutdown hangs in preforked
          workers</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=436" target="_top">#436</a>, trunk checkout builds vs Solaris sh</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=440" target="_top">#440</a>, escaping vs parentheses declared as valid in
          charset_table</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=442" target="_top">#442</a>, occasional non-aligned free in MVA indexing</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=447" target="_top">#447</a>, occasional crashes in MVA indexing</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=449" target="_top">#449</a>, pconn busyloop on aborted clients on certain
          arches</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=465" target="_top">#465</a>, build issue on Alpha</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=468" target="_top">#468</a>, build issue in libsphinxclient</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=472" target="_top">#472</a>, multiple stopword files failing to load</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=489" target="_top">#489</a>, buffer overflow in query logging</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=493" target="_top">#493</a>, Python API assertion after error returned from
          Query()</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=500" target="_top">#500</a>, malformed MySQL packet when sending MVAs</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=504" target="_top">#504</a>, SIGPIPE in libsphinxclient</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=506" target="_top">#506</a>, better MySQL protocol commands support in SphinxQL
          (PING etc)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=509" target="_top">#509</a>, indexing ranged results from stored
          procedures</p></li>
</ul></div></div>
<div class="sect1" title="A.3.&nbsp;Version 0.9.9-release, 02 dec 2009"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel099"></a>A.3.&nbsp;Version 0.9.9-release, 02 dec 2009</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added Open, Close, Status calls to libsphinxclient (C
          API)</p></li>
<li class="listitem"><p>added automatic persistent connection reopening to PHP, Python
          APIs</p></li>
<li class="listitem"><p>added 64-bit value/range filters, fullscan mode support to
          SphinxSE</p></li>
<li class="listitem"><p>MAJOR CHANGE, our IANA assigned ports are 9312 and 9306
          respectively (goodbye, trusty 3312)</p></li>
<li class="listitem"><p>MAJOR CHANGE, erroneous filters now fail with an error (were
          silently ignored before)</p></li>
<li class="listitem"><p>optimized unbuffered .spa writes on merge</p></li>
<li class="listitem"><p>optimized 1-keyword queries ranking in extended2 mode</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=441" target="_top">#441</a> (IO race in case of highly conccurent load on a
          preopened)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=434" target="_top">#434</a> (distrubuted indexes were not searchable via MySQL
          protocol)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=317" target="_top">#317</a> (indexer MVA progress counter)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=398" target="_top">#398</a> (stopwords not removed from search query)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=328" target="_top">#328</a> (broken cutoff)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=250" target="_top">#250</a> (now quoting paths w/spaces when installing Windows
          service)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=348" target="_top">#348</a> (K-list was not updated on merge)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=357" target="_top">#357</a> (destination index were not K-list-filtered on
          merge)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=369" target="_top">#369</a> (precaching .spi files over 2 GBs)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=438" target="_top">#438</a> (missing boundary proximity matches)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=371" target="_top">#371</a> (.spa flush in case of files over 2 GBs)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=373" target="_top">#373</a> (crashes on distributed queries via mysql
          proto)</p></li>
<li class="listitem"><p>fixed critical bugs in hit merging code</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=424" target="_top">#424</a> (ordinals could be misplaced during indexing in
          case of bitfields etc)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=426" target="_top">#426</a> (failing SE build on Solaris; thanks to Ben
          Beecher)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=423" target="_top">#423</a> (typo in SE caused crash on SHOW STATUS)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=363" target="_top">#363</a> (handling of read_timeout over 2147 seconds)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=376" target="_top">#376</a> (minor error message mismatch)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=413" target="_top">#413</a> (minus in SphinxQL)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=417" target="_top">#417</a> (floats w/o leading digit in SphinxQL)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=403" target="_top">#403</a> (typo in SetFieldWeights name in Java API)</p></li>
<li class="listitem"><p>fixed index rotation vs persistent connections</p></li>
<li class="listitem"><p>fixed backslash handling in SphinxQL parser</p></li>
<li class="listitem"><p>fixed uint unpacking vs. PHP 5.2.9 (possibly other
          versions)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=325" target="_top">#325</a> (filter settings send from SphinxSE)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=352" target="_top">#352</a> (removed mysql wrapper around close() in
          SphinxSE)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=389" target="_top">#389</a> (display error messages through SphinxSE status
          variable)</p></li>
<li class="listitem"><p>fixed linking with port-installed iconv on OS X</p></li>
<li class="listitem"><p>fixed negative 64-bit unpacking in PHP API</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=349" target="_top">#349</a> (escaping backslash in query emulation mode)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=320" target="_top">#320</a> (disabled multi-query route when select items
          differ)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=353" target="_top">#353</a> (better quorum counts check)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=341" target="_top">#341</a> (merging of trailing hits; maybe other ranking
          issues too)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=368" target="_top">#368</a> (partially; @field "" caused crashes; now resets
          field limit)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=365" target="_top">#365</a> (field mask was leaking on field-limited
          terms)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=339" target="_top">#339</a> (updated debug query dumper)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=361" target="_top">#361</a> (added SetConnectTimeout() to Java API)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=338" target="_top">#338</a> (added missing fullscan to mode check in Java
          API)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=323" target="_top">#323</a> (added floats support to SphinxQL)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=340" target="_top">#340</a> (support listen=port:proto syntax too)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=332" target="_top">#332</a> (\r is legal SphinxQL space now)</p></li>
<li class="listitem"><p>fixed xmlpipe2 K-lists</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=322" target="_top">#322</a> (safety gaps in mysql protocol row buffer)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=313" target="_top">#313</a> (return keyword stats for empty indexes too)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=344" target="_top">#344</a> (invalid checkpoints after merge)</p></li>
<li class="listitem"><p>fixed <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=326" target="_top">#326</a> (missing CLOCK_xxx on FreeBSD)</p></li>
</ul></div></div>
<div class="sect1" title="A.4.&nbsp;Version 0.9.9-rc2, 08 apr 2009"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel099rc2"></a>A.4.&nbsp;Version 0.9.9-rc2, 08 apr 2009</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added IsConnectError(), Open(), Close() calls to Java API (bug
          #240)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-read-buffer" title="11.4.23.&nbsp;read_buffer">read_buffer</a>,
          <a class="link" href="#conf-read-unhinted" title="11.4.24.&nbsp;read_unhinted">read_unhinted</a>
          directives</p></li>
<li class="listitem"><p>added checks for build options returned by mysql_config
          (builds on Solaris now)</p></li>
<li class="listitem"><p>added fixed-RAM index merge (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=169" target="_top">#169</a>)</p></li>
<li class="listitem"><p>added logging chained queries count in case of (optimized)
          multi-queries</p></li>
<li class="listitem"><p>added <a class="link" href="#sort-expr" title="5.6.&nbsp;SPH_SORT_EXPR mode">GEODIST()</a>
          function</p></li>
<li class="listitem"><p>added <a class="link" href="#ref-searchd" title="6.2.&nbsp;searchd command reference">--status switch to
          searchd</a></p></li>
<li class="listitem"><p>added MySpell (OpenOffice) affix file support (bug
          #281)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-odbc-dsn" title="11.1.10.&nbsp;odbc_dsn">ODBC support</a> (both
          Windows and UnixODBC)</p></li>
<li class="listitem"><p>added support for @id in IN() (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=292" target="_top">#292</a>)</p></li>
<li class="listitem"><p>added support for <a class="link" href="#api-func-setselect" title="8.2.4.&nbsp;SetSelect">aggregate
          functions</a> in GROUP BY (namely AVG, MAX, MIN, SUM)</p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxse-snippets" title="9.4.&nbsp;Building snippets (excerpts) via MySQL">MySQL UDF that builds
          snippets</a> using searchd</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-write-buffer" title="11.3.5.&nbsp;write_buffer">write_buffer</a>
          directive (defaults to 1M)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-xmlpipe-fixup-utf8" title="11.1.45.&nbsp;xmlpipe_fixup_utf8">xmlpipe_fixup_utf8</a>
          directive</p></li>
<li class="listitem"><p>added suggestions sample</p></li>
<li class="listitem"><p>added microsecond precision int64 timer (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=282" target="_top">#282</a>)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-listen-backlog" title="11.4.22.&nbsp;listen_backlog">listen_backlog
          directive</a></p></li>
<li class="listitem"><p>added <a class="link" href="#conf-max-xmlpipe2-field" title="11.3.4.&nbsp;max_xmlpipe2_field">max_xmlpipe2_field</a>
          directive</p></li>
<li class="listitem"><p>added <a class="link" href="#sphinxql" title="5.10.&nbsp;MySQL protocol support and SphinxQL">initial SphinxQL support</a>
          to mysql41 handler, SELECT .../SHOW WARNINGS/STATUS/META are
          handled</p></li>
<li class="listitem"><p>added support for different network protocols, and mysql41
          protocol</p></li>
<li class="listitem"><p>added <a class="link" href="#api-func-setrankingmode" title="8.3.2.&nbsp;SetRankingMode">fieldmask
          ranker</a>, updated SphinxSE list of rankers</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-mysql-ssl" title="11.1.9.&nbsp;mysql_ssl_cert, mysql_ssl_key, mysql_ssl_ca">mysql_ssl_xxx</a>
          directives</p></li>
<li class="listitem"><p>added <a class="link" href="#ref-searchd" title="6.2.&nbsp;searchd command reference">--cpustats (requires
          clock_gettime()) and --status switches</a> to searchd</p></li>
<li class="listitem"><p>added performance counters, <a class="link" href="#api-func-status" title="8.7.5.&nbsp;Status">Status()</a> API call</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-overshort-step" title="11.2.43.&nbsp;overshort_step">overshort_step</a> and <a class="link" href="#conf-stopword-step" title="11.2.44.&nbsp;stopword_step">stopword_step</a> directives</p></li>
<li class="listitem"><p>added <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">strict order
          operator</a> (aka operator before, eg. "one &lt;&lt; two &lt;&lt;
          three")</p></li>
<li class="listitem"><p>added <a class="link" href="#ref-indextool" title="6.5.&nbsp;indextool command reference">indextool</a> utility,
          moved --dumpheader there, added --debugdocids, --dumphitlist
          options</p></li>
<li class="listitem"><p>added own RNG, reseeded on @random sort query (bug
          #183)</p></li>
<li class="listitem"><p>added <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">field-start and
          field-end modifiers support</a> (syntax is "^hello world$";
          field-end requires reindex)</p></li>
<li class="listitem"><p>added MVA attribute support to IN() function</p></li>
<li class="listitem"><p>added <a class="link" href="#sort-expr" title="5.6.&nbsp;SPH_SORT_EXPR mode">AND, OR, and NOT
          support</a> to expressions</p></li>
<li class="listitem"><p>improved logging of (optimized) multi-queries (now logging
          chained query count)</p></li>
<li class="listitem"><p>improved handshake error handling, fixed protocol version byte
          order (omg)</p></li>
<li class="listitem"><p>updated SphinxSE to protocol 1.22</p></li>
<li class="listitem"><p>allowed phrase_boundary_step=-1 (trick to emulate keyword
          expansion)</p></li>
<li class="listitem"><p>removed SPH_MAX_QUERY_WORDS limit</p></li>
<li class="listitem"><p>fixed CLI search vs documents missing from DB (bug
          #257)</p></li>
<li class="listitem"><p>fixed libsphinxclient results leak on subsequent
          sphinx_run_queries call (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=256" target="_top">#256</a>)</p></li>
<li class="listitem"><p>fixed libsphinxclient handling of zero max_matches and cutoff
          (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=208" target="_top">#208</a>)</p></li>
<li class="listitem"><p>fixed Java API over-64K string reads (eg. big snippets) in
          Java API (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=181" target="_top">#181</a>)</p></li>
<li class="listitem"><p>fixed Java API 2nd Query() after network error in 1st Query()
          call (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=308" target="_top">#308</a>)</p></li>
<li class="listitem"><p>fixed typo-class bugs in SetFilterFloatRange (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=259" target="_top">#259</a>),
          SetSortMode (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=248" target="_top">#248</a>)</p></li>
<li class="listitem"><p>fixed missing @@relaxed support (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=276" target="_top">#276</a>), fixed missing
          error on @nosuchfield queries, documented @@relaxed</p></li>
<li class="listitem"><p>fixed UNIX socket permissions to 0777 (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=288" target="_top">#288</a>)</p></li>
<li class="listitem"><p>fixed xmlpipe2 crash on schemas with no fields, added better
          document structure checks</p></li>
<li class="listitem"><p>fixed (and optimized) expr parser vs IN() with huge (10K+)
          args count</p></li>
<li class="listitem"><p>fixed double EarlyCalc() in fullscan mode (minor performance
          impact)</p></li>
<li class="listitem"><p>fixed phrase boundary handling in some cases (on buffer end,
          on trailing whitespace)</p></li>
<li class="listitem"><p>fixes in snippets (aka excerpts) generation</p></li>
<li class="listitem"><p>fixed inline attrs vs id64 index corruption</p></li>
<li class="listitem"><p>fixed head searchd crash on config re-parse failure</p></li>
<li class="listitem"><p>fixed handling of numeric keywords with leading zeroes such as
          "007" (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=251" target="_top">#251</a>)</p></li>
<li class="listitem"><p>fixed junk in SphinxSE status variables (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=304" target="_top">#304</a>)</p></li>
<li class="listitem"><p>fixed wordlist checkpoints serialization (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=236" target="_top">#236</a>)</p></li>
<li class="listitem"><p>fixed unaligned docinfo id access (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=230" target="_top">#230</a>)</p></li>
<li class="listitem"><p>fixed GetRawBytes() vs oversized blocks (headers with over 32K
          charset_table should now work, bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=300" target="_top">#300</a>)</p></li>
<li class="listitem"><p>fixed buffer overflow caused by too long dest wordform,
          updated tests</p></li>
<li class="listitem"><p>fixed IF() return type (was always int, is deduced now)</p></li>
<li class="listitem"><p>fixed legacy queries vs. special chars vs. multiple
          indexes</p></li>
<li class="listitem"><p>fixed write-write-read socket access pattern vs Nagle vs
          delays vs FreeBSD (oh wow)</p></li>
<li class="listitem"><p>fixed exceptions vs query-parser issue</p></li>
<li class="listitem"><p>fixed late calc vs @weight in expressions (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=285" target="_top">#285</a>)</p></li>
<li class="listitem"><p>fixed early lookup/calc vs filters (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=284" target="_top">#284</a>)</p></li>
<li class="listitem"><p>fixed emulated MATCH_ANY queries (empty proximity and phrase
          queries are allowed now)</p></li>
<li class="listitem"><p>fixed MATCH_ANY ranker vs fields with no matches</p></li>
<li class="listitem"><p>fixed index file size vs inplace_enable (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=245" target="_top">#245</a>)</p></li>
<li class="listitem"><p>fixed that old logs were not closed on USR1 (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=221" target="_top">#221</a>)</p></li>
<li class="listitem"><p>fixed handling of '!' alias to NOT operator (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=237" target="_top">#237</a>)</p></li>
<li class="listitem"><p>fixed error handling vs query steps (step failure was not
          reported)</p></li>
<li class="listitem"><p>fixed querying vs inline attributes</p></li>
<li class="listitem"><p>fixed stupid bug in escaping code, fixed EscapeString() and
          made it static</p></li>
<li class="listitem"><p>fixed parser vs @field -keyword, foo|@field bar, "" queries
          (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=310" target="_top">#310</a>)</p></li>
</ul></div></div>
<div class="sect1" title="A.5.&nbsp;Version 0.9.9-rc1, 17 nov 2008"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel099rc1"></a>A.5.&nbsp;Version 0.9.9-rc1, 17 nov 2008</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added <a class="link" href="#conf-min-stemming-len" title="11.2.10.&nbsp;min_stemming_len">min_stemming_len</a>
          directive</p></li>
<li class="listitem"><p>added <a class="link" href="#api-func-isconnecterror" title="8.1.7.&nbsp;IsConnectError">IsConnectError()</a> API call
          (helps distingusih API vs remote errors)</p></li>
<li class="listitem"><p>added duplicate log messages filter to searchd</p></li>
<li class="listitem"><p>added --nodetach debugging switch to searchd</p></li>
<li class="listitem"><p>added blackhole agents support for debugging/testing (<a class="link" href="#conf-agent-blackhole" title="11.2.32.&nbsp;agent_blackhole">agent_blackhole</a>
          directive)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-max-filters" title="11.4.20.&nbsp;max_filters">max_filters</a>,
          <a class="link" href="#conf-max-filter-values" title="11.4.21.&nbsp;max_filter_values">max_filter_values</a>
          directives (were hardcoded before)</p></li>
<li class="listitem"><p>added int64 expression evaluation path, automatic inference,
          and BIGINT() enforcer function</p></li>
<li class="listitem"><p>added crash handler for debugging (<a class="link" href="#conf-crash-log-path" title="11.4.19.&nbsp;crash_log_path">crash_log_path</a>
          directive)</p></li>
<li class="listitem"><p>added MS SQL (aka SQL Server) source support (Windows only,
          <a class="link" href="#conf-mssql-winauth" title="11.1.46.&nbsp;mssql_winauth">mssql_winauth</a> and <a class="link" href="#conf-mssql-unicode" title="11.1.47.&nbsp;mssql_unicode">mssql_unicode</a> directives)</p></li>
<li class="listitem"><p>added indexer-side column unpacking feature (<a class="link" href="#conf-unpack-zlib" title="11.1.48.&nbsp;unpack_zlib">unpack_zlib</a>, <a class="link" href="#conf-unpack-mysqlcompress" title="11.1.49.&nbsp;unpack_mysqlcompress">unpack_mysqlcompress</a>
          directives)</p></li>
<li class="listitem"><p>added nested brackers and NOTs support to <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">query language</a>, rewritten query
          parser</p></li>
<li class="listitem"><p>added persistent connections support (<a class="link" href="#api-func-open" title="8.8.1.&nbsp;Open">Open()</a> and <a class="link" href="#api-func-close" title="8.8.2.&nbsp;Close">Close()</a> API calls)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-index-exact-words" title="11.2.42.&nbsp;index_exact_words">index_exact_words</a> feature,
          and exact form operator to query language ("hello =world")</p></li>
<li class="listitem"><p>added status variables support to SphinxSE (SHOW STATUS LIKE
          'sphinx_%')</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-max-packet-size" title="11.4.17.&nbsp;max_packet_size">max_packet_size</a> directive (was
          hardcoded at 8M before)</p></li>
<li class="listitem"><p>added UNIX socket support, and multi-interface support (<a class="link" href="#conf-listen" title="11.4.1.&nbsp;listen">listen</a> directive)</p></li>
<li class="listitem"><p>added star-syntax support to <a class="link" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">BuildExcerpts()</a> API
          call</p></li>
<li class="listitem"><p>added inplace inversion of .spa and .spp (<a class="link" href="#conf-inplace-enable" title="11.2.37.&nbsp;inplace_enable">inplace_enable</a> directive,
          1.5-2x less disk space for indexing)</p></li>
<li class="listitem"><p>added builtin Czech stemmer (morphology=stem_cz)</p></li>
<li class="listitem"><p>added <a class="link" href="#sort-expr" title="5.6.&nbsp;SPH_SORT_EXPR mode">IDIV(), NOW(), INTERVAL(),
          IN() functions</a> to expressions</p></li>
<li class="listitem"><p>added index-level early-reject based on filters</p></li>
<li class="listitem"><p>added MVA updates feature (<a class="link" href="#conf-mva-updates-pool" title="11.4.18.&nbsp;mva_updates_pool">mva_updates_pool</a>
          directive)</p></li>
<li class="listitem"><p>added select-list feature with computed expressions support
          (see <a class="link" href="#api-func-setselect" title="8.2.4.&nbsp;SetSelect">SetSelect()</a> API call,
          test.php --select switch), protocol 1.22</p></li>
<li class="listitem"><p>added integer expressions support (2x faster than
          float)</p></li>
<li class="listitem"><p>added multiforms support (multiple source words in wordforms
          file)</p></li>
<li class="listitem"><p>added <a class="link" href="#api-func-setrankingmode" title="8.3.2.&nbsp;SetRankingMode">legacy
          rankers</a> (MATCH_ALL/MATCH_ANY/etc), removed legacy matching
          code (everything runs on V2 engine now)</p></li>
<li class="listitem"><p>added <a class="link" href="#extended-syntax" title="5.3.&nbsp;Extended query syntax">field position
          limit</a> modifier to field operator (syntax: @title[50] hello
          world)</p></li>
<li class="listitem"><p>added killlist support (<a class="link" href="#conf-sql-query-killlist" title="11.1.16.&nbsp;sql_query_killlist">sql_query_killlist</a>
          directive, --merge-killlists switch)</p></li>
<li class="listitem"><p>added on-disk SPI support (<a class="link" href="#conf-ondisk-dict" title="11.2.36.&nbsp;ondisk_dict">ondisk_dict</a> directive)</p></li>
<li class="listitem"><p>added indexer IO stats</p></li>
<li class="listitem"><p>added periodic .spa flush (<a class="link" href="#conf-attr-flush-period" title="11.4.15.&nbsp;attr_flush_period">attr_flush_period</a>
          directive)</p></li>
<li class="listitem"><p>added config reload on SIGHUP</p></li>
<li class="listitem"><p>added per-query attribute overrides feature (see <a class="link" href="#api-func-setoverride" title="8.2.3.&nbsp;SetOverride">SetOverride()</a> API call);
          protocol 1.21</p></li>
<li class="listitem"><p>added signed 64bit attrs support (<a class="link" href="#conf-sql-attr-bigint" title="11.1.19.&nbsp;sql_attr_bigint">sql_attr_bigint</a>
          directive)</p></li>
<li class="listitem"><p>improved HTML stripper to also skip PIs (&lt;? ... ?&gt;, such
          as &lt;?php ... ?&gt;)</p></li>
<li class="listitem"><p>improved excerpts speed (upto 50x faster on big
          documents)</p></li>
<li class="listitem"><p>fixed a short window of searchd inaccessibility on startup
          (started listen()ing too early before)</p></li>
<li class="listitem"><p>fixed .spa loading on systems where read() is 2GB
          capped</p></li>
<li class="listitem"><p>fixed infixes vs morphology issues</p></li>
<li class="listitem"><p>fixed backslash escaping, added backslash to
          EscapeString()</p></li>
<li class="listitem"><p>fixed handling of over-2GB dictionary files (.spi)</p></li>
</ul></div></div>
<div class="sect1" title="A.6.&nbsp;Version 0.9.8.1, 30 oct 2008"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel0981"></a>A.6.&nbsp;Version 0.9.8.1, 30 oct 2008</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added configure script to libsphinxclient</p></li>
<li class="listitem"><p>changed proximity/quorum operator syntax to require whitespace
          after length</p></li>
<li class="listitem"><p>fixed potential head process crash on SIGPIPE during "maxed
          out" message</p></li>
<li class="listitem"><p>fixed handling of incomplete remote replies (caused
          over-degraded distributed results, in rare cases)</p></li>
<li class="listitem"><p>fixed sending of big remote requests (caused distributed
          requests to fail, in rare cases)</p></li>
<li class="listitem"><p>fixed FD_SET() overflow (caused searchd to crash on startup,
          in rare cases)</p></li>
<li class="listitem"><p>fixed MVA vs distributed indexes (caused loss of 1st MVA value
          in result set)</p></li>
<li class="listitem"><p>fixed tokenizing of exceptions terminated by specials (eg.
          "GPS AT&amp;T" in extended mode)</p></li>
<li class="listitem"><p>fixed buffer overrun in stemmer on overlong tokens
          occasionally emitted by proximity/quorum operator parser (caused
          crashes on certain proximity/quorum queries)</p></li>
<li class="listitem"><p>fixed wordcount ranker (could be dropping hits)</p></li>
<li class="listitem"><p>fixed --merge feature (numerous different fixes, caused broken
          indexes)</p></li>
<li class="listitem"><p>fixed --merge-dst-range performance</p></li>
<li class="listitem"><p>fixed prefix/infix generation for stopwords</p></li>
<li class="listitem"><p>fixed ignore_chars vs specials</p></li>
<li class="listitem"><p>fixed misplaced F_SETLKW check (caused certain build types,
          eg. RPM build on FC8, to fail)</p></li>
<li class="listitem"><p>fixed dictionary-defined charsets support in spelldump, added
          \x-style wordchars support</p></li>
<li class="listitem"><p>fixed Java API to properly send long strings (over 64K; eg.
          long document bodies for excerpts)</p></li>
<li class="listitem"><p>fixed Python API to accept offset/limit of 'long' type</p></li>
<li class="listitem"><p>fixed default ID range (that filtered out all 64-bit values)
          in Java and Python APIs</p></li>
</ul></div></div>
<div class="sect1" title="A.7.&nbsp;Version 0.9.8, 14 jul 2008"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel098"></a>A.7.&nbsp;Version 0.9.8, 14 jul 2008</h2></div></div></div>
<h3>Indexing</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added support for 64-bit document and keyword IDs,
          --enable-id64 switch to configure</p></li>
<li class="listitem"><p>added support for floating point attributes</p></li>
<li class="listitem"><p>added support for bitfields in attributes, <a class="link" href="#conf-sql-attr-bool" title="11.1.18.&nbsp;sql_attr_bool">sql_attr_bool</a> directive and
          bit-widths part in <a class="link" href="#conf-sql-attr-uint" title="11.1.17.&nbsp;sql_attr_uint">sql_attr_uint</a> directive</p></li>
<li class="listitem"><p>added support for multi-valued attributes (MVA)</p></li>
<li class="listitem"><p>added metaphone preprocessor</p></li>
<li class="listitem"><p>added libstemmer library support, provides stemmers for a
          number of additional languages</p></li>
<li class="listitem"><p>added xmlpipe2 source type, that supports arbitrary fields and
          attributes</p></li>
<li class="listitem"><p>added word form dictionaries, <a class="link" href="#conf-wordforms" title="11.2.12.&nbsp;wordforms">wordforms</a> directive (and spelldump
          utility)</p></li>
<li class="listitem"><p>added tokenizing exceptions, <a class="link" href="#conf-exceptions" title="11.2.13.&nbsp;exceptions">exceptions</a> directive</p></li>
<li class="listitem"><p>added an option to fully remove element contents to HTML
          stripper, <a class="link" href="#conf-html-remove-elements" title="11.2.29.&nbsp;html_remove_elements">html_remove_elements</a>
          directive</p></li>
<li class="listitem"><p>added HTML entities decoder (with full XHTML1 set support) to
          HTML stripper</p></li>
<li class="listitem"><p>added per-index HTML stripping settings, <a class="link" href="#conf-html-strip" title="11.2.27.&nbsp;html_strip">html_strip</a>, <a class="link" href="#conf-html-index-attrs" title="11.2.28.&nbsp;html_index_attrs">html_index_attrs</a>, and <a class="link" href="#conf-html-remove-elements" title="11.2.29.&nbsp;html_remove_elements">html_remove_elements</a>
          directives</p></li>
<li class="listitem"><p>added IO load throttling, <a class="link" href="#conf-max-iops" title="11.3.2.&nbsp;max_iops">max_iops</a> and <a class="link" href="#conf-max-iosize" title="11.3.3.&nbsp;max_iosize">max_iosize</a> directives</p></li>
<li class="listitem"><p>added SQL load throttling, <a class="link" href="#conf-sql-ranged-throttle" title="11.1.32.&nbsp;sql_ranged_throttle">sql_ranged_throttle</a>
          directive</p></li>
<li class="listitem"><p>added an option to index prefixes/infixes for given fields
          only, <a class="link" href="#conf-prefix-fields" title="11.2.20.&nbsp;prefix_fields">prefix_fields</a> and
          <a class="link" href="#conf-infix-fields" title="11.2.21.&nbsp;infix_fields">infix_fields</a>
          directives</p></li>
<li class="listitem"><p>added an option to ignore certain characters (instead of just
          treating them as whitespace), <a class="link" href="#conf-ignore-chars" title="11.2.17.&nbsp;ignore_chars">ignore_chars</a> directive</p></li>
<li class="listitem"><p>added an option to increment word position on phrase boundary
          characters, <a class="link" href="#conf-phrase-boundary" title="11.2.25.&nbsp;phrase_boundary">phrase_boundary</a> and <a class="link" href="#conf-phrase-boundary-step" title="11.2.26.&nbsp;phrase_boundary_step">phrase_boundary_step</a>
          directives</p></li>
<li class="listitem"><p>added --merge-dst-range switch (and filters) to index merging
          feature (--merge switch)</p></li>
<li class="listitem"><p>added <a class="link" href="#conf-mysql-connect-flags" title="11.1.8.&nbsp;mysql_connect_flags">mysql_connect_flags</a>
          directive (eg. to reduce indexing time MySQL network traffic and/or
          time)</p></li>
<li class="listitem"><p>improved ordinals sorting; now runs in fixed RAM</p></li>
<li class="listitem"><p>improved handling of documents with zero/NULL ids, now
          skipping them instead of aborting</p></li>
</ul></div>
<h3>Search daemon</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added an option to unlink old index on succesful rotation,
          <a class="link" href="#conf-unlink-old" title="11.4.14.&nbsp;unlink_old">unlink_old</a> directive</p></li>
<li class="listitem"><p>added an option to keep index files open at all times (fixes
          subtle races on rotation), <a class="link" href="#conf-preopen" title="11.2.35.&nbsp;preopen">preopen</a> and <a class="link" href="#conf-preopen-indexes" title="11.4.13.&nbsp;preopen_indexes">preopen_indexes</a>
          directives</p></li>
<li class="listitem"><p>added an option to profile searchd disk I/O, --iostats
          command-line option</p></li>
<li class="listitem"><p>added an option to rotate index seamlessly (fully avoids query
          stalls), <a class="link" href="#conf-seamless-rotate" title="11.4.12.&nbsp;seamless_rotate">seamless_rotate</a>
          directive</p></li>
<li class="listitem"><p>added HTML stripping support to excerpts (uses per-index
          settings)</p></li>
<li class="listitem"><p>added 'exact_phrase', 'single_passage', 'use_boundaries',
          'weight_order 'options to <a class="link" href="#api-func-buildexcerpts" title="8.7.1.&nbsp;BuildExcerpts">BuildExcerpts()</a> API
          call</p></li>
<li class="listitem"><p>added distributed attribute updates propagation</p></li>
<li class="listitem"><p>added distributed retries on master node side</p></li>
<li class="listitem"><p>added log reopen on SIGUSR1</p></li>
<li class="listitem"><p>added --stop switch (sends SIGTERM to running instance)</p></li>
<li class="listitem"><p>added Windows service mode, and --servicename switch</p></li>
<li class="listitem"><p>added Windows --rotate support</p></li>
<li class="listitem"><p>improved log timestamping, now with millisecond
          precision</p></li>
</ul></div>
<h3>Querying</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added extended engine V2 (faster, cleaner, better;
          SPH_MATCH_EXTENDED2 mode)</p></li>
<li class="listitem"><p>added ranking modes support (V2 engine only; <a class="link" href="#api-func-setrankingmode" title="8.3.2.&nbsp;SetRankingMode">SetRankingMode()</a> API
          call)</p></li>
<li class="listitem"><p>added quorum searching support to query language (V2 engine
          only; example: "any three of all these words"/3)</p></li>
<li class="listitem"><p>added query escaping support to query language, and <a class="link" href="#api-func-escapestring" title="8.7.4.&nbsp;EscapeString">EscapeString()</a> API
          call</p></li>
<li class="listitem"><p>added multi-field syntax support to query language (example:
          "@(field1,field2) something"), and @@relaxed field checks
          option</p></li>
<li class="listitem"><p>added optional star-syntax ('word*') support in keywords,
          <a class="link" href="#conf-enable-star" title="11.2.22.&nbsp;enable_star">enable_star</a> directive (for
          prefix/infix indexes only)</p></li>
<li class="listitem"><p>added full-scan support (query must be fully empty; can
          perform block-reject optimization)</p></li>
<li class="listitem"><p>added COUNT(DISTINCT(attr)) calculation support, <a class="link" href="#api-func-setgroupdistinct" title="8.5.2.&nbsp;SetGroupDistinct">SetGroupDistinct()</a> API
          call</p></li>
<li class="listitem"><p>added group-by on MVA support, <a class="link" href="#api-func-setarrayresult" title="8.1.6.&nbsp;SetArrayResult">SetArrayResult()</a> PHP API
          call</p></li>
<li class="listitem"><p>added per-index weights feature, <a class="link" href="#api-func-setindexweights" title="8.3.6.&nbsp;SetIndexWeights">SetIndexWeights()</a> API
          call</p></li>
<li class="listitem"><p>added geodistance support, <a class="link" href="#api-func-setgeoanchor" title="8.4.5.&nbsp;SetGeoAnchor">SetGeoAnchor()</a> API
          call</p></li>
<li class="listitem"><p>added result set sorting by arbitrary expressions in run time
          (eg. "@weight+log(price)*2.5"), SPH_SORT_EXPR mode</p></li>
<li class="listitem"><p>added result set sorting by @custom compile-time sorting
          function (see src/sphinxcustomsort.inl)</p></li>
<li class="listitem"><p>added result set sorting by @random value</p></li>
<li class="listitem"><p>added result set merging for indexes with different
          schemas</p></li>
<li class="listitem"><p>added query comments support (3rd arg to <a class="link" href="#api-func-query" title="8.6.1.&nbsp;Query">Query()</a>/<a class="link" href="#api-func-addquery" title="8.6.2.&nbsp;AddQuery">AddQuery()</a> API calls, copied
          verbatim to query log)</p></li>
<li class="listitem"><p>added keyword extraction support, <a class="link" href="#api-func-buildkeywords" title="8.7.3.&nbsp;BuildKeywords">BuildKeywords()</a> API
          call</p></li>
<li class="listitem"><p>added binding field weights by name, <a class="link" href="#api-func-setfieldweights" title="8.3.5.&nbsp;SetFieldWeights">SetFieldWeights()</a> API
          call</p></li>
<li class="listitem"><p>added optional limit on query time, <a class="link" href="#api-func-setmaxquerytime" title="8.2.2.&nbsp;SetMaxQueryTime">SetMaxQueryTime()</a> API
          call</p></li>
<li class="listitem"><p>added optional limit on found matches count (4rd arg to <a class="link" href="#api-func-setlimits" title="8.2.1.&nbsp;SetLimits">SetLimits()</a> API call, so-called
          'cutoff')</p></li>
</ul></div>
<h3>APIs and SphinxSE</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added pure C API (libsphinxclient)</p></li>
<li class="listitem"><p>added Ruby API (thanks to Dmytro Shteflyuk)</p></li>
<li class="listitem"><p>added Java API</p></li>
<li class="listitem"><p>added SphinxSE support for MVAs (use varchar), floats (use
          float), 64bit docids (use bigint)</p></li>
<li class="listitem"><p>added SphinxSE options "floatrange", "geoanchor",
          "fieldweights", "indexweights", "maxquerytime", "comment", "host"
          and "port"; and support for "expr:CLAUSE"</p></li>
<li class="listitem"><p>improved SphinxSE max query size (using MySQL condition
          pushdown), upto 256K now</p></li>
</ul></div>
<h3>General</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added scripting (shebang syntax) support to config files
          (example: #!/usr/bin/php in the first line)</p></li>
<li class="listitem"><p>added unified config handling and validation to all
          programs</p></li>
<li class="listitem"><p>added unified documentation</p></li>
<li class="listitem"><p>added .spec file for RPM builds</p></li>
<li class="listitem"><p>added automated testing suite</p></li>
<li class="listitem"><p>improved index locking, now fcntl()-based instead of buggy
          file-existence-based</p></li>
<li class="listitem"><p>fixed unaligned RAM accesses, now works on SPARC and
          ARM</p></li>
</ul></div>
<h3><a name="rel098-fixes-since-rc2"></a>Changes and fixes since
      0.9.8-rc2</h3><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added pure C API (libsphinxclient)</p></li>
<li class="listitem"><p>added Ruby API</p></li>
<li class="listitem"><p>added SetConnectTimeout() PHP API call</p></li>
<li class="listitem"><p>added allowed type check to UpdateAttributes() handler (bug
          #174)</p></li>
<li class="listitem"><p>added defensive MVA checks on index preload (protection
          against broken indexes, bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=168" target="_top">#168</a>)</p></li>
<li class="listitem"><p>added sphinx-min.conf sample file</p></li>
<li class="listitem"><p>added --without-iconv switch to configure</p></li>
<li class="listitem"><p>removed redundant -lz dependency in searchd</p></li>
<li class="listitem"><p>removed erroneous "xmlpipe2 deprecated" warning</p></li>
<li class="listitem"><p>fixed EINTR handling in piped read (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=166" target="_top">#166</a>)</p></li>
<li class="listitem"><p>fixup query time before logging and sending to client (bug
          #153)</p></li>
<li class="listitem"><p>fixed attribute updates vs full-scan early-reject index (bug
          #149)</p></li>
<li class="listitem"><p>fixed gcc warnings (bug <a class="ulink" href="http://sphinxsearch.com/bugs/view.php?id=160" target="_top">#160</a>)</p></li>
<li class="listitem"><p>fixed mysql connection attempt vs pgsql source type (bug
          #165)</p></li>
<li class="listitem"><p>fixed 32-bit wraparound when preloading over 2 GB files</p></li>
<li class="listitem"><p>fixed "out of memory" message vs over 2 GB allocs (bug
          #116)</p></li>
<li class="listitem"><p>fixed unaligned RAM access detection on ARM (where unaligned
          reads do not crash but produce wrong results)</p></li>
<li class="listitem"><p>fixed missing full scan results in some cases</p></li>
<li class="listitem"><p>fixed several bugs in --merge, --merge-dst-range</p></li>
<li class="listitem"><p>fixed @geodist vs MultiQuery and filters, @expr vs
          MultiQuery</p></li>
<li class="listitem"><p>fixed GetTokenEnd() vs 1-grams (was causing crash in
          excerpts)</p></li>
<li class="listitem"><p>fixed sql_query_range to handle empty strings in addition to
          NULL strings (Postgres specific)</p></li>
<li class="listitem"><p>fixed morphology=none vs infixes</p></li>
<li class="listitem"><p>fixed case sensitive attributes names in
          UpdateAttributes()</p></li>
<li class="listitem"><p>fixed ext2 ranking vs. stopwords (now using atompos from query
          parser)</p></li>
<li class="listitem"><p>fixed EscapeString() call</p></li>
<li class="listitem"><p>fixed escaped specials (now handled as whitespace if not in
          charset)</p></li>
<li class="listitem"><p>fixed schema minimizer (now handles type/size
          mismatches)</p></li>
<li class="listitem"><p>fixed word stats in extended2; stemmed form is now
          returned</p></li>
<li class="listitem"><p>fixed spelldump case folding vs dictionary-defined character
          sets</p></li>
<li class="listitem"><p>fixed Postgres BOOLEAN handling</p></li>
<li class="listitem"><p>fixed enforced "inline" docinfo on empty indexes (normally ok,
          but index merge was really confused)</p></li>
<li class="listitem"><p>fixed rare count(distinct) out-of-bounds issue (it occasionaly
          caused too high @distinct values)</p></li>
<li class="listitem"><p>fixed hangups on documents with id=DOCID_MAX in some
          cases</p></li>
<li class="listitem"><p>fixed rare crash in tokenizer (prefixed synonym vs. input
          stream eof)</p></li>
<li class="listitem"><p>fixed query parser vs "aaa (bbb ccc)|ddd" queries</p></li>
<li class="listitem"><p>fixed BuildExcerpts() request in Java API</p></li>
<li class="listitem"><p>fixed Postgres specific memory leak</p></li>
<li class="listitem"><p>fixed handling of overshort keywords (less than
          min_word_len)</p></li>
<li class="listitem"><p>fixed HTML stripper (now emits space after indexed
          attributes)</p></li>
<li class="listitem"><p>fixed 32-field case in query parser</p></li>
<li class="listitem"><p>fixed rare count(distinct) vs. querying multiple local indexes
          vs. reusable sorter issue</p></li>
<li class="listitem"><p>fixed sorting of negative floats in SPH_SORT_EXTENDED
          mode</p></li>
</ul></div></div>
<div class="sect1" title="A.8.&nbsp;Version 0.9.7, 02 apr 2007"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel097"></a>A.8.&nbsp;Version 0.9.7, 02 apr 2007</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added support for
          <code class="option">sql_str2ordinal_column</code></p></li>
<li class="listitem"><p>added support for upto 5 sort-by attrs (in extended sorting
          mode)</p></li>
<li class="listitem"><p>added support for separate groups sorting clause (in group-by
          mode)</p></li>
<li class="listitem"><p>added support for on-the-fly attribute updates (PRE-ALPHA;
          will change heavily; use for preliminary testing ONLY)</p></li>
<li class="listitem"><p>added support for zero/NULL attributes</p></li>
<li class="listitem"><p>added support for 0.9.7 features to SphinxSE</p></li>
<li class="listitem"><p>added support for n-grams (alpha, 1-grams only for now)</p></li>
<li class="listitem"><p>added support for warnings reported to client</p></li>
<li class="listitem"><p>added support for exclude-filters</p></li>
<li class="listitem"><p>added support for prefix and infix indexing (see
          <code class="option">max_prefix_len</code>,
          <code class="option">max_infix_len</code>)</p></li>
<li class="listitem"><p>added <code class="option">@*</code> syntax to reset current field to
          query language</p></li>
<li class="listitem"><p>added removal of duplicate entries in query index order</p></li>
<li class="listitem"><p>added PHP API workarounds for PHP signed/unsigned
          braindamage</p></li>
<li class="listitem"><p>added locks to avoid two concurrent indexers working on same
          index</p></li>
<li class="listitem"><p>added check for existing attributes vs.
          <code class="option">docinfo=none</code> case</p></li>
<li class="listitem"><p>improved groupby code a lot (better precision, and upto 25x
          times faster in extreme cases)</p></li>
<li class="listitem"><p>improved error handling and reporting</p></li>
<li class="listitem"><p>improved handling of broken indexes (reports error instead of
          hanging/crashing)</p></li>
<li class="listitem"><p>improved <code class="option">mmap()</code> limits for attributes and
          wordlists (now able to map over 4 GB on x64 and over 2 GB on x32
          where possible)</p></li>
<li class="listitem"><p>improved <code class="option">malloc()</code> pressure in head daemon
          (search time should not degrade with time any more)</p></li>
<li class="listitem"><p>improved <code class="filename">test.php</code> command line
          options</p></li>
<li class="listitem"><p>improved error reporting (distributed query, broken index etc
          issues now reported to client)</p></li>
<li class="listitem"><p>changed default network packet size to be 8M, added extra
          checks</p></li>
<li class="listitem"><p>fixed division by zero in BM25 on 1-document collections (in
          extended matching mode)</p></li>
<li class="listitem"><p>fixed <code class="filename">.spl</code> files getting unlinked</p></li>
<li class="listitem"><p>fixed crash in schema compatibility test</p></li>
<li class="listitem"><p>fixed UTF-8 Russian stemmer</p></li>
<li class="listitem"><p>fixed requested matches count when querying distributed
          agents</p></li>
<li class="listitem"><p>fixed signed vs. unsigned issues everywhere (ranged queries,
          CLI search output, and obtaining docid)</p></li>
<li class="listitem"><p>fixed potential crashes vs. negative query offsets</p></li>
<li class="listitem"><p>fixed 0-match docs vs. extended mode vs. stats</p></li>
<li class="listitem"><p>fixed group/timestamp filters being ignored if querying from
          older clients</p></li>
<li class="listitem"><p>fixed docs to mention <code class="option">pgsql</code> source
          type</p></li>
<li class="listitem"><p>fixed issues with explicit '&amp;' in extended matching
          mode</p></li>
<li class="listitem"><p>fixed wrong assertion in SBCS encoder</p></li>
<li class="listitem"><p>fixed crashes with no-attribute indexes after rotate</p></li>
</ul></div></div>
<div class="sect1" title="A.9.&nbsp;Version 0.9.7-rc2, 15 dec 2006"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel097rc2"></a>A.9.&nbsp;Version 0.9.7-rc2, 15 dec 2006</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added support for extended matching mode (query
          language)</p></li>
<li class="listitem"><p>added support for extended sorting mode (sorting
          clauses)</p></li>
<li class="listitem"><p>added support for SBCS excerpts</p></li>
<li class="listitem"><p>added <code class="option">mmap()ing</code> for attributes and wordlist
          (improves search time, speeds up <code class="option">fork()</code>
          greatly)</p></li>
<li class="listitem"><p>fixed attribute name handling to be case insensitive</p></li>
<li class="listitem"><p>fixed default compiler options to simplify post-mortem
          debugging (added <code class="option">-g</code>, removed
          <code class="option">-fomit-frame-pointer</code>)</p></li>
<li class="listitem"><p>fixed rare memory leak</p></li>
<li class="listitem"><p>fixed "hello hello" queries in "match phrase" mode</p></li>
<li class="listitem"><p>fixed issue with excerpts, texts and overlong queries</p></li>
<li class="listitem"><p>fixed logging multiple index name (no longer tokenized)</p></li>
<li class="listitem"><p>fixed trailing stopword not flushed from tokenizer</p></li>
<li class="listitem"><p>fixed boolean evaluation</p></li>
<li class="listitem"><p>fixed pidfile being wrongly <code class="option">unlink()ed</code> on
          <code class="option">bind()</code> failure</p></li>
<li class="listitem"><p>fixed <code class="option">--with-mysql-includes/libs</code> (they
          conflicted with well-known paths)</p></li>
<li class="listitem"><p>fixes for 64-bit platforms</p></li>
</ul></div></div>
<div class="sect1" title="A.10.&nbsp;Version 0.9.7-rc1, 26 oct 2006"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel097rc"></a>A.10.&nbsp;Version 0.9.7-rc1, 26 oct 2006</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added alpha index merging code</p></li>
<li class="listitem"><p>added an option to decrease <code class="option">max_matches</code>
          per-query</p></li>
<li class="listitem"><p>added an option to specify IP address for searchd to listen
          on</p></li>
<li class="listitem"><p>added support for unlimited amount of configured sources and
          indexes</p></li>
<li class="listitem"><p>added support for group-by queries</p></li>
<li class="listitem"><p>added support for /2 range modifier in charset_table</p></li>
<li class="listitem"><p>added support for arbitrary amount of document
          attributes</p></li>
<li class="listitem"><p>added logging filter count and index name</p></li>
<li class="listitem"><p>added <code class="option">--with-debug</code> option to configure to
          compile in debug mode</p></li>
<li class="listitem"><p>added <code class="option">-DNDEBUG</code> when compiling in default
          mode</p></li>
<li class="listitem"><p>improved search time (added doclist size hints, in-memory
          wordlist cache, and used VLB coding everywhere)</p></li>
<li class="listitem"><p>improved (refactored) SQL driver code (adding new drivers
          should be very easy now)</p></li>
<li class="listitem"><p>improved exceprts generation</p></li>
<li class="listitem"><p>fixed issue with empty sources and ranged queries</p></li>
<li class="listitem"><p>fixed querying purely remote distributed indexes</p></li>
<li class="listitem"><p>fixed suffix length check in English stemmer in some
          cases</p></li>
<li class="listitem"><p>fixed UTF-8 decoder for codes over U+20000 (for CJK)</p></li>
<li class="listitem"><p>fixed UTF-8 encoder for 3-byte sequences (for CJK)</p></li>
<li class="listitem"><p>fixed overshort (less than <code class="option">min_word_len</code>)
          words prepended to next field</p></li>
<li class="listitem"><p>fixed source connection order (indexer does not connect to all
          sources at once now)</p></li>
<li class="listitem"><p>fixed line numbering in config parser</p></li>
<li class="listitem"><p>fixed some issues with index rotation</p></li>
</ul></div></div>
<div class="sect1" title="A.11.&nbsp;Version 0.9.6, 24 jul 2006"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel096"></a>A.11.&nbsp;Version 0.9.6, 24 jul 2006</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added support for empty indexes</p></li>
<li class="listitem"><p>added support for multiple
          sql_query_pre/post/post_index</p></li>
<li class="listitem"><p>fixed timestamp ranges filter in "match any" mode</p></li>
<li class="listitem"><p>fixed configure issues with --without-mysql and --with-pgsql
          options</p></li>
<li class="listitem"><p>fixed building on Solaris 9</p></li>
</ul></div></div>
<div class="sect1" title="A.12.&nbsp;Version 0.9.6-rc1, 26 jun 2006"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rel096rc1"></a>A.12.&nbsp;Version 0.9.6-rc1, 26 jun 2006</h2></div></div></div>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>added boolean queries support (experimental, beta
          version)</p></li>
<li class="listitem"><p>added simple file-based query cache (experimental, beta
          version)</p></li>
<li class="listitem"><p>added storage engine for MySQL 5.0 and 5.1 (experimental, beta
          version)</p></li>
<li class="listitem"><p>added GNU style <code class="filename">configure</code> script</p></li>
<li class="listitem"><p>added new searchd protocol (all binary, and should be
          backwards compatible)</p></li>
<li class="listitem"><p>added distributed searching support to searchd</p></li>
<li class="listitem"><p>added PostgreSQL driver</p></li>
<li class="listitem"><p>added excerpts generation</p></li>
<li class="listitem"><p>added <code class="option">min_word_len</code> option to index</p></li>
<li class="listitem"><p>added <code class="option">max_matches</code> option to searchd, removed
          hardcoded MAX_MATCHES limit</p></li>
<li class="listitem"><p>added initial documentation, and a working
          <code class="filename">example.sql</code></p></li>
<li class="listitem"><p>added support for multiple sources per index</p></li>
<li class="listitem"><p>added soundex support</p></li>
<li class="listitem"><p>added group ID ranges support</p></li>
<li class="listitem"><p>added <code class="option">--stdin</code> command-line option to search
          utility</p></li>
<li class="listitem"><p>added <code class="option">--noprogress</code> option to indexer</p></li>
<li class="listitem"><p>added <code class="option">--index</code> option to search</p></li>
<li class="listitem"><p>fixed UTF-8 decoder (3-byte codepoints did not work)</p></li>
<li class="listitem"><p>fixed PHP API to handle big result sets faster</p></li>
<li class="listitem"><p>fixed config parser to handle empty values properly</p></li>
<li class="listitem"><p>fixed redundant <code class="code">time(NULL)</code> calls in time-segments
          mode</p></li>
</ul></div></div></div></div>

